<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computational Psychology on Computational Psychology</title>
    <link>http://haines-lab.com/</link>
    <description>Recent content in Computational Psychology on Computational Psychology</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Nathaniel Haines</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>On the equivalency between frequentist Ridge (and LASSO) regression and hierarchial Bayesian regression</title>
      <link>http://haines-lab.com/post/on-the-equivalency-between-the-lasso-ridge-regression-and-specific-bayesian-priors/</link>
      <pubDate>Mon, 06 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://haines-lab.com/post/on-the-equivalency-between-the-lasso-ridge-regression-and-specific-bayesian-priors/</guid>
      <description>&lt;script src=&#34;http://haines-lab.com/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;http://haines-lab.com/rmarkdown-libs/plotlyjs/plotly-htmlwidgets.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;http://haines-lab.com/rmarkdown-libs/plotlyjs/plotly-latest.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;http://haines-lab.com/rmarkdown-libs/plotly-binding/plotly.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;http://haines-lab.com/rmarkdown-libs/jquery/jquery.min.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;http://haines-lab.com/rmarkdown-libs/crosstalk/css/crosstalk.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;http://haines-lab.com/rmarkdown-libs/crosstalk/js/crosstalk.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;http://haines-lab.com/rmarkdown-libs/typedarray/typedarray.min.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In this post, we will explore frequentist and Bayesian analogues of &lt;em&gt;regularized/penalized linear regression&lt;/em&gt; models (e.g., LASSO [L1 penalty], Ridge regression [L2 penalty]), which are an extention of traditional linear regression models of the form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y = \beta_{0}+X\beta + \epsilon\tag{1}\]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is the squared error, which is normally distributed as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\epsilon \sim  \mathcal{N}(0, \sigma)\tag{2}\]&lt;/span&gt; Unlike these traditional linear regression models, regularized linear regression models produce &lt;strong&gt;biased estimates&lt;/strong&gt; for the &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights. Specifically, both frequentist and Bayesian regularized linear regression models pool information across &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights, resulting in regression toward a common mean. When the common mean is centered at 0, this pooling of information produces more conservative estimates for each &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weight (they are biased toward 0). In contrast, traditional linear regression models assume that &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights share no group-level information (i.e. they are independent), which leads to so-called &lt;strong&gt;unbiased estimates&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So then, why are these models—which produce biased estimates—becoming increasingly popular throughout the social and behavioral sciences?&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;learning-objectives&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Learning Objectives&lt;/h2&gt;
&lt;p&gt;The current post seeks to show that we actually want biased estimates in many contexts. In doing so, we will also explore associations between frequentist and Bayesian regularization. Therefore, the &lt;strong&gt;learning objectives&lt;/strong&gt; of the current post are to develop an understanding of:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;why so-called &lt;strong&gt;unbiased&lt;/strong&gt; estimates are good for science,&lt;/li&gt;
&lt;li&gt;the difference between traditional and regularized linear regression models, and&lt;/li&gt;
&lt;li&gt;the correspondence between frequentist regularization and hierarchical Bayesian regression&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data&lt;/h1&gt;
&lt;p&gt;For this post, we will use a college-admissions dataset that is freely available from &lt;a href=&#34;https://www.kaggle.com/mohansacharya/graduate-admissions&#34;&gt;Kaggle&lt;/a&gt;. Make sure to download the .csv file named &lt;code&gt;Admission_Predict_Ver1.1.csv&lt;/code&gt;. This dataset contains 500 observations (i.e. rows) and 9 total variables (i.e. columns). 1 of these columns is a subject ID, which we will note use for modeling. Taken directly from the link:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;“The dataset contains several parameters which are considered important during the application for Masters Programs. The parameters included are : 1. GRE Scores ( out of 340 ) 2. TOEFL Scores ( out of 120 ) 3. University Rating ( out of 5 ) 4. Statement of Purpose and Letter of Recommendation Strength ( out of 5 ) 5. Undergraduate GPA ( out of 10 ) 6. Research Experience ( either 0 or 1 ) 7. Chance of Admit ( ranging from 0 to 1 )”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Our goal is to predict the likelihood of being admitted to graduate school (&lt;em&gt;Chance of Admit&lt;/em&gt;), given the other variables, which we will now refer to as &lt;strong&gt;predictors&lt;/strong&gt;.&lt;/p&gt;
&lt;div id=&#34;getting-started&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;First off, let’s load the libraries that we will use:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# For traditional LASSO/Ridge regression
library(glmnet)
# For Bayesian modeling
library(rstan)
# For data wrangling/plotting
library(dplyr)
library(tidyr)
library(foreach)
library(ggplot2)
library(bayesplot) # Visualizing posteriors 
library(akima)     # for 3D plotting
library(plotly)    # for 3D plotting&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we need to read in the data. Assuming that you have already downloaded the data from the link above, we can read it into R as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# I was lazy and just left this in the downloads folder...
grad_dat &amp;lt;- read.csv(&amp;quot;~/Downloads/graduate-admissions/Admission_Predict_Ver1.1.csv&amp;quot;)

# View first few observations 
tbl_df(grad_dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 500 x 9
##    Serial.No. GRE.Score TOEFL.Score University.Rati…   SOP   LOR  CGPA
##         &amp;lt;int&amp;gt;     &amp;lt;int&amp;gt;       &amp;lt;int&amp;gt;            &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1          1       337         118                4   4.5   4.5  9.65
##  2          2       324         107                4   4     4.5  8.87
##  3          3       316         104                3   3     3.5  8   
##  4          4       322         110                3   3.5   2.5  8.67
##  5          5       314         103                2   2     3    8.21
##  6          6       330         115                5   4.5   3    9.34
##  7          7       321         109                3   3     4    8.2 
##  8          8       308         101                2   3     4    7.9 
##  9          9       302         102                1   2     1.5  8   
## 10         10       323         108                3   3.5   3    8.6 
## # … with 490 more rows, and 2 more variables: Research &amp;lt;int&amp;gt;,
## #   Chance.of.Admit &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-training-and-test-sets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Creating Training and Test Sets&lt;/h2&gt;
&lt;p&gt;Before really looking at the data, we need to separate out the training and testing portions. The original competition version of data uploaded to Kaggle only included the first 400 observations, and competitors had to make predictions on the remaining 100 observations before the actual outcomes (i.e. likelihood of getting into graduate school) were released.&lt;/p&gt;
&lt;p&gt;To show off the benefits of regularized over traditional methods, we will only train our models on &lt;strong&gt;the first 20 observations, and make predictions on the remaining 480&lt;/strong&gt;. In these low data settings—which are common to many areas of social and behavioral science (e.g., psychology, neuroscience, human ecology, etc.)—regularized regression models show clear advantages over traditional regression models. In fact, I will go as far as claiming that &lt;strong&gt;regularized models should be the default choice in most areas of science&lt;/strong&gt;, and the following examples should explain why.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Training data (used to fit model)
train_dat &amp;lt;- grad_dat[1:20,] # Only first 20 for training

# Testing data (used to test model generalizability)
test_dat &amp;lt;- grad_dat[21:500,] # Testing on the rest&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have the data read in and separated, it would be useful to visualize our training data to get a sense of what we are working with. A correlation matrix should do a good job here:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Plotting correlation matrix
cor(train_dat) %&amp;gt;%
  as.data.frame() %&amp;gt;%
  mutate(Var1 = factor(row.names(.), levels=row.names(.))) %&amp;gt;% # For nice order
  gather(Var2, Correlation, 1:9) %&amp;gt;%
  ggplot(aes(reorder(Var2, Correlation), # Reorder to visualize
             reorder(Var1, -Correlation), fill = Correlation)) +
  geom_tile() +
  scale_fill_continuous(type = &amp;quot;viridis&amp;quot;) +
  xlab(&amp;quot;Variable&amp;quot;) +
  ylab(&amp;quot;Variable&amp;quot;) +
  theme_minimal(base_size = 15) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2019-05-06-on-the-equivalency-between-the-lasso-ridge-regression-and-specific-bayesian-priors_files/figure-html/2019-05-06_fig0-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;This correlation matrix shows us that &lt;code&gt;Serial.No&lt;/code&gt; is not really correlated with any of the other 8 variables. This makes sense, given that &lt;code&gt;Serial.No&lt;/code&gt; is the subject ID (we will not use that in our models). Otherwise, it appears that there is a moderate amount of collinearity amoung the predictor and outcome variables.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;traditional-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Traditional Regression&lt;/h2&gt;
&lt;p&gt;Traditional linear regression models seek to mimimize the squared error between predicted and actual observations. Formally, we can represent this with a &lt;em&gt;loss function&lt;/em&gt; of the following form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\underset{\boldsymbol{\beta}}{argmin}\sum_{i=1}^{n}(y_{i} - \beta_{0} - \sum_{j=1}^{p}\beta_{j}x_{ij})^2\tag{3}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(y_{i}\)&lt;/span&gt; is the outcome variable (probability of acceptance in our example) for observation &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is the total number of observations (20 students in our training data example), &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is the number of predictors (7 in our example), &lt;span class=&#34;math inline&#34;&gt;\(\beta_{0}\)&lt;/span&gt; is the intercept of the model, and &lt;span class=&#34;math inline&#34;&gt;\(\beta_{1,2,...,j}\)&lt;/span&gt; are the weights (i.e. slopes) for each of the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; predictor variables. Under the assumption of normality, both ordinary least squares and maximum likelihood estimation of &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights in equation 3 will offer the same results—from here on, we will refer to these methods of minimizing equation 3 as &lt;em&gt;traditional linear regression&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Below, we will fit a traditional linear regression model on the training set (which contains 20 observations total), and we will see how well it predicts the graduate school acceptance probability (&lt;span class=&#34;math inline&#34;&gt;\(\text{Pr}(Acceptance)\)&lt;/span&gt;) for each of the remaining 480 observations. We begin by scaling all variables—that is, we mean-center and divide each column by its own standard deviation (SD). Then, we apply the same standardization to the test data, followed by fitting the traditional model and making test-set predictions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Scale training data (and get rid of ID)
train_scale &amp;lt;- scale(train_dat[,2:9])

# Find means and SDs of training data variables
means &amp;lt;- attributes(train_scale)$`scaled:center`
SDs &amp;lt;- attributes(train_scale)$`scaled:scale`

# Scale test data using training data summary stats (no cheating!)
test_scale &amp;lt;- scale(test_dat[,-1], center = means, scale = SDs)

# Fit linear regression
fit_lr &amp;lt;- lm(Chance.of.Admit ~ ., data = as.data.frame(train_scale))

# Generate test-set predictions with linear regression
y_pred_lr &amp;lt;- predict(fit_lr, newdata = as.data.frame(test_scale[,-8]))

# Plot cor(predicted, actual)
qplot(x = y_pred_lr, y = test_scale[,8],
      main = paste0(&amp;quot;Traditional Linear Regression\n&amp;quot;, 
                    &amp;quot;r = &amp;quot;, round(cor(test_scale[,8], y_pred_lr), 2))) +
  xlab(&amp;quot;Model Predicted Pr(Acceptance)&amp;quot;) +
  ylab(&amp;quot;Actual Pr(Acceptance)&amp;quot;) +
  theme_minimal(base_size = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2019-05-06-on-the-equivalency-between-the-lasso-ridge-regression-and-specific-bayesian-priors_files/figure-html/2019-05-06_fig1-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;Wow, not bad at all! Even with only 20 observations, the correlation between predicted and actual probability of acceptance for the remaining 480 observations is $r = $ &lt;span class=&#34;math inline&#34;&gt;\(0.76\)&lt;/span&gt;. This suggests that probability of acceptance is rather well described as a simple linear combination of the predictors.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;regularized-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Regularized Regression&lt;/h2&gt;
&lt;p&gt;As described above, regularized linear regression models aim to estimate more conservative values for the &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights in a model, and this is true for both frequentist and Bayesian versions of regularization. While there are many methods that can be used to regularize your estimation procedure, we will focus specifically on two popular forms—namely, ridge and LASSO regression. We start below by describing each regression generally, and then proceed to implement both the frequentist and Bayesian versions.&lt;/p&gt;
&lt;div id=&#34;ridge-regression&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Ridge Regression&lt;/h3&gt;
&lt;p&gt;The extention from traditional to ridge regression is actually very straightforward! Specifically, we modify the loss function (equation 3) to include a &lt;strong&gt;penalty term&lt;/strong&gt; for model complexity, where model complexity is operationalized as the sum of squared &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\underbrace{\underset{\boldsymbol{\beta}}{argmin}\sum_{i=1}^{n}(y_{i} - \beta_{0} - \sum_{j=1}^{p}\beta_{j}x_{ij})^2}_{\text{Traditional Loss Function}} + \underbrace{\lambda\sum_{j=1}^{p}\beta_{j}^2}_{\text{Ridge Penalty}}\tag{4}\]&lt;/span&gt; Here, &lt;span class=&#34;math inline&#34;&gt;\(\lambda~(0&amp;lt;\lambda&amp;lt;\infty)\)&lt;/span&gt; is a penalty parameter, which controls how much regularization we would like in the model. To gain an intuition for the behavior of this model, think of what happens at the very extremes of &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;. For example, when &lt;span class=&#34;math inline&#34;&gt;\(\lambda = 0\)&lt;/span&gt;, what happens to equation 4? Well, the model simply reduces to equation 3, and we are back to traditional regression! What about as &lt;span class=&#34;math inline&#34;&gt;\(\lambda \rightarrow \infty\)&lt;/span&gt;? In that case, any non-zero values for &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; will lead to an infinitely large penalty—then, the only solution to equation 4 is for all &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights to be equal to 0, indicating no learning from the data at all.&lt;/p&gt;
&lt;p&gt;Therefore, we can think of &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; as a parameter that &lt;strong&gt;controls how much we learn from the data&lt;/strong&gt;, with smaller and larger values leading to more and less learning, respectively. Note that parameters that control how much we learn from data are typically called &lt;strong&gt;hyper-parameters&lt;/strong&gt;. Framed in these terms, we can view traditional regression methods as those that maximally learn from the data, and regularized regression models as those that restrict learning from the data. It is in this way that traditional regression produces &lt;em&gt;unbiased&lt;/em&gt; estimate of the &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights. That is, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights are unbiased with respect to the information available in the training data. However, when data are noisy (i.e. contain large amounts of variability), such &lt;em&gt;unbiased&lt;/em&gt; estimates will be unduly influenced by noise. Thus, although traditional regression offers &lt;em&gt;unbiased&lt;/em&gt; estimates, it is also succeptable to estimating large magnitude &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights based purely on noise within the data. Ridge regression minimizes the potential learning from noise by penalizing the model for the squared sum of all the &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights. The squaring of the &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights encodes our knowledge that large-magnitude &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights are much less likely than small-magnitude &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights (given that all our variables are on the same scale after standardization). Practically, this means that if a traditional regression would give us a very large magnitude &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weight, when data are highly variable, ridge regression will &lt;em&gt;bias such large &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; estimates toward 0&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We can actually visualize the effects of the ridge penalty on &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights by plotting out the ridge penalty from equation 4. Specifically, the below plot shows the resulting penalty (where 0 is no penalty and increasingly negative numbers are stronger penalties) for the 2-dimensional case, where we only have 2 predictors. Importantly, the plot also includes the penalty functions for varying settings of &lt;span class=&#34;math inline&#34;&gt;\(\lambda \in \{0, .5, 1.5\}\)&lt;/span&gt;. Note that the flat surface is when &lt;span class=&#34;math inline&#34;&gt;\(\lambda = 0\)&lt;/span&gt;, which leads to no penalization.&lt;/p&gt;
&lt;div id=&#34;6ed64c9e0dfc&#34; style=&#34;width:672px;height:480px;&#34; class=&#34;plotly html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;6ed64c9e0dfc&#34;&gt;{&#34;x&#34;:{&#34;visdat&#34;:{&#34;6ed6734b2d96&#34;:[&#34;function () &#34;,&#34;plotlyVisDat&#34;]},&#34;cur_data&#34;:&#34;6ed6734b2d96&#34;,&#34;attrs&#34;:{&#34;6ed6734b2d96&#34;:{&#34;showscale&#34;:false,&#34;alpha&#34;:1,&#34;sizes&#34;:[10,100],&#34;z&#34;:{},&#34;type&#34;:&#34;surface&#34;,&#34;x&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;y&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;opacity&#34;:0.5},&#34;6ed6734b2d96.1&#34;:{&#34;showscale&#34;:false,&#34;alpha&#34;:1,&#34;sizes&#34;:[10,100],&#34;z&#34;:{},&#34;type&#34;:&#34;surface&#34;,&#34;x&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;y&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3]},&#34;6ed6734b2d96.2&#34;:{&#34;showscale&#34;:false,&#34;alpha&#34;:1,&#34;sizes&#34;:[10,100],&#34;z&#34;:{},&#34;type&#34;:&#34;surface&#34;,&#34;x&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;y&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3]}},&#34;layout&#34;:{&#34;margin&#34;:{&#34;b&#34;:40,&#34;l&#34;:60,&#34;t&#34;:25,&#34;r&#34;:10},&#34;scene&#34;:{&#34;xaxis&#34;:{&#34;title&#34;:&#34;Beta_1&#34;},&#34;yaxis&#34;:{&#34;title&#34;:&#34;Beta_2&#34;},&#34;zaxis&#34;:{&#34;title&#34;:&#34;Penalty&#34;}},&#34;title&#34;:&#34;Ridge Penalty Contour&#34;,&#34;xaxis&#34;:{&#34;domain&#34;:[0,1]},&#34;yaxis&#34;:{&#34;domain&#34;:[0,1]},&#34;hovermode&#34;:&#34;closest&#34;,&#34;showlegend&#34;:true},&#34;source&#34;:&#34;A&#34;,&#34;config&#34;:{&#34;modeBarButtonsToAdd&#34;:[{&#34;name&#34;:&#34;Collaborate&#34;,&#34;icon&#34;:{&#34;width&#34;:1000,&#34;ascent&#34;:500,&#34;descent&#34;:-50,&#34;path&#34;:&#34;M487 375c7-10 9-23 5-36l-79-259c-3-12-11-23-22-31-11-8-22-12-35-12l-263 0c-15 0-29 5-43 15-13 10-23 23-28 37-5 13-5 25-1 37 0 0 0 3 1 7 1 5 1 8 1 11 0 2 0 4-1 6 0 3-1 5-1 6 1 2 2 4 3 6 1 2 2 4 4 6 2 3 4 5 5 7 5 7 9 16 13 26 4 10 7 19 9 26 0 2 0 5 0 9-1 4-1 6 0 8 0 2 2 5 4 8 3 3 5 5 5 7 4 6 8 15 12 26 4 11 7 19 7 26 1 1 0 4 0 9-1 4-1 7 0 8 1 2 3 5 6 8 4 4 6 6 6 7 4 5 8 13 13 24 4 11 7 20 7 28 1 1 0 4 0 7-1 3-1 6-1 7 0 2 1 4 3 6 1 1 3 4 5 6 2 3 3 5 5 6 1 2 3 5 4 9 2 3 3 7 5 10 1 3 2 6 4 10 2 4 4 7 6 9 2 3 4 5 7 7 3 2 7 3 11 3 3 0 8 0 13-1l0-1c7 2 12 2 14 2l218 0c14 0 25-5 32-16 8-10 10-23 6-37l-79-259c-7-22-13-37-20-43-7-7-19-10-37-10l-248 0c-5 0-9-2-11-5-2-3-2-7 0-12 4-13 18-20 41-20l264 0c5 0 10 2 16 5 5 3 8 6 10 11l85 282c2 5 2 10 2 17 7-3 13-7 17-13z m-304 0c-1-3-1-5 0-7 1-1 3-2 6-2l174 0c2 0 4 1 7 2 2 2 4 4 5 7l6 18c0 3 0 5-1 7-1 1-3 2-6 2l-173 0c-3 0-5-1-8-2-2-2-4-4-4-7z m-24-73c-1-3-1-5 0-7 2-2 3-2 6-2l174 0c2 0 5 0 7 2 3 2 4 4 5 7l6 18c1 2 0 5-1 6-1 2-3 3-5 3l-174 0c-3 0-5-1-7-3-3-1-4-4-5-6z&#34;},&#34;click&#34;:&#34;function(gd) { \n        // is this being viewed in RStudio?\n        if (location.search == &#39;?viewer_pane=1&#39;) {\n          alert(&#39;To learn about plotly for collaboration, visit:\\n https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html&#39;);\n        } else {\n          window.open(&#39;https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html&#39;, &#39;_blank&#39;);\n        }\n      }&#34;}],&#34;cloud&#34;:false},&#34;data&#34;:[{&#34;colorbar&#34;:{&#34;title&#34;:&#34;ridge_p1$z&lt;br /&gt;ridge_p2$z&lt;br /&gt;ridge_p3$z&#34;,&#34;ticklen&#34;:2},&#34;colorscale&#34;:[[&#34;0&#34;,&#34;rgba(68,1,84,1)&#34;],[&#34;0.000189933523266812&#34;,&#34;rgba(68,1,84,1)&#34;],[&#34;0.0206303418803419&#34;,&#34;rgba(69,10,91,1)&#34;],[&#34;0.0423646723646724&#34;,&#34;rgba(70,19,97,1)&#34;],[&#34;0.0633926875593542&#34;,&#34;rgba(71,26,104,1)&#34;],[&#34;0.0825356125356126&#34;,&#34;rgba(72,32,111,1)&#34;],[&#34;0.105470085470086&#34;,&#34;rgba(72,38,118,1)&#34;],[&#34;0.124786324786325&#34;,&#34;rgba(71,45,122,1)&#34;],[&#34;0.147763532763533&#34;,&#34;rgba(70,52,126,1)&#34;],[&#34;0.168005698005698&#34;,&#34;rgba(68,58,129,1)&#34;],[&#34;0.190580484330484&#34;,&#34;rgba(66,65,132,1)&#34;],[&#34;0.224700854700855&#34;,&#34;rgba(62,75,137,1)&#34;],[&#34;0.269964387464387&#34;,&#34;rgba(58,87,139,1)&#34;],[&#34;0.332407407407407&#34;,&#34;rgba(49,104,142,1)&#34;],[&#34;0.413760683760684&#34;,&#34;rgba(42,123,142,1)&#34;],[&#34;0.503084045584046&#34;,&#34;rgba(36,145,140,1)&#34;],[&#34;0.618803418803419&#34;,&#34;rgba(46,172,128,1)&#34;],[&#34;1&#34;,&#34;rgba(253,231,37,1)&#34;]],&#34;showscale&#34;:false,&#34;z&#34;:[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]],&#34;type&#34;:&#34;surface&#34;,&#34;x&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;y&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;opacity&#34;:0.5,&#34;frame&#34;:null},{&#34;colorbar&#34;:{&#34;title&#34;:&#34;ridge_p1$z&lt;br /&gt;ridge_p2$z&lt;br /&gt;ridge_p3$z&#34;,&#34;ticklen&#34;:2},&#34;colorscale&#34;:[[&#34;0&#34;,&#34;rgba(68,1,84,1)&#34;],[&#34;0.000189933523266812&#34;,&#34;rgba(68,1,84,1)&#34;],[&#34;0.0206303418803419&#34;,&#34;rgba(69,10,91,1)&#34;],[&#34;0.0423646723646724&#34;,&#34;rgba(70,19,97,1)&#34;],[&#34;0.0633926875593542&#34;,&#34;rgba(71,26,104,1)&#34;],[&#34;0.0825356125356126&#34;,&#34;rgba(72,32,111,1)&#34;],[&#34;0.105470085470086&#34;,&#34;rgba(72,38,118,1)&#34;],[&#34;0.124786324786325&#34;,&#34;rgba(71,45,122,1)&#34;],[&#34;0.147763532763533&#34;,&#34;rgba(70,52,126,1)&#34;],[&#34;0.168005698005698&#34;,&#34;rgba(68,58,129,1)&#34;],[&#34;0.190580484330484&#34;,&#34;rgba(66,65,132,1)&#34;],[&#34;0.224700854700855&#34;,&#34;rgba(62,75,137,1)&#34;],[&#34;0.269964387464387&#34;,&#34;rgba(58,87,139,1)&#34;],[&#34;0.332407407407407&#34;,&#34;rgba(49,104,142,1)&#34;],[&#34;0.413760683760684&#34;,&#34;rgba(42,123,142,1)&#34;],[&#34;0.503084045584046&#34;,&#34;rgba(36,145,140,1)&#34;],[&#34;0.618803418803419&#34;,&#34;rgba(46,172,128,1)&#34;],[&#34;1&#34;,&#34;rgba(253,231,37,1)&#34;]],&#34;showscale&#34;:false,&#34;z&#34;:[[9,8.55153846153846,8.12461538461539,7.72307692307692,7.34384615384615,6.98923076923077,6.65769230769231,6.35,6.06615384615385,5.80538461538462,5.56923076923077,5.35538461538462,5.16692307692308,5,4.85923076923077,4.74,4.64615384615385,4.57461538461538,4.52769230769231,4.50384615384615,4.50384615384615,4.52769230769231,4.57461538461538,4.64615384615385,4.74,4.85923076923077,5,5.16692307692308,5.35538461538462,5.56923076923077,5.80538461538462,6.06615384615385,6.35,6.65769230769231,6.98923076923077,7.34384615384615,7.72307692307692,8.12461538461538,8.55153846153846,9],[8.55153846153846,8.10307692307692,7.67615384615385,7.27461538461538,6.89538461538462,6.54076923076923,6.20923076923077,5.90153846153846,5.61769230769231,5.35692307692308,5.12076923076923,4.90692307692308,4.71846153846154,4.55153846153846,4.41076923076923,4.29153846153846,4.19769230769231,4.12615384615385,4.07923076923077,4.05538461538462,4.05538461538462,4.07923076923077,4.12615384615385,4.19769230769231,4.29153846153846,4.41076923076923,4.55153846153846,4.71846153846154,4.90692307692308,5.12076923076923,5.35692307692308,5.61769230769231,5.90153846153846,6.20923076923077,6.54076923076923,6.89538461538462,7.27461538461538,7.67615384615385,8.10307692307692,8.55153846153846],[8.12461538461538,7.67615384615385,7.24923076923077,6.84769230769231,6.46846153846154,6.11384615384615,5.78230769230769,5.47461538461538,5.19076923076923,4.93,4.69384615384615,4.48,4.29153846153846,4.12461538461539,3.98384615384615,3.86461538461539,3.77076923076923,3.69923076923077,3.65230769230769,3.62846153846154,3.62846153846154,3.65230769230769,3.69923076923077,3.77076923076923,3.86461538461539,3.98384615384615,4.12461538461539,4.29153846153846,4.48,4.69384615384616,4.93,5.19076923076923,5.47461538461539,5.78230769230769,6.11384615384616,6.46846153846154,6.84769230769231,7.24923076923077,7.67615384615385,8.12461538461538],[7.72307692307692,7.27461538461538,6.84769230769231,6.44615384615385,6.06692307692308,5.71230769230769,5.38076923076923,5.07307692307692,4.78923076923077,4.52846153846154,4.29230769230769,4.07846153846154,3.89,3.72307692307692,3.58230769230769,3.46307692307692,3.36923076923077,3.29769230769231,3.25076923076923,3.22692307692308,3.22692307692308,3.25076923076923,3.29769230769231,3.36923076923077,3.46307692307692,3.58230769230769,3.72307692307692,3.89,4.07846153846154,4.29230769230769,4.52846153846154,4.78923076923077,5.07307692307692,5.38076923076923,5.71230769230769,6.06692307692308,6.44615384615385,6.84769230769231,7.27461538461538,7.72307692307692],[7.34384615384615,6.89538461538462,6.46846153846154,6.06692307692308,5.68769230769231,5.33307692307692,5.00153846153846,4.69384615384615,4.41,4.14923076923077,3.91307692307692,3.69923076923077,3.51076923076923,3.34384615384615,3.20307692307692,3.08384615384615,2.99,2.91846153846154,2.87153846153846,2.84769230769231,2.84769230769231,2.87153846153846,2.91846153846154,2.99,3.08384615384615,3.20307692307692,3.34384615384615,3.51076923076923,3.69923076923077,3.91307692307692,4.14923076923077,4.41,4.69384615384615,5.00153846153846,5.33307692307692,5.68769230769231,6.06692307692308,6.46846153846154,6.89538461538462,7.34384615384615],[6.98923076923077,6.54076923076923,6.11384615384616,5.71230769230769,5.33307692307692,4.97846153846154,4.64692307692308,4.33923076923077,4.05538461538462,3.79461538461538,3.55846153846154,3.34461538461538,3.15615384615385,2.98923076923077,2.84846153846154,2.72923076923077,2.63538461538461,2.56384615384615,2.51692307692308,2.49307692307692,2.49307692307692,2.51692307692308,2.56384615384615,2.63538461538462,2.72923076923077,2.84846153846154,2.98923076923077,3.15615384615385,3.34461538461539,3.55846153846154,3.79461538461539,4.05538461538462,4.33923076923077,4.64692307692308,4.97846153846154,5.33307692307692,5.71230769230769,6.11384615384615,6.54076923076923,6.98923076923077],[6.65769230769231,6.20923076923077,5.78230769230769,5.38076923076923,5.00153846153846,4.64692307692308,4.31538461538461,4.00769230769231,3.72384615384615,3.46307692307692,3.22692307692308,3.01307692307692,2.82461538461538,2.65769230769231,2.51692307692308,2.39769230769231,2.30384615384615,2.23230769230769,2.18538461538461,2.16153846153846,2.16153846153846,2.18538461538461,2.23230769230769,2.30384615384615,2.39769230769231,2.51692307692308,2.65769230769231,2.82461538461538,3.01307692307692,3.22692307692308,3.46307692307692,3.72384615384615,4.00769230769231,4.31538461538462,4.64692307692308,5.00153846153846,5.38076923076923,5.78230769230769,6.20923076923077,6.65769230769231],[6.35,5.90153846153846,5.47461538461538,5.07307692307692,4.69384615384615,4.33923076923077,4.00769230769231,3.7,3.41615384615385,3.15538461538462,2.91923076923077,2.70538461538461,2.51692307692308,2.35,2.20923076923077,2.09,1.99615384615385,1.92461538461538,1.87769230769231,1.85384615384615,1.85384615384615,1.87769230769231,1.92461538461538,1.99615384615385,2.09,2.20923076923077,2.35,2.51692307692308,2.70538461538462,2.91923076923077,3.15538461538462,3.41615384615385,3.7,4.00769230769231,4.33923076923077,4.69384615384615,5.07307692307692,5.47461538461538,5.90153846153846,6.35],[6.06615384615385,5.61769230769231,5.19076923076923,4.78923076923077,4.41,4.05538461538462,3.72384615384615,3.41615384615385,3.13230769230769,2.87153846153846,2.63538461538462,2.42153846153846,2.23307692307692,2.06615384615385,1.92538461538461,1.80615384615385,1.71230769230769,1.64076923076923,1.59384615384615,1.57,1.57,1.59384615384615,1.64076923076923,1.71230769230769,1.80615384615385,1.92538461538462,2.06615384615385,2.23307692307692,2.42153846153846,2.63538461538462,2.87153846153846,3.13230769230769,3.41615384615385,3.72384615384615,4.05538461538462,4.41,4.78923076923077,5.19076923076923,5.61769230769231,6.06615384615385],[5.80538461538461,5.35692307692308,4.93,4.52846153846154,4.14923076923077,3.79461538461538,3.46307692307692,3.15538461538462,2.87153846153846,2.61076923076923,2.37461538461538,2.16076923076923,1.97230769230769,1.80538461538462,1.66461538461538,1.54538461538462,1.45153846153846,1.38,1.33307692307692,1.30923076923077,1.30923076923077,1.33307692307692,1.38,1.45153846153846,1.54538461538462,1.66461538461538,1.80538461538462,1.97230769230769,2.16076923076923,2.37461538461538,2.61076923076923,2.87153846153846,3.15538461538462,3.46307692307692,3.79461538461539,4.14923076923077,4.52846153846154,4.93,5.35692307692308,5.80538461538462],[5.56923076923077,5.12076923076923,4.69384615384615,4.29230769230769,3.91307692307692,3.55846153846154,3.22692307692308,2.91923076923077,2.63538461538461,2.37461538461538,2.13846153846154,1.92461538461538,1.73615384615385,1.56923076923077,1.42846153846154,1.30923076923077,1.21538461538462,1.14384615384615,1.09692307692308,1.07307692307692,1.07307692307692,1.09692307692308,1.14384615384615,1.21538461538462,1.30923076923077,1.42846153846154,1.56923076923077,1.73615384615385,1.92461538461539,2.13846153846154,2.37461538461539,2.63538461538461,2.91923076923077,3.22692307692308,3.55846153846154,3.91307692307692,4.29230769230769,4.69384615384615,5.12076923076923,5.56923076923077],[5.35538461538462,4.90692307692308,4.48,4.07846153846154,3.69923076923077,3.34461538461538,3.01307692307692,2.70538461538461,2.42153846153846,2.16076923076923,1.92461538461538,1.71076923076923,1.52230769230769,1.35538461538462,1.21461538461538,1.09538461538461,1.00153846153846,0.93,0.883076923076923,0.859230769230769,0.859230769230769,0.883076923076923,0.93,1.00153846153846,1.09538461538462,1.21461538461538,1.35538461538462,1.52230769230769,1.71076923076923,1.92461538461538,2.16076923076923,2.42153846153846,2.70538461538462,3.01307692307692,3.34461538461538,3.69923076923077,4.07846153846154,4.48,4.90692307692308,5.35538461538462],[5.16692307692308,4.71846153846154,4.29153846153846,3.89,3.51076923076923,3.15615384615385,2.82461538461538,2.51692307692308,2.23307692307692,1.97230769230769,1.73615384615385,1.52230769230769,1.33384615384615,1.16692307692308,1.02615384615385,0.906923076923077,0.813076923076923,0.741538461538461,0.694615384615385,0.670769230769231,0.670769230769231,0.694615384615385,0.741538461538462,0.813076923076923,0.906923076923077,1.02615384615385,1.16692307692308,1.33384615384615,1.52230769230769,1.73615384615385,1.97230769230769,2.23307692307692,2.51692307692308,2.82461538461539,3.15615384615385,3.51076923076923,3.89,4.29153846153846,4.71846153846154,5.16692307692308],[5,4.55153846153846,4.12461538461539,3.72307692307692,3.34384615384615,2.98923076923077,2.65769230769231,2.35,2.06615384615385,1.80538461538462,1.56923076923077,1.35538461538462,1.16692307692308,1,0.859230769230769,0.74,0.646153846153846,0.574615384615385,0.527692307692308,0.503846153846154,0.503846153846154,0.527692307692308,0.574615384615385,0.646153846153846,0.74,0.859230769230769,1,1.16692307692308,1.35538461538462,1.56923076923077,1.80538461538462,2.06615384615385,2.35,2.65769230769231,2.98923076923077,3.34384615384615,3.72307692307692,4.12461538461539,4.55153846153846,5],[4.85923076923077,4.41076923076923,3.98384615384615,3.58230769230769,3.20307692307692,2.84846153846154,2.51692307692308,2.20923076923077,1.92538461538461,1.66461538461538,1.42846153846154,1.21461538461538,1.02615384615385,0.859230769230769,0.718461538461538,0.599230769230769,0.505384615384615,0.433846153846154,0.386923076923077,0.363076923076923,0.363076923076923,0.386923076923077,0.433846153846154,0.505384615384615,0.599230769230769,0.718461538461538,0.859230769230769,1.02615384615385,1.21461538461539,1.42846153846154,1.66461538461539,1.92538461538462,2.20923076923077,2.51692307692308,2.84846153846154,3.20307692307692,3.58230769230769,3.98384615384615,4.41076923076923,4.85923076923077],[4.74,4.29153846153846,3.86461538461539,3.46307692307692,3.08384615384615,2.72923076923077,2.39769230769231,2.09,1.80615384615385,1.54538461538462,1.30923076923077,1.09538461538462,0.906923076923077,0.74,0.599230769230769,0.48,0.386153846153846,0.314615384615384,0.267692307692308,0.243846153846154,0.243846153846154,0.267692307692308,0.314615384615385,0.386153846153846,0.48,0.599230769230769,0.74,0.906923076923077,1.09538461538462,1.30923076923077,1.54538461538462,1.80615384615385,2.09,2.39769230769231,2.72923076923077,3.08384615384615,3.46307692307692,3.86461538461539,4.29153846153846,4.74],[4.64615384615385,4.19769230769231,3.77076923076923,3.36923076923077,2.99,2.63538461538462,2.30384615384615,1.99615384615385,1.71230769230769,1.45153846153846,1.21538461538462,1.00153846153846,0.813076923076923,0.646153846153846,0.505384615384615,0.386153846153846,0.292307692307692,0.220769230769231,0.173846153846154,0.15,0.15,0.173846153846154,0.220769230769231,0.292307692307692,0.386153846153846,0.505384615384615,0.646153846153846,0.813076923076923,1.00153846153846,1.21538461538462,1.45153846153846,1.71230769230769,1.99615384615385,2.30384615384615,2.63538461538462,2.99,3.36923076923077,3.77076923076923,4.19769230769231,4.64615384615385],[4.57461538461538,4.12615384615385,3.69923076923077,3.29769230769231,2.91846153846154,2.56384615384615,2.23230769230769,1.92461538461538,1.64076923076923,1.38,1.14384615384615,0.93,0.741538461538461,0.574615384615385,0.433846153846153,0.314615384615384,0.220769230769231,0.149230769230769,0.102307692307692,0.0784615384615384,0.0784615384615384,0.102307692307692,0.149230769230769,0.220769230769231,0.314615384615385,0.433846153846154,0.574615384615385,0.741538461538462,0.930000000000001,1.14384615384615,1.38,1.64076923076923,1.92461538461539,2.23230769230769,2.56384615384615,2.91846153846154,3.29769230769231,3.69923076923077,4.12615384615385,4.57461538461538],[4.52769230769231,4.07923076923077,3.65230769230769,3.25076923076923,2.87153846153846,2.51692307692308,2.18538461538461,1.87769230769231,1.59384615384615,1.33307692307692,1.09692307692308,0.883076923076923,0.694615384615385,0.527692307692308,0.386923076923077,0.267692307692308,0.173846153846154,0.102307692307692,0.0553846153846154,0.0315384615384615,0.0315384615384616,0.0553846153846154,0.102307692307692,0.173846153846154,0.267692307692308,0.386923076923077,0.527692307692308,0.694615384615385,0.883076923076924,1.09692307692308,1.33307692307692,1.59384615384615,1.87769230769231,2.18538461538462,2.51692307692308,2.87153846153846,3.25076923076923,3.65230769230769,4.07923076923077,4.52769230769231],[4.50384615384615,4.05538461538462,3.62846153846154,3.22692307692308,2.84769230769231,2.49307692307692,2.16153846153846,1.85384615384615,1.57,1.30923076923077,1.07307692307692,0.859230769230769,0.670769230769231,0.503846153846154,0.363076923076923,0.243846153846154,0.15,0.0784615384615384,0.0315384615384615,0.00769230769230764,0.00769230769230768,0.0315384615384615,0.0784615384615386,0.15,0.243846153846154,0.363076923076923,0.503846153846154,0.670769230769231,0.85923076923077,1.07307692307692,1.30923076923077,1.57,1.85384615384615,2.16153846153846,2.49307692307692,2.84769230769231,3.22692307692308,3.62846153846154,4.05538461538462,4.50384615384615],[4.50384615384615,4.05538461538462,3.62846153846154,3.22692307692308,2.84769230769231,2.49307692307692,2.16153846153846,1.85384615384615,1.57,1.30923076923077,1.07307692307692,0.859230769230769,0.670769230769231,0.503846153846154,0.363076923076923,0.243846153846154,0.15,0.0784615384615385,0.0315384615384616,0.00769230769230768,0.00769230769230772,0.0315384615384616,0.0784615384615386,0.15,0.243846153846154,0.363076923076923,0.503846153846154,0.670769230769231,0.85923076923077,1.07307692307692,1.30923076923077,1.57,1.85384615384615,2.16153846153846,2.49307692307692,2.84769230769231,3.22692307692308,3.62846153846154,4.05538461538462,4.50384615384615],[4.52769230769231,4.07923076923077,3.65230769230769,3.25076923076923,2.87153846153846,2.51692307692308,2.18538461538461,1.87769230769231,1.59384615384615,1.33307692307692,1.09692307692308,0.883076923076923,0.694615384615385,0.527692307692308,0.386923076923077,0.267692307692308,0.173846153846154,0.102307692307692,0.0553846153846154,0.0315384615384615,0.0315384615384616,0.0553846153846154,0.102307692307692,0.173846153846154,0.267692307692308,0.386923076923077,0.527692307692308,0.694615384615385,0.883076923076924,1.09692307692308,1.33307692307692,1.59384615384615,1.87769230769231,2.18538461538462,2.51692307692308,2.87153846153846,3.25076923076923,3.65230769230769,4.07923076923077,4.52769230769231],[4.57461538461539,4.12615384615385,3.69923076923077,3.29769230769231,2.91846153846154,2.56384615384615,2.23230769230769,1.92461538461538,1.64076923076923,1.38,1.14384615384615,0.93,0.741538461538462,0.574615384615385,0.433846153846154,0.314615384615385,0.220769230769231,0.149230769230769,0.102307692307692,0.0784615384615386,0.0784615384615386,0.102307692307692,0.14923076923077,0.220769230769231,0.314615384615385,0.433846153846154,0.574615384615385,0.741538461538462,0.930000000000001,1.14384615384615,1.38,1.64076923076923,1.92461538461539,2.23230769230769,2.56384615384615,2.91846153846154,3.29769230769231,3.69923076923077,4.12615384615385,4.57461538461538],[4.64615384615385,4.19769230769231,3.77076923076923,3.36923076923077,2.99,2.63538461538462,2.30384615384615,1.99615384615385,1.71230769230769,1.45153846153846,1.21538461538462,1.00153846153846,0.813076923076923,0.646153846153846,0.505384615384615,0.386153846153846,0.292307692307692,0.220769230769231,0.173846153846154,0.15,0.15,0.173846153846154,0.220769230769231,0.292307692307693,0.386153846153846,0.505384615384616,0.646153846153846,0.813076923076924,1.00153846153846,1.21538461538462,1.45153846153846,1.71230769230769,1.99615384615385,2.30384615384616,2.63538461538462,2.99,3.36923076923077,3.77076923076923,4.19769230769231,4.64615384615385],[4.74,4.29153846153846,3.86461538461539,3.46307692307692,3.08384615384615,2.72923076923077,2.39769230769231,2.09,1.80615384615385,1.54538461538462,1.30923076923077,1.09538461538462,0.906923076923077,0.74,0.599230769230769,0.48,0.386153846153846,0.314615384615385,0.267692307692308,0.243846153846154,0.243846153846154,0.267692307692308,0.314615384615385,0.386153846153846,0.48,0.599230769230769,0.74,0.906923076923077,1.09538461538462,1.30923076923077,1.54538461538462,1.80615384615385,2.09,2.39769230769231,2.72923076923077,3.08384615384615,3.46307692307692,3.86461538461539,4.29153846153846,4.74],[4.85923076923077,4.41076923076923,3.98384615384615,3.58230769230769,3.20307692307692,2.84846153846154,2.51692307692308,2.20923076923077,1.92538461538462,1.66461538461538,1.42846153846154,1.21461538461538,1.02615384615385,0.859230769230769,0.718461538461538,0.599230769230769,0.505384615384615,0.433846153846154,0.386923076923077,0.363076923076923,0.363076923076923,0.386923076923077,0.433846153846154,0.505384615384616,0.599230769230769,0.718461538461539,0.859230769230769,1.02615384615385,1.21461538461539,1.42846153846154,1.66461538461539,1.92538461538462,2.20923076923077,2.51692307692308,2.84846153846154,3.20307692307692,3.58230769230769,3.98384615384615,4.41076923076923,4.85923076923077],[5,4.55153846153846,4.12461538461539,3.72307692307692,3.34384615384615,2.98923076923077,2.65769230769231,2.35,2.06615384615385,1.80538461538462,1.56923076923077,1.35538461538462,1.16692307692308,1,0.859230769230769,0.74,0.646153846153846,0.574615384615385,0.527692307692308,0.503846153846154,0.503846153846154,0.527692307692308,0.574615384615385,0.646153846153846,0.74,0.859230769230769,1,1.16692307692308,1.35538461538462,1.56923076923077,1.80538461538462,2.06615384615385,2.35,2.65769230769231,2.98923076923077,3.34384615384615,3.72307692307692,4.12461538461539,4.55153846153846,5],[5.16692307692308,4.71846153846154,4.29153846153846,3.89,3.51076923076923,3.15615384615385,2.82461538461538,2.51692307692308,2.23307692307692,1.97230769230769,1.73615384615385,1.52230769230769,1.33384615384615,1.16692307692308,1.02615384615385,0.906923076923077,0.813076923076923,0.741538461538462,0.694615384615385,0.670769230769231,0.670769230769231,0.694615384615385,0.741538461538462,0.813076923076924,0.906923076923077,1.02615384615385,1.16692307692308,1.33384615384615,1.52230769230769,1.73615384615385,1.97230769230769,2.23307692307692,2.51692307692308,2.82461538461539,3.15615384615385,3.51076923076923,3.89,4.29153846153846,4.71846153846154,5.16692307692308],[5.35538461538462,4.90692307692308,4.48,4.07846153846154,3.69923076923077,3.34461538461539,3.01307692307692,2.70538461538462,2.42153846153846,2.16076923076923,1.92461538461539,1.71076923076923,1.52230769230769,1.35538461538462,1.21461538461539,1.09538461538462,1.00153846153846,0.930000000000001,0.883076923076924,0.85923076923077,0.85923076923077,0.883076923076924,0.930000000000001,1.00153846153846,1.09538461538462,1.21461538461539,1.35538461538462,1.52230769230769,1.71076923076923,1.92461538461539,2.16076923076923,2.42153846153846,2.70538461538462,3.01307692307692,3.34461538461539,3.69923076923077,4.07846153846154,4.48,4.90692307692308,5.35538461538462],[5.56923076923077,5.12076923076923,4.69384615384615,4.29230769230769,3.91307692307692,3.55846153846154,3.22692307692308,2.91923076923077,2.63538461538462,2.37461538461538,2.13846153846154,1.92461538461538,1.73615384615385,1.56923076923077,1.42846153846154,1.30923076923077,1.21538461538462,1.14384615384615,1.09692307692308,1.07307692307692,1.07307692307692,1.09692307692308,1.14384615384615,1.21538461538462,1.30923076923077,1.42846153846154,1.56923076923077,1.73615384615385,1.92461538461539,2.13846153846154,2.37461538461539,2.63538461538461,2.91923076923077,3.22692307692308,3.55846153846154,3.91307692307692,4.29230769230769,4.69384615384615,5.12076923076923,5.56923076923077],[5.80538461538462,5.35692307692308,4.93,4.52846153846154,4.14923076923077,3.79461538461539,3.46307692307692,3.15538461538462,2.87153846153846,2.61076923076923,2.37461538461539,2.16076923076923,1.97230769230769,1.80538461538462,1.66461538461539,1.54538461538462,1.45153846153846,1.38,1.33307692307692,1.30923076923077,1.30923076923077,1.33307692307692,1.38,1.45153846153846,1.54538461538462,1.66461538461539,1.80538461538462,1.97230769230769,2.16076923076923,2.37461538461539,2.61076923076923,2.87153846153846,3.15538461538462,3.46307692307693,3.79461538461539,4.14923076923077,4.52846153846154,4.93,5.35692307692308,5.80538461538462],[6.06615384615385,5.61769230769231,5.19076923076923,4.78923076923077,4.41,4.05538461538462,3.72384615384615,3.41615384615385,3.13230769230769,2.87153846153846,2.63538461538461,2.42153846153846,2.23307692307692,2.06615384615385,1.92538461538462,1.80615384615385,1.71230769230769,1.64076923076923,1.59384615384615,1.57,1.57,1.59384615384615,1.64076923076923,1.71230769230769,1.80615384615385,1.92538461538462,2.06615384615385,2.23307692307692,2.42153846153846,2.63538461538462,2.87153846153846,3.13230769230769,3.41615384615385,3.72384615384615,4.05538461538462,4.41,4.78923076923077,5.19076923076923,5.61769230769231,6.06615384615385],[6.35,5.90153846153846,5.47461538461539,5.07307692307692,4.69384615384615,4.33923076923077,4.00769230769231,3.7,3.41615384615385,3.15538461538462,2.91923076923077,2.70538461538462,2.51692307692308,2.35,2.20923076923077,2.09,1.99615384615385,1.92461538461539,1.87769230769231,1.85384615384615,1.85384615384615,1.87769230769231,1.92461538461539,1.99615384615385,2.09,2.20923076923077,2.35,2.51692307692308,2.70538461538462,2.91923076923077,3.15538461538462,3.41615384615385,3.7,4.00769230769231,4.33923076923077,4.69384615384616,5.07307692307692,5.47461538461538,5.90153846153846,6.35],[6.65769230769231,6.20923076923077,5.78230769230769,5.38076923076923,5.00153846153846,4.64692307692308,4.31538461538462,4.00769230769231,3.72384615384615,3.46307692307692,3.22692307692308,3.01307692307692,2.82461538461539,2.65769230769231,2.51692307692308,2.39769230769231,2.30384615384615,2.23230769230769,2.18538461538462,2.16153846153846,2.16153846153846,2.18538461538462,2.23230769230769,2.30384615384616,2.39769230769231,2.51692307692308,2.65769230769231,2.82461538461539,3.01307692307692,3.22692307692308,3.46307692307693,3.72384615384615,4.00769230769231,4.31538461538462,4.64692307692308,5.00153846153846,5.38076923076923,5.78230769230769,6.20923076923077,6.65769230769231],[6.98923076923077,6.54076923076923,6.11384615384616,5.71230769230769,5.33307692307692,4.97846153846154,4.64692307692308,4.33923076923077,4.05538461538462,3.79461538461538,3.55846153846154,3.34461538461538,3.15615384615385,2.98923076923077,2.84846153846154,2.72923076923077,2.63538461538462,2.56384615384615,2.51692307692308,2.49307692307692,2.49307692307692,2.51692307692308,2.56384615384615,2.63538461538462,2.72923076923077,2.84846153846154,2.98923076923077,3.15615384615385,3.34461538461539,3.55846153846154,3.79461538461539,4.05538461538462,4.33923076923077,4.64692307692308,4.97846153846154,5.33307692307692,5.71230769230769,6.11384615384616,6.54076923076923,6.98923076923077],[7.34384615384615,6.89538461538462,6.46846153846154,6.06692307692308,5.68769230769231,5.33307692307692,5.00153846153846,4.69384615384615,4.41,4.14923076923077,3.91307692307692,3.69923076923077,3.51076923076923,3.34384615384615,3.20307692307692,3.08384615384615,2.99,2.91846153846154,2.87153846153846,2.84769230769231,2.84769230769231,2.87153846153846,2.91846153846154,2.99,3.08384615384615,3.20307692307692,3.34384615384615,3.51076923076923,3.69923076923077,3.91307692307692,4.14923076923077,4.41,4.69384615384616,5.00153846153846,5.33307692307692,5.68769230769231,6.06692307692308,6.46846153846154,6.89538461538462,7.34384615384615],[7.72307692307692,7.27461538461538,6.84769230769231,6.44615384615385,6.06692307692308,5.71230769230769,5.38076923076923,5.07307692307692,4.78923076923077,4.52846153846154,4.29230769230769,4.07846153846154,3.89,3.72307692307692,3.58230769230769,3.46307692307692,3.36923076923077,3.29769230769231,3.25076923076923,3.22692307692308,3.22692307692308,3.25076923076923,3.29769230769231,3.36923076923077,3.46307692307692,3.58230769230769,3.72307692307692,3.89,4.07846153846154,4.29230769230769,4.52846153846154,4.78923076923077,5.07307692307692,5.38076923076923,5.71230769230769,6.06692307692308,6.44615384615385,6.84769230769231,7.27461538461539,7.72307692307692],[8.12461538461538,7.67615384615385,7.24923076923077,6.84769230769231,6.46846153846154,6.11384615384616,5.78230769230769,5.47461538461538,5.19076923076923,4.93,4.69384615384615,4.48,4.29153846153846,4.12461538461539,3.98384615384615,3.86461538461539,3.77076923076923,3.69923076923077,3.65230769230769,3.62846153846154,3.62846153846154,3.65230769230769,3.69923076923077,3.77076923076923,3.86461538461539,3.98384615384615,4.12461538461539,4.29153846153846,4.48,4.69384615384615,4.93,5.19076923076923,5.47461538461539,5.78230769230769,6.11384615384616,6.46846153846154,6.84769230769231,7.24923076923077,7.67615384615385,8.12461538461538],[8.55153846153846,8.10307692307692,7.67615384615385,7.27461538461539,6.89538461538462,6.54076923076923,6.20923076923077,5.90153846153846,5.61769230769231,5.35692307692308,5.12076923076923,4.90692307692308,4.71846153846154,4.55153846153846,4.41076923076923,4.29153846153846,4.19769230769231,4.12615384615385,4.07923076923077,4.05538461538462,4.05538461538462,4.07923076923077,4.12615384615385,4.19769230769231,4.29153846153846,4.41076923076923,4.55153846153846,4.71846153846154,4.90692307692308,5.12076923076923,5.35692307692308,5.61769230769231,5.90153846153846,6.20923076923077,6.54076923076923,6.89538461538462,7.27461538461539,7.67615384615385,8.10307692307693,8.55153846153846],[9,8.55153846153846,8.12461538461539,7.72307692307692,7.34384615384615,6.98923076923077,6.65769230769231,6.35,6.06615384615385,5.80538461538462,5.56923076923077,5.35538461538462,5.16692307692308,5,4.85923076923077,4.74,4.64615384615385,4.57461538461538,4.52769230769231,4.50384615384615,4.50384615384615,4.52769230769231,4.57461538461539,4.64615384615385,4.74,4.85923076923077,5,5.16692307692308,5.35538461538462,5.56923076923077,5.80538461538462,6.06615384615385,6.35,6.65769230769231,6.98923076923077,7.34384615384615,7.72307692307692,8.12461538461538,8.55153846153846,9]],&#34;type&#34;:&#34;surface&#34;,&#34;x&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;y&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;frame&#34;:null},{&#34;colorbar&#34;:{&#34;title&#34;:&#34;ridge_p1$z&lt;br /&gt;ridge_p2$z&lt;br /&gt;ridge_p3$z&#34;,&#34;ticklen&#34;:2},&#34;colorscale&#34;:[[&#34;0&#34;,&#34;rgba(68,1,84,1)&#34;],[&#34;0.000189933523266812&#34;,&#34;rgba(68,1,84,1)&#34;],[&#34;0.0206303418803419&#34;,&#34;rgba(69,10,91,1)&#34;],[&#34;0.0423646723646724&#34;,&#34;rgba(70,19,97,1)&#34;],[&#34;0.0633926875593542&#34;,&#34;rgba(71,26,104,1)&#34;],[&#34;0.0825356125356126&#34;,&#34;rgba(72,32,111,1)&#34;],[&#34;0.105470085470086&#34;,&#34;rgba(72,38,118,1)&#34;],[&#34;0.124786324786325&#34;,&#34;rgba(71,45,122,1)&#34;],[&#34;0.147763532763533&#34;,&#34;rgba(70,52,126,1)&#34;],[&#34;0.168005698005698&#34;,&#34;rgba(68,58,129,1)&#34;],[&#34;0.190580484330484&#34;,&#34;rgba(66,65,132,1)&#34;],[&#34;0.224700854700855&#34;,&#34;rgba(62,75,137,1)&#34;],[&#34;0.269964387464387&#34;,&#34;rgba(58,87,139,1)&#34;],[&#34;0.332407407407407&#34;,&#34;rgba(49,104,142,1)&#34;],[&#34;0.413760683760684&#34;,&#34;rgba(42,123,142,1)&#34;],[&#34;0.503084045584046&#34;,&#34;rgba(36,145,140,1)&#34;],[&#34;0.618803418803419&#34;,&#34;rgba(46,172,128,1)&#34;],[&#34;1&#34;,&#34;rgba(253,231,37,1)&#34;]],&#34;showscale&#34;:false,&#34;z&#34;:[[27,25.6546153846154,24.3738461538462,23.1692307692308,22.0315384615385,20.9676923076923,19.9730769230769,19.05,18.1984615384615,17.4161538461538,16.7076923076923,16.0661538461538,15.5007692307692,15,14.5776923076923,14.22,13.9384615384615,13.7238461538462,13.5830769230769,13.5115384615385,13.5115384615385,13.5830769230769,13.7238461538462,13.9384615384615,14.22,14.5776923076923,15,15.5007692307692,16.0661538461538,16.7076923076923,17.4161538461539,18.1984615384615,19.05,19.9730769230769,20.9676923076923,22.0315384615385,23.1692307692308,24.3738461538462,25.6546153846154,27],[25.6546153846154,24.3092307692308,23.0284615384615,21.8238461538462,20.6861538461538,19.6223076923077,18.6276923076923,17.7046153846154,16.8530769230769,16.0707692307692,15.3623076923077,14.7207692307692,14.1553846153846,13.6546153846154,13.2323076923077,12.8746153846154,12.5930769230769,12.3784615384615,12.2376923076923,12.1661538461538,12.1661538461538,12.2376923076923,12.3784615384615,12.5930769230769,12.8746153846154,13.2323076923077,13.6546153846154,14.1553846153846,14.7207692307692,15.3623076923077,16.0707692307692,16.8530769230769,17.7046153846154,18.6276923076923,19.6223076923077,20.6861538461539,21.8238461538462,23.0284615384615,24.3092307692308,25.6546153846154],[24.3738461538462,23.0284615384615,21.7476923076923,20.5430769230769,19.4053846153846,18.3415384615385,17.3469230769231,16.4238461538462,15.5723076923077,14.79,14.0815384615385,13.44,12.8746153846154,12.3738461538462,11.9515384615385,11.5938461538462,11.3123076923077,11.0976923076923,10.9569230769231,10.8853846153846,10.8853846153846,10.9569230769231,11.0976923076923,11.3123076923077,11.5938461538462,11.9515384615385,12.3738461538462,12.8746153846154,13.44,14.0815384615385,14.79,15.5723076923077,16.4238461538462,17.3469230769231,18.3415384615385,19.4053846153846,20.5430769230769,21.7476923076923,23.0284615384615,24.3738461538462],[23.1692307692308,21.8238461538462,20.5430769230769,19.3384615384615,18.2007692307692,17.1369230769231,16.1423076923077,15.2192307692308,14.3676923076923,13.5853846153846,12.8769230769231,12.2353846153846,11.67,11.1692307692308,10.7469230769231,10.3892307692308,10.1076923076923,9.89307692307692,9.75230769230769,9.68076923076923,9.68076923076923,9.75230769230769,9.89307692307692,10.1076923076923,10.3892307692308,10.7469230769231,11.1692307692308,11.67,12.2353846153846,12.8769230769231,13.5853846153846,14.3676923076923,15.2192307692308,16.1423076923077,17.1369230769231,18.2007692307692,19.3384615384615,20.5430769230769,21.8238461538462,23.1692307692308],[22.0315384615385,20.6861538461539,19.4053846153846,18.2007692307692,17.0630769230769,15.9992307692308,15.0046153846154,14.0815384615385,13.23,12.4476923076923,11.7392307692308,11.0976923076923,10.5323076923077,10.0315384615385,9.60923076923077,9.25153846153846,8.97,8.75538461538462,8.61461538461539,8.54307692307692,8.54307692307692,8.61461538461538,8.75538461538462,8.97,9.25153846153846,9.60923076923077,10.0315384615385,10.5323076923077,11.0976923076923,11.7392307692308,12.4476923076923,13.23,14.0815384615385,15.0046153846154,15.9992307692308,17.0630769230769,18.2007692307692,19.4053846153846,20.6861538461539,22.0315384615385],[20.9676923076923,19.6223076923077,18.3415384615385,17.1369230769231,15.9992307692308,14.9353846153846,13.9407692307692,13.0176923076923,12.1661538461538,11.3838461538462,10.6753846153846,10.0338461538462,9.46846153846154,8.96769230769231,8.54538461538461,8.18769230769231,7.90615384615385,7.69153846153846,7.55076923076923,7.47923076923077,7.47923076923077,7.55076923076923,7.69153846153846,7.90615384615385,8.18769230769231,8.54538461538461,8.96769230769231,9.46846153846154,10.0338461538462,10.6753846153846,11.3838461538462,12.1661538461538,13.0176923076923,13.9407692307692,14.9353846153846,15.9992307692308,17.1369230769231,18.3415384615385,19.6223076923077,20.9676923076923],[19.9730769230769,18.6276923076923,17.3469230769231,16.1423076923077,15.0046153846154,13.9407692307692,12.9461538461538,12.0230769230769,11.1715384615385,10.3892307692308,9.68076923076923,9.03923076923077,8.47384615384615,7.97307692307692,7.55076923076923,7.19307692307692,6.91153846153846,6.69692307692307,6.55615384615384,6.48461538461538,6.48461538461538,6.55615384615384,6.69692307692307,6.91153846153846,7.19307692307692,7.55076923076923,7.97307692307692,8.47384615384615,9.03923076923077,9.68076923076923,10.3892307692308,11.1715384615385,12.0230769230769,12.9461538461538,13.9407692307692,15.0046153846154,16.1423076923077,17.3469230769231,18.6276923076923,19.9730769230769],[19.05,17.7046153846154,16.4238461538462,15.2192307692308,14.0815384615385,13.0176923076923,12.0230769230769,11.1,10.2484615384615,9.46615384615385,8.75769230769231,8.11615384615384,7.55076923076923,7.05,6.62769230769231,6.27,5.98846153846154,5.77384615384615,5.63307692307692,5.56153846153846,5.56153846153846,5.63307692307692,5.77384615384615,5.98846153846154,6.27,6.62769230769231,7.05,7.55076923076923,8.11615384615385,8.75769230769231,9.46615384615385,10.2484615384615,11.1,12.0230769230769,13.0176923076923,14.0815384615385,15.2192307692308,16.4238461538462,17.7046153846154,19.05],[18.1984615384615,16.8530769230769,15.5723076923077,14.3676923076923,13.23,12.1661538461538,11.1715384615385,10.2484615384615,9.39692307692308,8.61461538461538,7.90615384615385,7.26461538461538,6.69923076923077,6.19846153846154,5.77615384615384,5.41846153846154,5.13692307692308,4.92230769230769,4.78153846153846,4.71,4.71,4.78153846153846,4.92230769230769,5.13692307692308,5.41846153846154,5.77615384615385,6.19846153846154,6.69923076923077,7.26461538461539,7.90615384615385,8.61461538461539,9.39692307692308,10.2484615384615,11.1715384615385,12.1661538461538,13.23,14.3676923076923,15.5723076923077,16.8530769230769,18.1984615384615],[17.4161538461538,16.0707692307692,14.79,13.5853846153846,12.4476923076923,11.3838461538462,10.3892307692308,9.46615384615385,8.61461538461539,7.83230769230769,7.12384615384615,6.48230769230769,5.91692307692308,5.41615384615385,4.99384615384615,4.63615384615385,4.35461538461538,4.14,3.99923076923077,3.92769230769231,3.92769230769231,3.99923076923077,4.14,4.35461538461539,4.63615384615385,4.99384615384615,5.41615384615385,5.91692307692308,6.48230769230769,7.12384615384615,7.83230769230769,8.61461538461538,9.46615384615385,10.3892307692308,11.3838461538462,12.4476923076923,13.5853846153846,14.79,16.0707692307692,17.4161538461538],[16.7076923076923,15.3623076923077,14.0815384615385,12.8769230769231,11.7392307692308,10.6753846153846,9.68076923076923,8.75769230769231,7.90615384615385,7.12384615384615,6.41538461538461,5.77384615384615,5.20846153846154,4.70769230769231,4.28538461538461,3.92769230769231,3.64615384615385,3.43153846153846,3.29076923076923,3.21923076923077,3.21923076923077,3.29076923076923,3.43153846153846,3.64615384615385,3.92769230769231,4.28538461538461,4.70769230769231,5.20846153846154,5.77384615384616,6.41538461538462,7.12384615384616,7.90615384615385,8.75769230769231,9.68076923076923,10.6753846153846,11.7392307692308,12.8769230769231,14.0815384615385,15.3623076923077,16.7076923076923],[16.0661538461538,14.7207692307692,13.44,12.2353846153846,11.0976923076923,10.0338461538462,9.03923076923077,8.11615384615384,7.26461538461538,6.48230769230769,5.77384615384615,5.13230769230769,4.56692307692308,4.06615384615385,3.64384615384615,3.28615384615384,3.00461538461538,2.79,2.64923076923077,2.57769230769231,2.57769230769231,2.64923076923077,2.79,3.00461538461538,3.28615384615385,3.64384615384615,4.06615384615385,4.56692307692308,5.13230769230769,5.77384615384615,6.48230769230769,7.26461538461538,8.11615384615385,9.03923076923077,10.0338461538462,11.0976923076923,12.2353846153846,13.44,14.7207692307692,16.0661538461538],[15.5007692307692,14.1553846153846,12.8746153846154,11.67,10.5323076923077,9.46846153846154,8.47384615384615,7.55076923076923,6.69923076923077,5.91692307692308,5.20846153846154,4.56692307692308,4.00153846153846,3.50076923076923,3.07846153846154,2.72076923076923,2.43923076923077,2.22461538461538,2.08384615384615,2.01230769230769,2.01230769230769,2.08384615384615,2.22461538461538,2.43923076923077,2.72076923076923,3.07846153846154,3.50076923076923,4.00153846153846,4.56692307692308,5.20846153846154,5.91692307692308,6.69923076923077,7.55076923076923,8.47384615384616,9.46846153846154,10.5323076923077,11.67,12.8746153846154,14.1553846153846,15.5007692307692],[15,13.6546153846154,12.3738461538462,11.1692307692308,10.0315384615385,8.96769230769231,7.97307692307692,7.05,6.19846153846154,5.41615384615385,4.70769230769231,4.06615384615385,3.50076923076923,3,2.57769230769231,2.22,1.93846153846154,1.72384615384615,1.58307692307692,1.51153846153846,1.51153846153846,1.58307692307692,1.72384615384615,1.93846153846154,2.22,2.57769230769231,3,3.50076923076923,4.06615384615385,4.70769230769231,5.41615384615385,6.19846153846154,7.05,7.97307692307693,8.96769230769231,10.0315384615385,11.1692307692308,12.3738461538462,13.6546153846154,15],[14.5776923076923,13.2323076923077,11.9515384615385,10.7469230769231,9.60923076923077,8.54538461538461,7.55076923076923,6.62769230769231,5.77615384615384,4.99384615384615,4.28538461538461,3.64384615384615,3.07846153846154,2.57769230769231,2.15538461538461,1.79769230769231,1.51615384615385,1.30153846153846,1.16076923076923,1.08923076923077,1.08923076923077,1.16076923076923,1.30153846153846,1.51615384615385,1.79769230769231,2.15538461538462,2.57769230769231,3.07846153846154,3.64384615384616,4.28538461538461,4.99384615384616,5.77615384615384,6.62769230769231,7.55076923076923,8.54538461538462,9.60923076923077,10.7469230769231,11.9515384615385,13.2323076923077,14.5776923076923],[14.22,12.8746153846154,11.5938461538462,10.3892307692308,9.25153846153846,8.18769230769231,7.19307692307692,6.27,5.41846153846154,4.63615384615385,3.92769230769231,3.28615384615384,2.72076923076923,2.22,1.79769230769231,1.44,1.15846153846154,0.943846153846153,0.803076923076923,0.731538461538461,0.731538461538461,0.803076923076923,0.943846153846154,1.15846153846154,1.44,1.79769230769231,2.22,2.72076923076923,3.28615384615385,3.92769230769231,4.63615384615385,5.41846153846154,6.27,7.19307692307692,8.18769230769231,9.25153846153846,10.3892307692308,11.5938461538462,12.8746153846154,14.22],[13.9384615384615,12.5930769230769,11.3123076923077,10.1076923076923,8.97,7.90615384615385,6.91153846153846,5.98846153846154,5.13692307692308,4.35461538461538,3.64615384615385,3.00461538461538,2.43923076923077,1.93846153846154,1.51615384615385,1.15846153846154,0.876923076923076,0.662307692307692,0.521538461538461,0.45,0.45,0.521538461538461,0.662307692307693,0.876923076923077,1.15846153846154,1.51615384615385,1.93846153846154,2.43923076923077,3.00461538461539,3.64615384615385,4.35461538461539,5.13692307692308,5.98846153846154,6.91153846153846,7.90615384615385,8.97,10.1076923076923,11.3123076923077,12.5930769230769,13.9384615384615],[13.7238461538462,12.3784615384615,11.0976923076923,9.89307692307692,8.75538461538461,7.69153846153846,6.69692307692308,5.77384615384615,4.92230769230769,4.14,3.43153846153846,2.79,2.22461538461538,1.72384615384615,1.30153846153846,0.943846153846153,0.662307692307692,0.447692307692308,0.306923076923077,0.235384615384615,0.235384615384615,0.306923076923077,0.447692307692308,0.662307692307693,0.943846153846154,1.30153846153846,1.72384615384615,2.22461538461539,2.79,3.43153846153846,4.14,4.92230769230769,5.77384615384616,6.69692307692308,7.69153846153846,8.75538461538462,9.89307692307692,11.0976923076923,12.3784615384615,13.7238461538462],[13.5830769230769,12.2376923076923,10.9569230769231,9.75230769230769,8.61461538461538,7.55076923076923,6.55615384615384,5.63307692307692,4.78153846153846,3.99923076923077,3.29076923076923,2.64923076923077,2.08384615384615,1.58307692307692,1.16076923076923,0.803076923076923,0.521538461538461,0.306923076923077,0.166153846153846,0.0946153846153846,0.0946153846153847,0.166153846153846,0.306923076923077,0.521538461538462,0.803076923076924,1.16076923076923,1.58307692307692,2.08384615384615,2.64923076923077,3.29076923076923,3.99923076923077,4.78153846153846,5.63307692307692,6.55615384615385,7.55076923076923,8.61461538461539,9.75230769230769,10.9569230769231,12.2376923076923,13.5830769230769],[13.5115384615385,12.1661538461538,10.8853846153846,9.68076923076923,8.54307692307692,7.47923076923077,6.48461538461538,5.56153846153846,4.71,3.92769230769231,3.21923076923077,2.57769230769231,2.01230769230769,1.51153846153846,1.08923076923077,0.731538461538461,0.45,0.235384615384615,0.0946153846153846,0.0230769230769229,0.023076923076923,0.0946153846153846,0.235384615384616,0.45,0.731538461538462,1.08923076923077,1.51153846153846,2.01230769230769,2.57769230769231,3.21923076923077,3.92769230769231,4.71,5.56153846153846,6.48461538461539,7.47923076923077,8.54307692307692,9.68076923076923,10.8853846153846,12.1661538461539,13.5115384615385],[13.5115384615385,12.1661538461538,10.8853846153846,9.68076923076923,8.54307692307692,7.47923076923077,6.48461538461538,5.56153846153846,4.71,3.92769230769231,3.21923076923077,2.57769230769231,2.01230769230769,1.51153846153846,1.08923076923077,0.731538461538461,0.45,0.235384615384615,0.0946153846153847,0.023076923076923,0.0230769230769231,0.0946153846153847,0.235384615384616,0.450000000000001,0.731538461538462,1.08923076923077,1.51153846153846,2.01230769230769,2.57769230769231,3.21923076923077,3.92769230769231,4.71,5.56153846153846,6.48461538461539,7.47923076923077,8.54307692307693,9.68076923076923,10.8853846153846,12.1661538461539,13.5115384615385],[13.5830769230769,12.2376923076923,10.9569230769231,9.75230769230769,8.61461538461538,7.55076923076923,6.55615384615384,5.63307692307692,4.78153846153846,3.99923076923077,3.29076923076923,2.64923076923077,2.08384615384615,1.58307692307692,1.16076923076923,0.803076923076923,0.521538461538461,0.306923076923077,0.166153846153846,0.0946153846153846,0.0946153846153847,0.166153846153846,0.306923076923077,0.521538461538462,0.803076923076924,1.16076923076923,1.58307692307692,2.08384615384616,2.64923076923077,3.29076923076923,3.99923076923077,4.78153846153846,5.63307692307692,6.55615384615385,7.55076923076923,8.61461538461539,9.75230769230769,10.9569230769231,12.2376923076923,13.5830769230769],[13.7238461538462,12.3784615384615,11.0976923076923,9.89307692307692,8.75538461538461,7.69153846153846,6.69692307692308,5.77384615384615,4.92230769230769,4.14,3.43153846153846,2.79,2.22461538461538,1.72384615384615,1.30153846153846,0.943846153846154,0.662307692307693,0.447692307692308,0.306923076923077,0.235384615384616,0.235384615384616,0.306923076923077,0.447692307692309,0.662307692307693,0.943846153846155,1.30153846153846,1.72384615384615,2.22461538461539,2.79,3.43153846153846,4.14,4.92230769230769,5.77384615384616,6.69692307692308,7.69153846153846,8.75538461538462,9.89307692307692,11.0976923076923,12.3784615384615,13.7238461538462],[13.9384615384615,12.5930769230769,11.3123076923077,10.1076923076923,8.97,7.90615384615385,6.91153846153846,5.98846153846154,5.13692307692308,4.35461538461539,3.64615384615385,3.00461538461538,2.43923076923077,1.93846153846154,1.51615384615385,1.15846153846154,0.876923076923077,0.662307692307693,0.521538461538462,0.45,0.450000000000001,0.521538461538462,0.662307692307693,0.876923076923078,1.15846153846154,1.51615384615385,1.93846153846154,2.43923076923077,3.00461538461539,3.64615384615385,4.35461538461539,5.13692307692308,5.98846153846154,6.91153846153847,7.90615384615385,8.97,10.1076923076923,11.3123076923077,12.5930769230769,13.9384615384615],[14.22,12.8746153846154,11.5938461538462,10.3892307692308,9.25153846153846,8.18769230769231,7.19307692307692,6.27,5.41846153846154,4.63615384615385,3.92769230769231,3.28615384615385,2.72076923076923,2.22,1.79769230769231,1.44,1.15846153846154,0.943846153846154,0.803076923076924,0.731538461538462,0.731538461538462,0.803076923076924,0.943846153846155,1.15846153846154,1.44,1.79769230769231,2.22,2.72076923076923,3.28615384615385,3.92769230769231,4.63615384615385,5.41846153846154,6.27,7.19307692307693,8.18769230769231,9.25153846153847,10.3892307692308,11.5938461538462,12.8746153846154,14.22],[14.5776923076923,13.2323076923077,11.9515384615385,10.7469230769231,9.60923076923077,8.54538461538462,7.55076923076923,6.62769230769231,5.77615384615385,4.99384615384615,4.28538461538461,3.64384615384615,3.07846153846154,2.57769230769231,2.15538461538462,1.79769230769231,1.51615384615385,1.30153846153846,1.16076923076923,1.08923076923077,1.08923076923077,1.16076923076923,1.30153846153846,1.51615384615385,1.79769230769231,2.15538461538462,2.57769230769231,3.07846153846154,3.64384615384616,4.28538461538462,4.99384615384616,5.77615384615385,6.62769230769231,7.55076923076923,8.54538461538462,9.60923076923077,10.7469230769231,11.9515384615385,13.2323076923077,14.5776923076923],[15,13.6546153846154,12.3738461538462,11.1692307692308,10.0315384615385,8.96769230769231,7.97307692307692,7.05,6.19846153846154,5.41615384615385,4.70769230769231,4.06615384615385,3.50076923076923,3,2.57769230769231,2.22,1.93846153846154,1.72384615384615,1.58307692307692,1.51153846153846,1.51153846153846,1.58307692307692,1.72384615384615,1.93846153846154,2.22,2.57769230769231,3,3.50076923076923,4.06615384615385,4.70769230769231,5.41615384615385,6.19846153846154,7.05,7.97307692307693,8.96769230769231,10.0315384615385,11.1692307692308,12.3738461538462,13.6546153846154,15],[15.5007692307692,14.1553846153846,12.8746153846154,11.67,10.5323076923077,9.46846153846154,8.47384615384615,7.55076923076923,6.69923076923077,5.91692307692308,5.20846153846154,4.56692307692308,4.00153846153846,3.50076923076923,3.07846153846154,2.72076923076923,2.43923076923077,2.22461538461539,2.08384615384615,2.01230769230769,2.01230769230769,2.08384615384615,2.22461538461539,2.43923076923077,2.72076923076923,3.07846153846154,3.50076923076923,4.00153846153846,4.56692307692308,5.20846153846154,5.91692307692308,6.69923076923077,7.55076923076923,8.47384615384616,9.46846153846154,10.5323076923077,11.67,12.8746153846154,14.1553846153846,15.5007692307692],[16.0661538461538,14.7207692307692,13.44,12.2353846153846,11.0976923076923,10.0338461538462,9.03923076923077,8.11615384615385,7.26461538461539,6.4823076923077,5.77384615384616,5.13230769230769,4.56692307692308,4.06615384615385,3.64384615384616,3.28615384615385,3.00461538461539,2.79,2.64923076923077,2.57769230769231,2.57769230769231,2.64923076923077,2.79,3.00461538461539,3.28615384615385,3.64384615384616,4.06615384615385,4.56692307692308,5.1323076923077,5.77384615384616,6.4823076923077,7.26461538461539,8.11615384615385,9.03923076923077,10.0338461538462,11.0976923076923,12.2353846153846,13.44,14.7207692307692,16.0661538461538],[16.7076923076923,15.3623076923077,14.0815384615385,12.8769230769231,11.7392307692308,10.6753846153846,9.68076923076923,8.75769230769231,7.90615384615385,7.12384615384615,6.41538461538461,5.77384615384615,5.20846153846154,4.70769230769231,4.28538461538461,3.92769230769231,3.64615384615385,3.43153846153846,3.29076923076923,3.21923076923077,3.21923076923077,3.29076923076923,3.43153846153846,3.64615384615385,3.92769230769231,4.28538461538462,4.70769230769231,5.20846153846154,5.77384615384616,6.41538461538462,7.12384615384616,7.90615384615385,8.75769230769231,9.68076923076923,10.6753846153846,11.7392307692308,12.8769230769231,14.0815384615385,15.3623076923077,16.7076923076923],[17.4161538461539,16.0707692307692,14.79,13.5853846153846,12.4476923076923,11.3838461538462,10.3892307692308,9.46615384615385,8.61461538461539,7.83230769230769,7.12384615384616,6.48230769230769,5.91692307692308,5.41615384615385,4.99384615384616,4.63615384615385,4.35461538461539,4.14,3.99923076923077,3.92769230769231,3.92769230769231,3.99923076923077,4.14,4.35461538461539,4.63615384615385,4.99384615384616,5.41615384615385,5.91692307692308,6.4823076923077,7.12384615384616,7.8323076923077,8.61461538461539,9.46615384615385,10.3892307692308,11.3838461538462,12.4476923076923,13.5853846153846,14.79,16.0707692307692,17.4161538461539],[18.1984615384615,16.8530769230769,15.5723076923077,14.3676923076923,13.23,12.1661538461538,11.1715384615385,10.2484615384615,9.39692307692308,8.61461538461538,7.90615384615384,7.26461538461538,6.69923076923077,6.19846153846154,5.77615384615384,5.41846153846154,5.13692307692308,4.92230769230769,4.78153846153846,4.71,4.71,4.78153846153846,4.92230769230769,5.13692307692308,5.41846153846154,5.77615384615385,6.19846153846154,6.69923076923077,7.26461538461539,7.90615384615385,8.61461538461539,9.39692307692308,10.2484615384615,11.1715384615385,12.1661538461538,13.23,14.3676923076923,15.5723076923077,16.8530769230769,18.1984615384615],[19.05,17.7046153846154,16.4238461538462,15.2192307692308,14.0815384615385,13.0176923076923,12.0230769230769,11.1,10.2484615384615,9.46615384615385,8.75769230769231,8.11615384615385,7.55076923076923,7.05,6.62769230769231,6.27,5.98846153846154,5.77384615384616,5.63307692307692,5.56153846153846,5.56153846153846,5.63307692307692,5.77384615384616,5.98846153846154,6.27,6.62769230769231,7.05,7.55076923076923,8.11615384615385,8.75769230769231,9.46615384615385,10.2484615384615,11.1,12.0230769230769,13.0176923076923,14.0815384615385,15.2192307692308,16.4238461538462,17.7046153846154,19.05],[19.9730769230769,18.6276923076923,17.3469230769231,16.1423076923077,15.0046153846154,13.9407692307692,12.9461538461538,12.0230769230769,11.1715384615385,10.3892307692308,9.68076923076923,9.03923076923077,8.47384615384616,7.97307692307693,7.55076923076923,7.19307692307693,6.91153846153846,6.69692307692308,6.55615384615385,6.48461538461539,6.48461538461539,6.55615384615385,6.69692307692308,6.91153846153847,7.19307692307693,7.55076923076923,7.97307692307693,8.47384615384616,9.03923076923077,9.68076923076923,10.3892307692308,11.1715384615385,12.0230769230769,12.9461538461539,13.9407692307692,15.0046153846154,16.1423076923077,17.3469230769231,18.6276923076923,19.9730769230769],[20.9676923076923,19.6223076923077,18.3415384615385,17.1369230769231,15.9992307692308,14.9353846153846,13.9407692307692,13.0176923076923,12.1661538461538,11.3838461538462,10.6753846153846,10.0338461538462,9.46846153846154,8.96769230769231,8.54538461538461,8.18769230769231,7.90615384615385,7.69153846153846,7.55076923076923,7.47923076923077,7.47923076923077,7.55076923076923,7.69153846153846,7.90615384615385,8.18769230769231,8.54538461538462,8.96769230769231,9.46846153846154,10.0338461538462,10.6753846153846,11.3838461538462,12.1661538461538,13.0176923076923,13.9407692307692,14.9353846153846,15.9992307692308,17.1369230769231,18.3415384615385,19.6223076923077,20.9676923076923],[22.0315384615385,20.6861538461539,19.4053846153846,18.2007692307692,17.0630769230769,15.9992307692308,15.0046153846154,14.0815384615385,13.23,12.4476923076923,11.7392307692308,11.0976923076923,10.5323076923077,10.0315384615385,9.60923076923077,9.25153846153846,8.97,8.75538461538462,8.61461538461539,8.54307692307692,8.54307692307692,8.61461538461539,8.75538461538462,8.97,9.25153846153846,9.60923076923077,10.0315384615385,10.5323076923077,11.0976923076923,11.7392307692308,12.4476923076923,13.23,14.0815384615385,15.0046153846154,15.9992307692308,17.0630769230769,18.2007692307692,19.4053846153846,20.6861538461539,22.0315384615385],[23.1692307692308,21.8238461538462,20.5430769230769,19.3384615384615,18.2007692307692,17.1369230769231,16.1423076923077,15.2192307692308,14.3676923076923,13.5853846153846,12.8769230769231,12.2353846153846,11.67,11.1692307692308,10.7469230769231,10.3892307692308,10.1076923076923,9.89307692307692,9.75230769230769,9.68076923076923,9.68076923076923,9.75230769230769,9.89307692307692,10.1076923076923,10.3892307692308,10.7469230769231,11.1692307692308,11.67,12.2353846153846,12.8769230769231,13.5853846153846,14.3676923076923,15.2192307692308,16.1423076923077,17.1369230769231,18.2007692307692,19.3384615384615,20.5430769230769,21.8238461538462,23.1692307692308],[24.3738461538462,23.0284615384615,21.7476923076923,20.5430769230769,19.4053846153846,18.3415384615385,17.3469230769231,16.4238461538462,15.5723076923077,14.79,14.0815384615385,13.44,12.8746153846154,12.3738461538462,11.9515384615385,11.5938461538462,11.3123076923077,11.0976923076923,10.9569230769231,10.8853846153846,10.8853846153846,10.9569230769231,11.0976923076923,11.3123076923077,11.5938461538462,11.9515384615385,12.3738461538462,12.8746153846154,13.44,14.0815384615385,14.79,15.5723076923077,16.4238461538462,17.3469230769231,18.3415384615385,19.4053846153846,20.5430769230769,21.7476923076923,23.0284615384615,24.3738461538462],[25.6546153846154,24.3092307692308,23.0284615384615,21.8238461538462,20.6861538461539,19.6223076923077,18.6276923076923,17.7046153846154,16.8530769230769,16.0707692307692,15.3623076923077,14.7207692307692,14.1553846153846,13.6546153846154,13.2323076923077,12.8746153846154,12.5930769230769,12.3784615384615,12.2376923076923,12.1661538461539,12.1661538461539,12.2376923076923,12.3784615384615,12.5930769230769,12.8746153846154,13.2323076923077,13.6546153846154,14.1553846153846,14.7207692307692,15.3623076923077,16.0707692307692,16.8530769230769,17.7046153846154,18.6276923076923,19.6223076923077,20.6861538461539,21.8238461538462,23.0284615384615,24.3092307692308,25.6546153846154],[27,25.6546153846154,24.3738461538462,23.1692307692308,22.0315384615385,20.9676923076923,19.9730769230769,19.05,18.1984615384615,17.4161538461538,16.7076923076923,16.0661538461538,15.5007692307692,15,14.5776923076923,14.22,13.9384615384615,13.7238461538462,13.5830769230769,13.5115384615385,13.5115384615385,13.5830769230769,13.7238461538462,13.9384615384615,14.22,14.5776923076923,15,15.5007692307692,16.0661538461538,16.7076923076923,17.4161538461539,18.1984615384615,19.05,19.9730769230769,20.9676923076923,22.0315384615385,23.1692307692308,24.3738461538462,25.6546153846154,27]],&#34;type&#34;:&#34;surface&#34;,&#34;x&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;y&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;frame&#34;:null}],&#34;highlight&#34;:{&#34;on&#34;:&#34;plotly_click&#34;,&#34;persistent&#34;:false,&#34;dynamic&#34;:false,&#34;selectize&#34;:false,&#34;opacityDim&#34;:0.2,&#34;selected&#34;:{&#34;opacity&#34;:1}},&#34;base_url&#34;:&#34;https://plot.ly&#34;},&#34;evals&#34;:[&#34;config.modeBarButtonsToAdd.0.click&#34;],&#34;jsHooks&#34;:{&#34;render&#34;:[{&#34;code&#34;:&#34;function(el, x) { var ctConfig = crosstalk.var(&#39;plotlyCrosstalkOpts&#39;).set({\&#34;on\&#34;:\&#34;plotly_click\&#34;,\&#34;persistent\&#34;:false,\&#34;dynamic\&#34;:false,\&#34;selectize\&#34;:false,\&#34;opacityDim\&#34;:0.2,\&#34;selected\&#34;:{\&#34;opacity\&#34;:1}}); }&#34;,&#34;data&#34;:null}]}}&lt;/script&gt;
&lt;p&gt;The goal of ridge regression is to find the optimal combination of &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights that minimizes the traditional loss function, while also accounting for the added “loss” incurred by the penalty term. Looking at the plot above, you can see that as the &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights both move away from 0, the ridge penalty function shows a slow increase near 0, which becomes progressively steeper as we move away from the origin. Further, as &lt;span class=&#34;math inline&#34;&gt;\(\lambda \rightarrow \infty\)&lt;/span&gt;, the penalty function becomes steeper and steeper. Altogether, ridge regression does not prefer particular values for &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights—it only prefers for all &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights to be closer to 0.&lt;/p&gt;
&lt;div id=&#34;frequentist-ridge-regression&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Frequentist Ridge Regression&lt;/h4&gt;
&lt;p&gt;One of the problems that arises from equation 4 is that we need to select a value for &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;, the parameter that controls how much we learn from our training data. But how should we select an optimal &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;? Of course, we could just pick a value based on our intuition, but that would likely lead to non-optimal solutions in many cases. Therefore, &lt;strong&gt;frequentist ridge regression typically relies on cross-validation (CV) to select&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; (see &lt;a href=&#34;https://en.wikipedia.org/wiki/Hyperparameter_optimization&#34;&gt;here&lt;/a&gt; for more details on hyper-parameter tuning/optimization). CV proceeds by:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;generating a grid of values for our hyper-parameter (&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;)&lt;/li&gt;
&lt;li&gt;splitting the training data into k equivalently sized training sets (&lt;em&gt;k folds&lt;/em&gt;),&lt;/li&gt;
&lt;li&gt;fitting a model to k-1 folds and testing prediction accuracy on the left-out fold, and&lt;/li&gt;
&lt;li&gt;iterating steps 2-3 for each hyper-parameter in the grid defined by step 1&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;When we are finished, we select the value of &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; in the grid that minimizes the CV error (step 3). The R code below proceeds through the above steps, using the R &lt;code&gt;glmnet&lt;/code&gt; package to fit the model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Penalty term values to test
lambdas &amp;lt;- 10^seq(3, -2, by = -.1)

# Fit and cross-validate
fit_ridge &amp;lt;- glmnet(x = train_scale[,-8], y = train_scale[,8], 
                    alpha = 0, lambda = lambdas, intercept = F)
cv_ridge &amp;lt;- cv.glmnet(x = train_scale[,-8], y = train_scale[,8], 
                      alpha = 0, lambda = lambdas, intercept = F)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Option grouped=FALSE enforced in cv.glmnet, since &amp;lt; 3 observations
## per fold&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Find optimal penalty term (lambda)
opt_lambda &amp;lt;- cv_ridge$lambda.min

# Generate predictions with opitmal lambda model from cross-validation
y_pred &amp;lt;- predict(fit_ridge, s = opt_lambda, newx = test_scale[,-8])

# Plot cor(predicted, actual)
qplot(x = y_pred[,1], y = test_scale[,8],
      main = paste0(&amp;quot;Frequentist Ridge Regression:\nEstimating &amp;quot;, expression(lambda), 
                    &amp;quot; with CV\nr = &amp;quot;, round(cor(test_scale[,8], y_pred[,1]), 2))) +
  #geom_point(aes(x = , y = train_scale[,8]))
  xlab(&amp;quot;Model Predicted Pr(Acceptance)&amp;quot;) +
  ylab(&amp;quot;Actual Pr(Acceptance)&amp;quot;) +
  theme_minimal(base_size = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2019-05-06-on-the-equivalency-between-the-lasso-ridge-regression-and-specific-bayesian-priors_files/figure-html/2019-05-06_fig3-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;Woah, much better than traditional linear regression! Before diving into these results, however, let’s first explore Bayesian ridge regression.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-ridge-regression&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Bayesian Ridge Regression&lt;/h4&gt;
&lt;p&gt;Bayesian Ridge regression differs from the frequentist variant in only one way, and it is with how we think of the &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; penalty term. In the frequentist perspective, we showed that &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; effectively tells our model how much it is allowed to learn from the data. &lt;em&gt;In the Bayesian world, we can capture such an effect in the form of a prior distribution over our&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; &lt;em&gt;weights&lt;/em&gt;. To reveal the extraordinary power hiding behind this simple idea, let’s first discuss Bayesian linear regression.&lt;/p&gt;
&lt;p&gt;Bayesian models view estimation as a problem of integrating prior information with information gained from data, which we formalize using probability distributions. This differs from the frequntist view, which treats regression as an opimization problem that results in a point estimate (e.g., minimizing squared error). A Bayesian regression model takes the form of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{i} | \beta_{0},\boldsymbol{x_{i}},\boldsymbol{\beta},\sigma \sim \mathcal{N}(\beta_{0} + \sum_{j=1}^{p}x_{ij}\beta_{j}, \sigma) \tag{5}\]&lt;/span&gt; Importantly, &lt;em&gt;Bayesian models require us to specify a &lt;strong&gt;prior distribution&lt;/strong&gt; for each parameter we seek to estimate&lt;/em&gt;. Therefore, we need to specify a prior on the intercept (&lt;span class=&#34;math inline&#34;&gt;\(\beta_{0}\)&lt;/span&gt;), slopes (&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{\beta}\)&lt;/span&gt;), and error variance (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;) in equation 5. Since we are standardizing all of our predictors and outcome variable(s), we will ignore the intercept term. Then, we are left with &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{\beta}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. &lt;strong&gt;Crucially, our choice of prior distribution on &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{\beta}\)&lt;/span&gt; is what determines how much information we learn from the data, analagous to the penalty term &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; used for frequentist regularization.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Like before, you can gain an intuition for this behavior by imagnining extreme cases. For example, suppose that we assumed that &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{\beta} \sim \mathcal{U}(-\infty,+\infty)\)&lt;/span&gt;. That is, we assume that &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{\beta}\)&lt;/span&gt; can take on any real-valued number. In this case, the mode of the posterior distribution on each &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weight will be equivalent to the maximum likelihood estimate of the respective &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weight, and by extention the OLS estimate under the normality assumption (see our prior &lt;a href=&#34;http://haines-lab.com/post/2018-03-24-human-choice-and-reinforcement-learning-3/&#34;&gt;post on parameter estimation&lt;/a&gt; for more details). If an unbounded uniform distribution on &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{\beta}\)&lt;/span&gt; produces the same behavior as traditional linear regression, it follows from our discussions above that it also allows us to maximally learn from the data.&lt;/p&gt;
&lt;p&gt;Now, what can we do to restrict learning in a Bayesian model? Well, we can use a prior distribution that pulls the &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights toward 0 (unlike the unbounded uniform distribution), similar to the &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; penalty parameter in frequentist regularization! Specifically, specifying the following prior distribution on &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{\beta}\)&lt;/span&gt; is mathematically equivalent in expectation (see &lt;a href=&#34;https://stats.stackexchange.com/questions/163388/l2-regularization-is-equivalent-to-gaussian-prior&#34;&gt;here&lt;/a&gt;) to using the ridge penalty in the frequentist model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\boldsymbol{\beta} \sim \mathcal{N}(0, \sigma_{\beta})\tag{6}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;There are two important points that the prior distribution in equation 6 conveys:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The normal distribution places very little prior probability on large-magnitude &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights (i.e. far from 0), while placing high prior probability on small-magnitude weights (i.e. near 0), and&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma_{\beta}\)&lt;/span&gt; controls how wide the normal distribution is, thus controlling the specific amount of prior probability placed on small- to large-magnitude &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The Bayesian version differs most in that we jointly estimate the “penalization term” &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{\beta}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{\beta}\)&lt;/span&gt; in a single model, as opposed to using CV to select an optimal &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; for frequentist regression. Because we are jointly estimating &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{\beta}\)&lt;/span&gt; along with individual-level &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights, we can actually view Bayesian ridge regression as a simple hierarchical Bayesian model, where &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{\beta}\)&lt;/span&gt; is interpreted as a group-level scaling parameter that is estimated from pooled information across individual &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights.&lt;/p&gt;
&lt;p&gt;Below is the Stan code that specifies the Bayesian variant of ridge regression. Note that this code is based on &lt;a href=&#34;https://osf.io/cg8fq/&#34;&gt;Erp, Oberski, &amp;amp; Mulder (2019)&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;stan&#34;&gt;&lt;code&gt;data{
    int N_train;             // # training observations
    int N_test;              // # test observations
    int N_pred;              // # predictor variables
    vector[N_train] y_train; // training outcomes
    matrix[N_train, N_pred] X_train; // training data
    matrix[N_test, N_pred] X_test;   // testing data
}
parameters{
    real&amp;lt;lower=0&amp;gt; sigma;   // error SD
    real&amp;lt;lower=0&amp;gt; sigma_B; // hierarchical SD across betas
    vector[N_pred] beta;   // regression beta weights
}
model{
  // group-level (hierarchical) SD across betas
  sigma_B ~ cauchy(0, 1);
  
  // model error SD
  sigma ~ normal(0, 1);
  
  // beta prior (provides &amp;quot;ridge&amp;quot; regularization)
  beta ~ normal(0, sigma_B);
    
  // model likelihood
    y_train ~ normal(X_train*beta, sigma);
}
generated quantities{ 
    real y_test[N_test]; // test data predictions
    for(i in 1:N_test){
        y_test[i] = normal_rng(X_test[i,] * beta, sigma);
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The important parts of the above code are in the &lt;code&gt;model{...}&lt;/code&gt; section. While the parameterization looks different from the frequentist model (equation 4), the behavior of the model is equivalent. In particular, we have a &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{\beta}\)&lt;/span&gt; “penalty” term, can shrink the variation between &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights toward 0. Intuitively, as &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{\beta} \rightarrow 0\)&lt;/span&gt;, all (&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;) weights are shrunk toward 0 (no learning from data). Conversely, as &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{\beta} \rightarrow \infty\)&lt;/span&gt;, prior on &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{\beta}\)&lt;/span&gt; becomes uniform. A uniform prior denotes no penalty at all, and we are left with traditional, non-regularized regression (albeit we get a joint posterior distribution as opposed to point estimates). It is worth noting that the mode of the resulting posterior distribution over &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{\beta}\)&lt;/span&gt; will be equivalent to the maximum likelihood estimate when the prior on &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{\beta}\)&lt;/span&gt; is uniform (for details, see MLE/MAP estimation described in a &lt;a href=&#34;http://haines-lab.com/post/2018-03-24-human-choice-and-reinforcement-learning-3/&#34;&gt;previous post&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Now, let’s try fitting the model!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# First, prepare data for Stan
stan_dat &amp;lt;- list(N_train = nrow(train_scale),
                 N_test  = nrow(test_scale),
                 N_pred  = ncol(train_scale)-1,
                 y_train = train_scale[,8],
                 X_train = train_scale[,-8],
                 X_test  = test_scale[,-8])

# Fit the model using Stan&amp;#39;s NUTS HMC sampler
fit_bayes_ridge &amp;lt;- sampling(bayes_ridge, stan_dat, iter = 2000, 
                            warmup = 500, chains = 3, cores = 3)

# Extract posterior distribution (parameters and predictions)
post_ridge &amp;lt;- rstan::extract(fit_bayes_ridge)

# Compute mean of the posterior predictive distribution over test set predictors,
# which integrates out uncertainty in parameter estimates
y_pred_bayes &amp;lt;- apply(post_ridge$y_test, 2, mean)

# Plot correlation between posterior predicted mean and actual Pr(Acceptance)
qplot(x = y_pred_bayes, y = test_scale[,8],
      main = paste0(&amp;quot;Bayesian Ridge Regression:\nEstimating &amp;quot;, expression(lambda), 
                    &amp;quot; Hierarchically\nr = &amp;quot;, round(cor(test_scale[,8], y_pred_bayes), 2))) +
    xlab(&amp;quot;Model Predicted Pr(Acceptance)&amp;quot;) +
    ylab(&amp;quot;Actual Pr(Acceptance)&amp;quot;) +
    theme_minimal(base_size = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2019-05-06-on-the-equivalency-between-the-lasso-ridge-regression-and-specific-bayesian-priors_files/figure-html/2019-05-06_fig4-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;It is clear that the Bayesian ridge regression is giving results very similar (almost identical) to frequentist ridge regression as outlined above. Importantly, the Bayesian method also offers straightforward measures of uncertainty for both parameter estimates and predictions on the test data. The plot above integrates over the prediction uncertainty (i.e. integrating over the posterior predictive distribution). To really appreciate the prediction uncertainty, we compute the correlation between predicted and actual Pr(Acceptance) for each posterior sample, and then visualize the resulting distribution of correlations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Iterate through each posterior prediction and compute cor(predicted, actual),
# which preserves uncertainty in parameter estimates
y_pred_bayes2 &amp;lt;- apply(post_ridge$y_test, 1, function(x) cor(x, test_scale[,8]))

# Plot posterior predictive distribution of cor(predicted, actual)
qplot(x = y_pred_bayes2, geom = &amp;quot;histogram&amp;quot;, 
      xlab = &amp;quot;Correlation between\nPredicted and Actual Pr(Acceptance)&amp;quot;) +
  theme_minimal(base_size = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2019-05-06-on-the-equivalency-between-the-lasso-ridge-regression-and-specific-bayesian-priors_files/figure-html/2019-05-06_fig5-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;Clearly, there is good amount of uncertainty contained within the posterior predictive distribution, and the above plot shows it well. Importantly, this uncertainty reduce in proportion to how much data (i.e. observations) we have. Given that we only used 20 observations, these results are actually pretty good!&lt;/p&gt;
&lt;p&gt;Another method is to visualize the scatterplot like above, but to include prediction intervals around the predicted mean estimates for each observation in the test set:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# `bayesplot` has many convenience functions for working with posteriors
color_scheme_set(scheme = &amp;quot;darkgray&amp;quot;)
ppc_intervals(x = colMeans(post_ridge$y_test), y = test_scale[,8],
              yrep = post_ridge$y_test, prob = 0.95) +
  ggtitle(&amp;quot;95% Posterior Prediction Intervals&amp;quot;) +
  xlab(&amp;quot;Model Predicted Pr(Acceptance)&amp;quot;) +
  ylab(&amp;quot;Actual Pr(Acceptance)&amp;quot;) +
  theme_minimal(base_size = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2019-05-06-on-the-equivalency-between-the-lasso-ridge-regression-and-specific-bayesian-priors_files/figure-html/2019-05-06_fig6-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;Looks great! We see that the 95% posterior prediction intervals contain the actual values in virtually all cases. Importantly, this visualization also makes it clear just how much uncertainty there is for each individual observation.&lt;/p&gt;
&lt;p&gt;Next up, we will explore Traditional and Bayesian LASSO regressions, followed by a discussion of the benefits of Bayesian over frequentist regularization more broadly.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;lasso-regression&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;LASSO Regression&lt;/h3&gt;
&lt;p&gt;Now that we have covered ridge regression, LASSO regression only involves a minor revision to the loss function. Specifically, as opposed to penalizing the model based on the sum of squared &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights, we will penalize the model by the sum of the absolute value of &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\underbrace{\underset{\boldsymbol{\beta}}{argmin}\sum_{i=1}^{n}(y_{i} - \beta_{0} - \sum_{j=1}^{p}\beta_{j}x_{ij})^2}_{\text{Traditional Loss Function}} + \underbrace{\lambda\sum_{j=1}^{p}|\beta_{j}|}_{\text{LASSO Penalty}}\tag{7}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;That’s it! But what difference does this make? At this point, it is useful to visualize the effect of the LASSO penalty on &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weight estimates, as we did above for the ridge penalty. As before, we are looking at penalty functions for varying settings of &lt;span class=&#34;math inline&#34;&gt;\(\lambda \in \{0, .5, 1.5\}\)&lt;/span&gt;:&lt;/p&gt;
&lt;div id=&#34;6ed65cc07ecb&#34; style=&#34;width:672px;height:480px;&#34; class=&#34;plotly html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;6ed65cc07ecb&#34;&gt;{&#34;x&#34;:{&#34;visdat&#34;:{&#34;6ed645939784&#34;:[&#34;function () &#34;,&#34;plotlyVisDat&#34;]},&#34;cur_data&#34;:&#34;6ed645939784&#34;,&#34;attrs&#34;:{&#34;6ed645939784&#34;:{&#34;showscale&#34;:false,&#34;alpha&#34;:1,&#34;sizes&#34;:[10,100],&#34;z&#34;:{},&#34;type&#34;:&#34;surface&#34;,&#34;x&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;y&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;opacity&#34;:0.5},&#34;6ed645939784.1&#34;:{&#34;showscale&#34;:false,&#34;alpha&#34;:1,&#34;sizes&#34;:[10,100],&#34;z&#34;:{},&#34;type&#34;:&#34;surface&#34;,&#34;x&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;y&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3]},&#34;6ed645939784.2&#34;:{&#34;showscale&#34;:false,&#34;alpha&#34;:1,&#34;sizes&#34;:[10,100],&#34;z&#34;:{},&#34;type&#34;:&#34;surface&#34;,&#34;x&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;y&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3]}},&#34;layout&#34;:{&#34;margin&#34;:{&#34;b&#34;:40,&#34;l&#34;:60,&#34;t&#34;:25,&#34;r&#34;:10},&#34;scene&#34;:{&#34;xaxis&#34;:{&#34;title&#34;:&#34;Beta_1&#34;},&#34;yaxis&#34;:{&#34;title&#34;:&#34;Beta_2&#34;},&#34;zaxis&#34;:{&#34;title&#34;:&#34;Penalty&#34;}},&#34;title&#34;:&#34;LASSO Penalty Contour&#34;,&#34;xaxis&#34;:{&#34;domain&#34;:[0,1]},&#34;yaxis&#34;:{&#34;domain&#34;:[0,1]},&#34;hovermode&#34;:&#34;closest&#34;,&#34;showlegend&#34;:true},&#34;source&#34;:&#34;A&#34;,&#34;config&#34;:{&#34;modeBarButtonsToAdd&#34;:[{&#34;name&#34;:&#34;Collaborate&#34;,&#34;icon&#34;:{&#34;width&#34;:1000,&#34;ascent&#34;:500,&#34;descent&#34;:-50,&#34;path&#34;:&#34;M487 375c7-10 9-23 5-36l-79-259c-3-12-11-23-22-31-11-8-22-12-35-12l-263 0c-15 0-29 5-43 15-13 10-23 23-28 37-5 13-5 25-1 37 0 0 0 3 1 7 1 5 1 8 1 11 0 2 0 4-1 6 0 3-1 5-1 6 1 2 2 4 3 6 1 2 2 4 4 6 2 3 4 5 5 7 5 7 9 16 13 26 4 10 7 19 9 26 0 2 0 5 0 9-1 4-1 6 0 8 0 2 2 5 4 8 3 3 5 5 5 7 4 6 8 15 12 26 4 11 7 19 7 26 1 1 0 4 0 9-1 4-1 7 0 8 1 2 3 5 6 8 4 4 6 6 6 7 4 5 8 13 13 24 4 11 7 20 7 28 1 1 0 4 0 7-1 3-1 6-1 7 0 2 1 4 3 6 1 1 3 4 5 6 2 3 3 5 5 6 1 2 3 5 4 9 2 3 3 7 5 10 1 3 2 6 4 10 2 4 4 7 6 9 2 3 4 5 7 7 3 2 7 3 11 3 3 0 8 0 13-1l0-1c7 2 12 2 14 2l218 0c14 0 25-5 32-16 8-10 10-23 6-37l-79-259c-7-22-13-37-20-43-7-7-19-10-37-10l-248 0c-5 0-9-2-11-5-2-3-2-7 0-12 4-13 18-20 41-20l264 0c5 0 10 2 16 5 5 3 8 6 10 11l85 282c2 5 2 10 2 17 7-3 13-7 17-13z m-304 0c-1-3-1-5 0-7 1-1 3-2 6-2l174 0c2 0 4 1 7 2 2 2 4 4 5 7l6 18c0 3 0 5-1 7-1 1-3 2-6 2l-173 0c-3 0-5-1-8-2-2-2-4-4-4-7z m-24-73c-1-3-1-5 0-7 2-2 3-2 6-2l174 0c2 0 5 0 7 2 3 2 4 4 5 7l6 18c1 2 0 5-1 6-1 2-3 3-5 3l-174 0c-3 0-5-1-7-3-3-1-4-4-5-6z&#34;},&#34;click&#34;:&#34;function(gd) { \n        // is this being viewed in RStudio?\n        if (location.search == &#39;?viewer_pane=1&#39;) {\n          alert(&#39;To learn about plotly for collaboration, visit:\\n https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html&#39;);\n        } else {\n          window.open(&#39;https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html&#39;, &#39;_blank&#39;);\n        }\n      }&#34;}],&#34;cloud&#34;:false},&#34;data&#34;:[{&#34;colorbar&#34;:{&#34;title&#34;:&#34;lasso_p1$z&lt;br /&gt;lasso_p2$z&lt;br /&gt;lasso_p3$z&#34;,&#34;ticklen&#34;:2},&#34;colorscale&#34;:[[&#34;0&#34;,&#34;rgba(68,1,84,1)&#34;],[&#34;0.00569800569800438&#34;,&#34;rgba(68,3,86,1)&#34;],[&#34;0.076923076923077&#34;,&#34;rgba(71,30,109,1)&#34;],[&#34;0.111111111111111&#34;,&#34;rgba(72,40,120,1)&#34;],[&#34;0.136752136752137&#34;,&#34;rgba(71,49,124,1)&#34;],[&#34;0.162393162393162&#34;,&#34;rgba(69,57,128,1)&#34;],[&#34;0.17948717948718&#34;,&#34;rgba(67,62,130,1)&#34;],[&#34;0.205128205128205&#34;,&#34;rgba(64,69,134,1)&#34;],[&#34;0.230769230769231&#34;,&#34;rgba(61,76,137,1)&#34;],[&#34;0.256410256410256&#34;,&#34;rgba(59,83,139,1)&#34;],[&#34;0.290598290598291&#34;,&#34;rgba(56,93,140,1)&#34;],[&#34;0.358974358974359&#34;,&#34;rgba(48,110,142,1)&#34;],[&#34;0.435897435897436&#34;,&#34;rgba(39,128,142,1)&#34;],[&#34;0.512820512820513&#34;,&#34;rgba(36,147,139,1)&#34;],[&#34;0.58974358974359&#34;,&#34;rgba(40,166,132,1)&#34;],[&#34;0.666666666666667&#34;,&#34;rgba(53,183,121,1)&#34;],[&#34;0.769230769230769&#34;,&#34;rgba(106,203,92,1)&#34;],[&#34;1&#34;,&#34;rgba(253,231,37,1)&#34;]],&#34;showscale&#34;:false,&#34;z&#34;:[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]],&#34;type&#34;:&#34;surface&#34;,&#34;x&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;y&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;opacity&#34;:0.5,&#34;frame&#34;:null},{&#34;colorbar&#34;:{&#34;title&#34;:&#34;lasso_p1$z&lt;br /&gt;lasso_p2$z&lt;br /&gt;lasso_p3$z&#34;,&#34;ticklen&#34;:2},&#34;colorscale&#34;:[[&#34;0&#34;,&#34;rgba(68,1,84,1)&#34;],[&#34;0.00569800569800438&#34;,&#34;rgba(68,3,86,1)&#34;],[&#34;0.076923076923077&#34;,&#34;rgba(71,30,109,1)&#34;],[&#34;0.111111111111111&#34;,&#34;rgba(72,40,120,1)&#34;],[&#34;0.136752136752137&#34;,&#34;rgba(71,49,124,1)&#34;],[&#34;0.162393162393162&#34;,&#34;rgba(69,57,128,1)&#34;],[&#34;0.17948717948718&#34;,&#34;rgba(67,62,130,1)&#34;],[&#34;0.205128205128205&#34;,&#34;rgba(64,69,134,1)&#34;],[&#34;0.230769230769231&#34;,&#34;rgba(61,76,137,1)&#34;],[&#34;0.256410256410256&#34;,&#34;rgba(59,83,139,1)&#34;],[&#34;0.290598290598291&#34;,&#34;rgba(56,93,140,1)&#34;],[&#34;0.358974358974359&#34;,&#34;rgba(48,110,142,1)&#34;],[&#34;0.435897435897436&#34;,&#34;rgba(39,128,142,1)&#34;],[&#34;0.512820512820513&#34;,&#34;rgba(36,147,139,1)&#34;],[&#34;0.58974358974359&#34;,&#34;rgba(40,166,132,1)&#34;],[&#34;0.666666666666667&#34;,&#34;rgba(53,183,121,1)&#34;],[&#34;0.769230769230769&#34;,&#34;rgba(106,203,92,1)&#34;],[&#34;1&#34;,&#34;rgba(253,231,37,1)&#34;]],&#34;showscale&#34;:false,&#34;z&#34;:[[3,2.92307692307692,2.84615384615385,2.76923076923077,2.69230769230769,2.61538461538462,2.53846153846154,2.46153846153846,2.38461538461538,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461538,2.46153846153846,2.53846153846154,2.61538461538462,2.69230769230769,2.76923076923077,2.84615384615385,2.92307692307692,3],[2.92307692307692,2.84615384615385,2.76923076923077,2.69230769230769,2.61538461538462,2.53846153846154,2.46153846153846,2.38461538461538,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461539,2.46153846153846,2.53846153846154,2.61538461538462,2.69230769230769,2.76923076923077,2.84615384615385,2.92307692307692],[2.84615384615385,2.76923076923077,2.69230769230769,2.61538461538462,2.53846153846154,2.46153846153846,2.38461538461538,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461539,2.46153846153846,2.53846153846154,2.61538461538462,2.69230769230769,2.76923076923077,2.84615384615385],[2.76923076923077,2.69230769230769,2.61538461538462,2.53846153846154,2.46153846153846,2.38461538461538,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461538,2.46153846153846,2.53846153846154,2.61538461538462,2.69230769230769,2.76923076923077],[2.69230769230769,2.61538461538462,2.53846153846154,2.46153846153846,2.38461538461538,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461539,2.46153846153846,2.53846153846154,2.61538461538462,2.69230769230769],[2.61538461538462,2.53846153846154,2.46153846153846,2.38461538461538,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461538,2.46153846153846,2.53846153846154,2.61538461538462],[2.53846153846154,2.46153846153846,2.38461538461538,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461538,2.46153846153846,2.53846153846154],[2.46153846153846,2.38461538461538,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461539,2.46153846153846],[2.38461538461538,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461538],[2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231],[2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.769230769230769,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461539,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923],[2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.692307692307692,0.692307692307692,0.769230769230769,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615],[2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.692307692307692,0.615384615384615,0.615384615384615,0.692307692307692,0.769230769230769,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308],[2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.692307692307692,0.615384615384615,0.538461538461538,0.538461538461539,0.615384615384615,0.692307692307693,0.769230769230769,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2],[1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.692307692307692,0.615384615384615,0.538461538461538,0.461538461538461,0.461538461538461,0.538461538461538,0.615384615384615,0.692307692307692,0.769230769230769,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692],[1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.692307692307692,0.615384615384615,0.538461538461538,0.461538461538461,0.384615384615384,0.384615384615385,0.461538461538461,0.538461538461539,0.615384615384615,0.692307692307692,0.769230769230769,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385],[1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.692307692307692,0.615384615384615,0.538461538461538,0.461538461538461,0.384615384615385,0.307692307692307,0.307692307692308,0.384615384615385,0.461538461538462,0.538461538461539,0.615384615384615,0.692307692307692,0.769230769230769,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077],[1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.692307692307692,0.615384615384615,0.538461538461538,0.461538461538461,0.384615384615385,0.307692307692308,0.230769230769231,0.230769230769231,0.307692307692308,0.384615384615385,0.461538461538462,0.538461538461539,0.615384615384615,0.692307692307692,0.769230769230769,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769],[1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.692307692307692,0.615384615384615,0.538461538461538,0.461538461538461,0.384615384615385,0.307692307692308,0.230769230769231,0.153846153846154,0.153846153846154,0.230769230769231,0.307692307692308,0.384615384615385,0.461538461538462,0.538461538461539,0.615384615384615,0.692307692307693,0.76923076923077,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462],[1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.692307692307692,0.615384615384615,0.538461538461538,0.461538461538461,0.384615384615384,0.307692307692307,0.230769230769231,0.153846153846154,0.0769230769230766,0.0769230769230769,0.153846153846154,0.230769230769231,0.307692307692308,0.384615384615385,0.461538461538461,0.538461538461538,0.615384615384615,0.692307692307693,0.769230769230769,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154],[1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.692307692307692,0.615384615384615,0.538461538461539,0.461538461538461,0.384615384615385,0.307692307692308,0.230769230769231,0.153846153846154,0.0769230769230769,0.0769230769230771,0.153846153846154,0.230769230769231,0.307692307692308,0.384615384615385,0.461538461538462,0.538461538461539,0.615384615384616,0.692307692307693,0.769230769230769,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154],[1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.692307692307692,0.615384615384615,0.538461538461538,0.461538461538461,0.384615384615385,0.307692307692308,0.230769230769231,0.153846153846154,0.153846153846154,0.230769230769231,0.307692307692308,0.384615384615385,0.461538461538462,0.538461538461539,0.615384615384615,0.692307692307693,0.76923076923077,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462],[1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.692307692307693,0.615384615384615,0.538461538461539,0.461538461538462,0.384615384615385,0.307692307692308,0.230769230769231,0.230769230769231,0.307692307692308,0.384615384615385,0.461538461538462,0.538461538461539,0.615384615384616,0.692307692307693,0.76923076923077,0.846153846153847,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461539,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769],[1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.692307692307692,0.615384615384615,0.538461538461539,0.461538461538462,0.384615384615385,0.307692307692308,0.307692307692308,0.384615384615385,0.461538461538462,0.538461538461539,0.615384615384616,0.692307692307693,0.769230769230769,0.846153846153846,0.923076923076924,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077],[1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.692307692307692,0.615384615384615,0.538461538461539,0.461538461538462,0.384615384615385,0.384615384615385,0.461538461538462,0.538461538461539,0.615384615384616,0.692307692307693,0.769230769230769,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461539,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385],[1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.692307692307692,0.615384615384615,0.538461538461539,0.461538461538461,0.461538461538462,0.538461538461539,0.615384615384616,0.692307692307693,0.769230769230769,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692],[2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.692307692307692,0.615384615384615,0.538461538461538,0.538461538461539,0.615384615384615,0.692307692307693,0.769230769230769,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2],[2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.692307692307693,0.615384615384615,0.615384615384616,0.692307692307693,0.76923076923077,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461539,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308],[2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461539,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.76923076923077,0.692307692307693,0.692307692307693,0.76923076923077,0.846153846153847,0.923076923076924,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461539,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615],[2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.769230769230769,0.769230769230769,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461539,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923],[2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.846153846153846,0.846153846153846,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461539,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231],[2.38461538461538,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,0.923076923076923,0.923076923076923,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461538],[2.46153846153846,2.38461538461539,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1,1,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461539,2.46153846153846],[2.53846153846154,2.46153846153846,2.38461538461539,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.07692307692308,1.07692307692308,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461539,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461539,2.46153846153846,2.53846153846154],[2.61538461538462,2.53846153846154,2.46153846153846,2.38461538461538,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.15384615384615,1.15384615384615,1.23076923076923,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461538,2.46153846153846,2.53846153846154,2.61538461538462],[2.69230769230769,2.61538461538462,2.53846153846154,2.46153846153846,2.38461538461539,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.23076923076923,1.23076923076923,1.30769230769231,1.38461538461539,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461539,2.46153846153846,2.53846153846154,2.61538461538462,2.69230769230769],[2.76923076923077,2.69230769230769,2.61538461538462,2.53846153846154,2.46153846153846,2.38461538461538,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.30769230769231,1.30769230769231,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461538,2.46153846153846,2.53846153846154,2.61538461538462,2.69230769230769,2.76923076923077],[2.84615384615385,2.76923076923077,2.69230769230769,2.61538461538462,2.53846153846154,2.46153846153846,2.38461538461538,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.38461538461538,1.38461538461538,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461539,2.46153846153846,2.53846153846154,2.61538461538462,2.69230769230769,2.76923076923077,2.84615384615385],[2.92307692307692,2.84615384615385,2.76923076923077,2.69230769230769,2.61538461538462,2.53846153846154,2.46153846153846,2.38461538461539,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.46153846153846,1.46153846153846,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461539,2.46153846153846,2.53846153846154,2.61538461538462,2.69230769230769,2.76923076923077,2.84615384615385,2.92307692307692],[3,2.92307692307692,2.84615384615385,2.76923076923077,2.69230769230769,2.61538461538462,2.53846153846154,2.46153846153846,2.38461538461538,2.30769230769231,2.23076923076923,2.15384615384615,2.07692307692308,2,1.92307692307692,1.84615384615385,1.76923076923077,1.69230769230769,1.61538461538462,1.53846153846154,1.53846153846154,1.61538461538462,1.69230769230769,1.76923076923077,1.84615384615385,1.92307692307692,2,2.07692307692308,2.15384615384615,2.23076923076923,2.30769230769231,2.38461538461538,2.46153846153846,2.53846153846154,2.61538461538462,2.69230769230769,2.76923076923077,2.84615384615385,2.92307692307692,3]],&#34;type&#34;:&#34;surface&#34;,&#34;x&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;y&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;frame&#34;:null},{&#34;colorbar&#34;:{&#34;title&#34;:&#34;lasso_p1$z&lt;br /&gt;lasso_p2$z&lt;br /&gt;lasso_p3$z&#34;,&#34;ticklen&#34;:2},&#34;colorscale&#34;:[[&#34;0&#34;,&#34;rgba(68,1,84,1)&#34;],[&#34;0.00569800569800438&#34;,&#34;rgba(68,3,86,1)&#34;],[&#34;0.076923076923077&#34;,&#34;rgba(71,30,109,1)&#34;],[&#34;0.111111111111111&#34;,&#34;rgba(72,40,120,1)&#34;],[&#34;0.136752136752137&#34;,&#34;rgba(71,49,124,1)&#34;],[&#34;0.162393162393162&#34;,&#34;rgba(69,57,128,1)&#34;],[&#34;0.17948717948718&#34;,&#34;rgba(67,62,130,1)&#34;],[&#34;0.205128205128205&#34;,&#34;rgba(64,69,134,1)&#34;],[&#34;0.230769230769231&#34;,&#34;rgba(61,76,137,1)&#34;],[&#34;0.256410256410256&#34;,&#34;rgba(59,83,139,1)&#34;],[&#34;0.290598290598291&#34;,&#34;rgba(56,93,140,1)&#34;],[&#34;0.358974358974359&#34;,&#34;rgba(48,110,142,1)&#34;],[&#34;0.435897435897436&#34;,&#34;rgba(39,128,142,1)&#34;],[&#34;0.512820512820513&#34;,&#34;rgba(36,147,139,1)&#34;],[&#34;0.58974358974359&#34;,&#34;rgba(40,166,132,1)&#34;],[&#34;0.666666666666667&#34;,&#34;rgba(53,183,121,1)&#34;],[&#34;0.769230769230769&#34;,&#34;rgba(106,203,92,1)&#34;],[&#34;1&#34;,&#34;rgba(253,231,37,1)&#34;]],&#34;showscale&#34;:false,&#34;z&#34;:[[9,8.76923076923077,8.53846153846154,8.30769230769231,8.07692307692308,7.84615384615385,7.61538461538461,7.38461538461539,7.15384615384615,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384615,7.38461538461539,7.61538461538462,7.84615384615385,8.07692307692308,8.30769230769231,8.53846153846154,8.76923076923077,9],[8.76923076923077,8.53846153846154,8.30769230769231,8.07692307692308,7.84615384615385,7.61538461538462,7.38461538461538,7.15384615384615,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538462,4.38461538461538,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384616,7.38461538461539,7.61538461538461,7.84615384615385,8.07692307692308,8.30769230769231,8.53846153846154,8.76923076923077],[8.53846153846154,8.30769230769231,8.07692307692308,7.84615384615385,7.61538461538461,7.38461538461539,7.15384615384615,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538462,4.38461538461539,4.15384615384615,4.15384615384615,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384616,7.38461538461539,7.61538461538462,7.84615384615385,8.07692307692308,8.30769230769231,8.53846153846154],[8.30769230769231,8.07692307692308,7.84615384615385,7.61538461538461,7.38461538461539,7.15384615384615,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461538,4.15384615384615,3.92307692307692,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384615,7.38461538461538,7.61538461538462,7.84615384615385,8.07692307692308,8.30769230769231],[8.07692307692308,7.84615384615385,7.61538461538461,7.38461538461539,7.15384615384615,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461538,4.15384615384615,3.92307692307692,3.69230769230769,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384616,7.38461538461538,7.61538461538461,7.84615384615385,8.07692307692308],[7.84615384615385,7.61538461538461,7.38461538461539,7.15384615384615,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461538,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384615,7.38461538461539,7.61538461538462,7.84615384615385],[7.61538461538461,7.38461538461538,7.15384615384615,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461538,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461538,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384615,7.38461538461539,7.61538461538461],[7.38461538461539,7.15384615384615,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461538,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461538,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384616,7.38461538461539],[7.15384615384615,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461539,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384615],[6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461538,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692],[6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461538,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461538,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769],[6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461538,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538461,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846],[6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461539,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,1.84615384615385,1.84615384615385,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461538,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923],[6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461538,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,1.84615384615385,1.61538461538461,1.61538461538462,1.84615384615385,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6],[5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461538,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,1.84615384615385,1.61538461538461,1.38461538461538,1.38461538461538,1.61538461538461,1.84615384615385,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538461,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077],[5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461538,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,1.84615384615385,1.61538461538461,1.38461538461538,1.15384615384615,1.15384615384615,1.38461538461538,1.61538461538462,1.84615384615385,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461538,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154],[5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461538,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,1.84615384615385,1.61538461538461,1.38461538461538,1.15384615384615,0.923076923076922,0.923076923076923,1.15384615384615,1.38461538461539,1.61538461538462,1.84615384615385,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538461,4.84615384615385,5.07692307692308,5.30769230769231],[5.07692307692308,4.84615384615385,4.61538461538462,4.38461538461538,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,1.84615384615385,1.61538461538461,1.38461538461538,1.15384615384615,0.923076923076923,0.692307692307692,0.692307692307693,0.923076923076923,1.15384615384615,1.38461538461539,1.61538461538462,1.84615384615385,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461538,4.61538461538462,4.84615384615385,5.07692307692308],[4.84615384615385,4.61538461538462,4.38461538461539,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,1.84615384615385,1.61538461538461,1.38461538461538,1.15384615384615,0.923076923076923,0.692307692307693,0.461538461538461,0.461538461538462,0.692307692307693,0.923076923076924,1.15384615384615,1.38461538461539,1.61538461538462,1.84615384615385,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461538,4.61538461538462,4.84615384615385],[4.61538461538461,4.38461538461538,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,1.84615384615385,1.61538461538461,1.38461538461538,1.15384615384615,0.923076923076922,0.692307692307692,0.461538461538461,0.23076923076923,0.230769230769231,0.461538461538461,0.692307692307693,0.923076923076923,1.15384615384615,1.38461538461538,1.61538461538461,1.84615384615385,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538461],[4.61538461538462,4.38461538461539,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,1.84615384615385,1.61538461538462,1.38461538461538,1.15384615384615,0.923076923076923,0.692307692307693,0.461538461538462,0.230769230769231,0.230769230769231,0.461538461538462,0.692307692307693,0.923076923076924,1.15384615384615,1.38461538461539,1.61538461538462,1.84615384615385,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538462],[4.84615384615385,4.61538461538462,4.38461538461539,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,1.84615384615385,1.61538461538461,1.38461538461538,1.15384615384615,0.923076923076923,0.692307692307693,0.461538461538461,0.461538461538462,0.692307692307693,0.923076923076924,1.15384615384615,1.38461538461539,1.61538461538462,1.84615384615385,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538462,4.84615384615385],[5.07692307692308,4.84615384615385,4.61538461538462,4.38461538461539,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,1.84615384615385,1.61538461538462,1.38461538461539,1.15384615384615,0.923076923076924,0.692307692307693,0.692307692307693,0.923076923076924,1.15384615384616,1.38461538461539,1.61538461538462,1.84615384615385,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384616,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308],[5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538462,4.38461538461539,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,1.84615384615385,1.61538461538462,1.38461538461539,1.15384615384615,0.923076923076923,0.923076923076924,1.15384615384615,1.38461538461539,1.61538461538462,1.84615384615385,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384616,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231],[5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538462,4.38461538461539,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,1.84615384615385,1.61538461538462,1.38461538461539,1.15384615384615,1.15384615384615,1.38461538461539,1.61538461538462,1.84615384615385,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384616,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154],[5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538462,4.38461538461538,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,1.84615384615385,1.61538461538462,1.38461538461538,1.38461538461539,1.61538461538462,1.84615384615385,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077],[6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461538,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,1.84615384615385,1.61538461538461,1.61538461538462,1.84615384615385,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6],[6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538462,4.38461538461539,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,1.84615384615385,1.84615384615385,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384616,4.38461538461538,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923],[6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538462,4.38461538461539,4.15384615384616,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.07692307692308,2.07692307692308,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307693,4.15384615384616,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846],[6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538462,4.38461538461539,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.30769230769231,2.30769230769231,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384616,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769],[6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538462,4.38461538461539,4.15384615384616,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.53846153846154,2.53846153846154,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384616,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692],[7.15384615384615,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461538,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,2.76923076923077,2.76923076923077,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384615],[7.38461538461539,7.15384615384616,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461539,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3,3,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384616,7.38461538461539],[7.61538461538462,7.38461538461539,7.15384615384616,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538462,4.38461538461539,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.23076923076923,3.23076923076923,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384616,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384616,7.38461538461539,7.61538461538462],[7.84615384615385,7.61538461538461,7.38461538461539,7.15384615384615,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461538,4.15384615384615,3.92307692307692,3.69230769230769,3.46153846153846,3.46153846153846,3.69230769230769,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384615,7.38461538461539,7.61538461538462,7.84615384615385],[8.07692307692308,7.84615384615385,7.61538461538462,7.38461538461539,7.15384615384616,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538462,4.38461538461539,4.15384615384615,3.92307692307692,3.69230769230769,3.69230769230769,3.92307692307692,4.15384615384616,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384616,7.38461538461539,7.61538461538462,7.84615384615385,8.07692307692308],[8.30769230769231,8.07692307692308,7.84615384615385,7.61538461538462,7.38461538461538,7.15384615384615,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.38461538461538,4.15384615384615,3.92307692307692,3.92307692307692,4.15384615384615,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384615,7.38461538461539,7.61538461538461,7.84615384615385,8.07692307692308,8.30769230769231],[8.53846153846154,8.30769230769231,8.07692307692308,7.84615384615385,7.61538461538461,7.38461538461539,7.15384615384615,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538462,4.38461538461538,4.15384615384615,4.15384615384615,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384616,7.38461538461539,7.61538461538462,7.84615384615385,8.07692307692308,8.30769230769231,8.53846153846154],[8.76923076923077,8.53846153846154,8.30769230769231,8.07692307692308,7.84615384615385,7.61538461538462,7.38461538461538,7.15384615384616,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538462,4.38461538461539,4.38461538461539,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384616,7.38461538461539,7.61538461538462,7.84615384615385,8.07692307692308,8.30769230769231,8.53846153846154,8.76923076923077],[9,8.76923076923077,8.53846153846154,8.30769230769231,8.07692307692308,7.84615384615385,7.61538461538461,7.38461538461539,7.15384615384615,6.92307692307692,6.69230769230769,6.46153846153846,6.23076923076923,6,5.76923076923077,5.53846153846154,5.30769230769231,5.07692307692308,4.84615384615385,4.61538461538461,4.61538461538462,4.84615384615385,5.07692307692308,5.30769230769231,5.53846153846154,5.76923076923077,6,6.23076923076923,6.46153846153846,6.69230769230769,6.92307692307692,7.15384615384615,7.38461538461539,7.61538461538462,7.84615384615385,8.07692307692308,8.30769230769231,8.53846153846154,8.76923076923077,9]],&#34;type&#34;:&#34;surface&#34;,&#34;x&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;y&#34;:[-3,-2.84615384615385,-2.69230769230769,-2.53846153846154,-2.38461538461538,-2.23076923076923,-2.07692307692308,-1.92307692307692,-1.76923076923077,-1.61538461538462,-1.46153846153846,-1.30769230769231,-1.15384615384615,-1,-0.846153846153846,-0.692307692307692,-0.538461538461538,-0.384615384615385,-0.230769230769231,-0.0769230769230766,0.0769230769230771,0.230769230769231,0.384615384615385,0.538461538461539,0.692307692307693,0.846153846153846,1,1.15384615384615,1.30769230769231,1.46153846153846,1.61538461538462,1.76923076923077,1.92307692307692,2.07692307692308,2.23076923076923,2.38461538461539,2.53846153846154,2.69230769230769,2.84615384615385,3],&#34;frame&#34;:null}],&#34;highlight&#34;:{&#34;on&#34;:&#34;plotly_click&#34;,&#34;persistent&#34;:false,&#34;dynamic&#34;:false,&#34;selectize&#34;:false,&#34;opacityDim&#34;:0.2,&#34;selected&#34;:{&#34;opacity&#34;:1}},&#34;base_url&#34;:&#34;https://plot.ly&#34;},&#34;evals&#34;:[&#34;config.modeBarButtonsToAdd.0.click&#34;],&#34;jsHooks&#34;:{&#34;render&#34;:[{&#34;code&#34;:&#34;function(el, x) { var ctConfig = crosstalk.var(&#39;plotlyCrosstalkOpts&#39;).set({\&#34;on\&#34;:\&#34;plotly_click\&#34;,\&#34;persistent\&#34;:false,\&#34;dynamic\&#34;:false,\&#34;selectize\&#34;:false,\&#34;opacityDim\&#34;:0.2,\&#34;selected\&#34;:{\&#34;opacity\&#34;:1}}); }&#34;,&#34;data&#34;:null}]}}&lt;/script&gt;
&lt;p&gt;Interesting! We can see here that unlike for the ridge penalty, there are sharp corners in the geometry, which correspond to when either &lt;span class=&#34;math inline&#34;&gt;\(\beta_{1}\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(\beta_{2}\)&lt;/span&gt; equal 0. Further, the LASSO penalty shows a linear increase as we move away from the origin. Together, the sharp corners on 0-valued &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights and the linear increase in penalty make the LASSO penalty favor solutions that set one (or more) &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights to exactly 0.&lt;/p&gt;
&lt;div id=&#34;frequentist-lasso-regression&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Frequentist LASSO Regression&lt;/h4&gt;
&lt;p&gt;The code below is very similar to what we had for traditional ridge regression, except that we will set &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 1\)&lt;/span&gt; as opposed to &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Scale training data (get rid of ID)
train_scale &amp;lt;- scale(train_dat[,2:9])

# Penalty term values to test
lambdas &amp;lt;- 10^seq(3, -2, by = -.1)

# Fit and cross-validate
fit_lasso &amp;lt;- glmnet(x = train_scale[,-8], y = train_scale[,8], 
                    alpha = 1, lambda = lambdas, intercept = F)
cv_lasso &amp;lt;- cv.glmnet(x = train_scale[,-8], y = train_scale[,8], 
                      alpha = 1, lambda = lambdas, intercept = F)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Option grouped=FALSE enforced in cv.glmnet, since &amp;lt; 3 observations
## per fold&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Find optimal penalty term (lambda)
opt_lambda_lasso &amp;lt;- cv_lasso$lambda.min

# Generate predictions on the test set
y_pred_lasso &amp;lt;- predict(fit_lasso, s = opt_lambda_lasso, newx = test_scale[,-8])

# Plot cor(predicted, actual)
qplot(x = y_pred_lasso[,1], y = test_scale[,8],
      main = paste0(&amp;quot;r = &amp;quot;, round(cor(test_scale[,8], y_pred_lasso[,1]), 2))) +
  xlab(&amp;quot;Model Predicted Pr(Acceptance)&amp;quot;) +
  ylab(&amp;quot;Actual Pr(Acceptance)&amp;quot;) +
  theme_minimal(base_size = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2019-05-06-on-the-equivalency-between-the-lasso-ridge-regression-and-specific-bayesian-priors_files/figure-html/2019-05-06_fig8-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;Clearly, there is not much of a performance difference between frequentist ridge and LASSO regression in this dataset. However, it is worth noting that the LASSO is often more useful when we expect the solution to be sparse—that is, we expect that many of the predictors in our model are mostly noise, and are goal is to identify more robust effects. In such a case, the LASSO does a good job of setting &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights on noisy predictors to exactly 0.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-lasso-regression&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Bayesian LASSO Regression&lt;/h4&gt;
&lt;p&gt;Recall that for Bayesian ridge regression, we only needed to specifiy a normal prior distribution to the &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights that we were aiming to regularize. For Bayesian LASSO regression, the only difference is in the form of the prior distribution. Specifically, &lt;strong&gt;setting a Laplace (i.e. double-exponential) prior on the &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights is mathematically equivalent in expectation to the frequentist LASSO penalty&lt;/strong&gt; (see e.g., &lt;a href=&#34;https://stats.stackexchange.com/questions/182098/why-is-lasso-penalty-equivalent-to-the-double-exponential-laplace-prior&#34;&gt;here&lt;/a&gt;):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\boldsymbol{\beta} \sim \text{double-exponential}(0, \tau_{\beta})\tag{8}\]&lt;/span&gt; Here, &lt;span class=&#34;math inline&#34;&gt;\(\tau_{\beta}~(0 &amp;lt; \tau_{\beta} &amp;lt; \infty)\)&lt;/span&gt; is a scale parameter that controls how peaked the prior distribution is around the center (0 in this case). As &lt;span class=&#34;math inline&#34;&gt;\(\tau_{\beta} \rightarrow 0\)&lt;/span&gt;, then the model assigns infinite weight on 0-valued &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights (i.e. no learning from data). Conversely, as &lt;span class=&#34;math inline&#34;&gt;\(\tau_{\beta} \rightarrow \infty\)&lt;/span&gt;, the prior reduces to a uniform prior, thus leading to no regularization at all (i.e traditional regression, albeit with posterior distributions rather than point estimates). It can be useful to visualize what this prior distribution looks like over a single &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weight. For example, centered at 0 with &lt;span class=&#34;math inline&#34;&gt;\(\tau_{\beta} = 0.5\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qplot(x = seq(-3, 3, .1), y = rmutil::dlaplace(seq(-3, 3, .1), 0, .5), geom = &amp;quot;line&amp;quot;) +
  ggtitle(&amp;quot;Laplace Prior with tau = 0.5&amp;quot;) +
  xlab(expression(beta[1])) +
  ylab(&amp;quot;Density&amp;quot;) +
  theme_minimal(base_size = 20) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2019-05-06-on-the-equivalency-between-the-lasso-ridge-regression-and-specific-bayesian-priors_files/figure-html/2019-05-06_fig9-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;Compared to the ridge prior, which is a normal distribution, it is clear that the Laplace distribiution places much more probability mass directly on 0, which produces the variable selection effect specific to LASSO regression. Note also that such peakedness explains why there are sharp corners in the frequentist penalty function (see the LASSO contour plot above).&lt;/p&gt;
&lt;p&gt;Below is the Stan code that specifies this Bayesian variant of LASSO regression. Like for the Bayesian ridge regression above, this code is loosely based on &lt;a href=&#34;https://osf.io/cg8fq/&#34;&gt;Erp, Oberski, &amp;amp; Mulder (2019)&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;stan&#34;&gt;&lt;code&gt;data{
    int N_train;             // # training observations
    int N_test;              // # test observations
    int N_pred;              // # predictor variables
    vector[N_train] y_train; // training outcomes
    matrix[N_train, N_pred] X_train; // training data
    matrix[N_test, N_pred] X_test;   // testing data
}
parameters{
    real&amp;lt;lower=0&amp;gt; sigma;   // error SD
    real&amp;lt;lower=0&amp;gt; sigma_B; // (hierarchical) SD across betas
    vector[N_pred] beta;   // regression beta weights
}
model{
  // group-level (hierarchical) SD across betas
  sigma_B ~ cauchy(0, 1);
  
  // Prior on SD
  sigma ~ normal(0, 1);
  
  // beta prior (Note this is the only change!)
  beta ~ double_exponential(0, sigma_B); 
    
  // model likelihood
    y_train ~ normal(X_train*beta, sigma);
}
generated quantities{ 
    real y_test[N_test]; // test data predictions
    for(i in 1:N_test){
        y_test[i] = normal_rng(X_test[i,] * beta, sigma);
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Time to fit the model and visualize results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Fit the model using Stan&amp;#39;s NUTS HMC sampler
fit_bayes_lasso &amp;lt;- sampling(bayes_lasso, stan_dat, iter = 2000, 
                            warmup = 500, chains = 3, cores = 3)

# Extract posterior distribution (parameters and predictions)
post_lasso &amp;lt;- rstan::extract(fit_bayes_lasso)

# Compute mean of the posterior predictive distribution over test set predictors,
# which integrates out uncertainty in parameter estimates
y_pred_bayes_lasso &amp;lt;- apply(post_lasso$y_test, 2, mean)

# Plot correlation between posterior predicted mean and actual Pr(Acceptance)
qplot(x = y_pred_bayes_lasso, y = test_scale[,8],
      main = paste0(&amp;quot;r = &amp;quot;, round(cor(test_scale[,8], y_pred_bayes_lasso), 2))) +
    xlab(&amp;quot;Model Predicted Pr(Acceptance)&amp;quot;) +
    ylab(&amp;quot;Actual Pr(Acceptance)&amp;quot;) +
    theme_minimal(base_size = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2019-05-06-on-the-equivalency-between-the-lasso-ridge-regression-and-specific-bayesian-priors_files/figure-html/2019-05-06_fig10-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;Like before, the Bayesian LASSO is producing very similar results compared to the frequentist version.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;comparing-the-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Comparing the Models&lt;/h2&gt;
&lt;p&gt;So far, we have described and fit both the frequentist and Bayesian versions of ridge and LASSO regression to our training data, and we have shown that we can make pretty outstanding predictions on our held-out test set! However, we have not explored the parameters that each model has estimated. Here, we will begin to probe our models.&lt;/p&gt;
&lt;p&gt;First off, let’s look at the ridge regression model parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Extract beta weights from traditional regression model
betas_trad &amp;lt;- fit_lr$coefficients[-1]

# Extract optimal ridge beta weights from CV
betas_ridge &amp;lt;- fit_ridge$beta[,which(cv_ridge$lambda==cv_ridge$lambda.min)]

# Plot posterior distributions and frequentist point estimates
p1 &amp;lt;- mcmc_areas(as.array(fit_bayes_ridge), pars = paste0(&amp;quot;beta[&amp;quot;, 1:7, &amp;quot;]&amp;quot;), 
           prob = 0.8, prob_outer = 0.99, point_est = &amp;quot;mean&amp;quot;) +
  geom_point(x = betas_ridge, y = 7:1, color = I(&amp;quot;#c61d29&amp;quot;), size = 2) +
  geom_point(x = betas_trad, y = 7:1, color = I(&amp;quot;black&amp;quot;), size = 2) +
  ggtitle(&amp;quot;Ridge Penalty&amp;quot;) +
  theme_minimal(base_size = 20)

# Extract optimal LASSO beta weights from CV
betas_lasso &amp;lt;- fit_lasso$beta[,which(cv_lasso$lambda==cv_lasso$lambda.min)]

# Plot posterior distributions and frequentist point estimates
p2 &amp;lt;- mcmc_areas(as.array(fit_bayes_lasso), pars = paste0(&amp;quot;beta[&amp;quot;, 1:7, &amp;quot;]&amp;quot;), 
           prob = 0.8, prob_outer = 0.99) +
  geom_point(x = betas_lasso, y = 7:1, color = I(&amp;quot;#c61d29&amp;quot;), size = 2) +
  geom_point(x = betas_trad, y = 7:1, color = I(&amp;quot;black&amp;quot;), size = 2) +
  ggtitle(&amp;quot;LASSO Penalty&amp;quot;) +
  theme_minimal(base_size = 20)

# Plot in grid
cowplot::plot_grid(p1, p2, ncol = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2019-05-06-on-the-equivalency-between-the-lasso-ridge-regression-and-specific-bayesian-priors_files/figure-html/2019-05-06_fig11-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;Above, the disributions reflect the Bayesian posteriors for each &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weight (shading represents the 80% central interval, based on quantiles; bar representing the posterior mean), the red points indicate the regularized frequentist point estimates, and black points are estimates from the trditional, non-regularized frequentist regression model (shown on each plot for comparison purposes). Importantly, the traditional regression estimates are far from 0 in many cases, whereas both frequentist and Bayesian regularization estimates are much closer to 0. &lt;strong&gt;It is this conservatism that allows &lt;em&gt;biased&lt;/em&gt; estimates (from regularization/penalization) to outperform traditional models that offer &lt;em&gt;unbiased estimates&lt;/em&gt; when tested on external data&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Thus, the benefit of regularization is that we get better parameter estimates (translating to better model performance) in low and/or noisy data settings. Crucially, as we collect more and more data, the effects of regularization become less apparent. We can demonstrate this by fitting all the models above to 400—as opposed to only 20—observations and compare the coefficients to the above plot.&lt;/p&gt;
&lt;p&gt;To get started, we first go through our pre-processing steps once again:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Training data
train_dat2 &amp;lt;- grad_dat[1:400,] # Use 400 observations now

# Testing data
test_dat2 &amp;lt;- grad_dat[401:500,] # Only using last 100 now

# Scale training data (and get rid of ID)
train_scale2 &amp;lt;- scale(train_dat2[,2:9])

# Find means and SDs of training data variables
means2 &amp;lt;- attributes(train_scale2)$`scaled:center`
SDs2 &amp;lt;- attributes(train_scale2)$`scaled:scale`

# Scale test data using training data summary stats (no cheating!)
test_scale2 &amp;lt;- scale(test_dat2[,-1], center = means2, scale = SDs2)

# Prepare data for Stan
stan_dat2 &amp;lt;- list(N_train = nrow(train_scale2),
                  N_test  = nrow(test_scale2),
                  N_pred  = ncol(train_scale2)-1,
                  y_train = train_scale2[,8],
                  X_train = train_scale2[,-8],
                  X_test  = test_scale2[,-8])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, we re-fit all the models:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Fit linear regression
fit_lr2 &amp;lt;- lm(Chance.of.Admit ~ ., data = as.data.frame(train_scale2))

# Fit and cross-validate ridge
fit_ridge2 &amp;lt;- glmnet(x = train_scale2[,-8], y = train_scale2[,8], 
                     alpha = 0, lambda = lambdas, intercept = F)
cv_ridge2 &amp;lt;- cv.glmnet(x = train_scale2[,-8], y = train_scale2[,8], 
                       alpha = 0, lambda = lambdas, intercept = F)

# Fit the model using Stan&amp;#39;s NUTS HMC sampler
fit_bayes_ridge2 &amp;lt;- sampling(bayes_ridge, stan_dat2, iter = 2000, 
                             warmup = 500, chains = 3, cores = 3)
# Fit and cross-validate LASSO
fit_lasso2 &amp;lt;- glmnet(x = train_scale2[,-8], y = train_scale2[,8], 
                     alpha = 1, lambda = lambdas, intercept = F)
cv_lasso2 &amp;lt;- cv.glmnet(x = train_scale2[,-8], y = train_scale2[,8], 
                       alpha = 1, lambda = lambdas, intercept = F)
# Fit the model using Stan&amp;#39;s NUTS HMC sampler
fit_bayes_lasso2 &amp;lt;- sampling(bayes_lasso, stan_dat2, iter = 2000, 
                             warmup = 500, chains = 3, cores = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And time to plot!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Extract beta weights from traditional regression model
betas_trad2 &amp;lt;- fit_lr2$coefficients[-1]

# Extract optimal ridge beta weights from CV
betas_ridge2 &amp;lt;- fit_ridge2$beta[,which(cv_ridge2$lambda==cv_ridge2$lambda.min)]

# Plot posterior distributions and frequentist point estimates
p3 &amp;lt;- mcmc_areas(as.array(fit_bayes_ridge2), pars = paste0(&amp;quot;beta[&amp;quot;, 1:7, &amp;quot;]&amp;quot;), 
           prob = 0.8, prob_outer = 0.99, point_est = &amp;quot;mean&amp;quot;) +
  geom_point(x = betas_ridge2, y = 7:1, color = I(&amp;quot;#c61d29&amp;quot;), size = 2) +
  geom_point(x = betas_trad2, y = 7:1, color = I(&amp;quot;black&amp;quot;), size = 2, alpha = .6) +
  ggtitle(&amp;quot;Ridge Penalty&amp;quot;) +
  theme_minimal(base_size = 20)

# Extract optimal LASSO beta weights from CV
betas_lasso2 &amp;lt;- fit_lasso2$beta[,which(cv_lasso2$lambda==cv_lasso2$lambda.min)]

# Plot posterior distributions and frequentist point estimates
p4 &amp;lt;- mcmc_areas(as.array(fit_bayes_lasso2), pars = paste0(&amp;quot;beta[&amp;quot;, 1:7, &amp;quot;]&amp;quot;), 
           prob = 0.8, prob_outer = 0.99) +
  geom_point(x = betas_lasso2, y = 7:1, color = I(&amp;quot;#c61d29&amp;quot;), size = 2) +
  geom_point(x = betas_trad2, y = 7:1, color = I(&amp;quot;black&amp;quot;), size = 2, alpha = .6) +
  ggtitle(&amp;quot;LASSO Penalty&amp;quot;) +
  theme_minimal(base_size = 20)

cowplot::plot_grid(p3, p4, ncol = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2019-05-06-on-the-equivalency-between-the-lasso-ridge-regression-and-specific-bayesian-priors_files/figure-html/2019-05-06_fig12-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;Woah! Unlike before, all of our estimates pretty much fall right on top of each other. Because this dataset has both: (1) many observations, and (2) a relatively high signal-to-noise ratio, both traditional and regularized regression methods offer the same conclusion when we make use the full training dataset.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;discussion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Discussion&lt;/h1&gt;
&lt;p&gt;In this post, we learned about the benefits of using regularized/penalized regression models over traditional regression. We determined that in low and/or noisy data settings, the so-called &lt;em&gt;unbiased&lt;/em&gt; estimates given by traditional regression modeling actually lead to worse-off model performance. Importantly, we learned that this occurs because being ubiased allows a model to learn a lot from the data, including learning patterns of noise. Then, we learned that &lt;em&gt;biased&lt;/em&gt; methods such as ridge and LASSO regression restrict the amount of learning that we get from data, which leads to better estimates in low and/or noisy data settings.&lt;/p&gt;
&lt;p&gt;Finally, we saw that hierarchical Bayesian models actually contain frequentist ridge and LASSO regression as a special case—namely, we can choose a prior distribution across the &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; weights that gives us a solution that is equivalent to that of the frequentist ridge or LASSO methods! Not only that, but Bayesian regression gives us a full posterior distribution for each parameter, thus circumventing problems with frequentist regularization that require the use of bootstrapping to estimate confidence intervals.&lt;/p&gt;
&lt;div id=&#34;so-what&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;So What?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Psychology&lt;/strong&gt;—and many other areas of social and behavoiral science—&lt;strong&gt;is in the midst of a replication crisis&lt;/strong&gt;. While many factors are at play here, one problem is that the methods we use to draw inference from our data are too liberal. Taken with the high measurement error, low sample sizes, and lack of mechanistic models in our research areas, we are bound to overestimate the &lt;a href=&#34;https://statmodeling.stat.columbia.edu/2004/12/29/type_1_type_2_t/&#34;&gt;magnitude (and even miss the sign&lt;/a&gt;) of effects that we are interested in if we continue to use methods that are prone to overfitting. &lt;strong&gt;&lt;em&gt;Regularization provides an elegant solution to this problem of “learning too much” from our data&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Moving forward, I hope that you consider regularizing your models! (and if you are feeling really fancy, go Bayes! Embrace the uncertainty!)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Using computer-vision and machine learning to automate facial coding of positive and negative affect intensity</title>
      <link>http://haines-lab.com/publication/haines_plos_one_2019/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://haines-lab.com/publication/haines_plos_one_2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task</title>
      <link>http://haines-lab.com/publication/haines_cog_sci_2018/</link>
      <pubDate>Fri, 05 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>http://haines-lab.com/publication/haines_cog_sci_2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Human Choice and Reinforcement Learning (3)</title>
      <link>http://haines-lab.com/post/2018-03-24-human-choice-and-reinforcement-learning-3/</link>
      <pubDate>Sat, 08 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>http://haines-lab.com/post/2018-03-24-human-choice-and-reinforcement-learning-3/</guid>
      <description>&lt;div id=&#34;goals-of-paramter-estimation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;1. Goals of Paramter Estimation&lt;/h1&gt;
&lt;p&gt;When estimating paramters for a given model, we typically aim to make an inference on an individual’s underlying decision process. We may be inferring a variety of different factors, such as the rate at which someone updates their expectations, the way that someone subjectively values an outcome, or the amount of exploration versus exploitation that someone engages in. Once we estimate an individual’s parameters, we can compare then to other people or even other groups of people. Further, we can compare parameters within subjects after an experimental manipulation (e.g., &lt;em&gt;does drug X affect a person’s learning rate?&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Below, we will explore multiple paremter estimation methods. Specifically, we will use: (1) maximum likelihood estimation, (2) maximum a posteriori estimation, (3) and fully Bayesian estimation. First, we will simulate data from models described in the previous post on a simple 2-armed bandit task. Importantly, we will simulate data using &lt;em&gt;known parameter values&lt;/em&gt;, which we will then try to recover from the simulated data. We will refer to the known paramters as the &lt;em&gt;true paramters&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simulation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;2. Simulation&lt;/h1&gt;
&lt;p&gt;For our simulation, we will simulate choice from a model using delta-rule learning and softmax choice. To keep things simple, the learning rate will be the only free paramter in the model. Additionally, we will simulate choices in a task where there are two choices, where choice 1 has a mean payoff of 1 and choice 2 has a mean payoff of -1. Therefore, a learning agent should be able to learn that choice 1 is optimal and make selections accordingly. However, we will add noise to each choice payoff (&lt;em&gt;sigma&lt;/em&gt; below) to make things more realistic.&lt;/p&gt;
&lt;p&gt;The following R code simulates 100 trials using the model ans task described above:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# For pretty plots
library(ggplot2)
library(foreach)

# Simulation paramters
set.seed(1)        # Random seed for replication
mu    &amp;lt;- c(1, -1)  # Mean payoff for choices 1 and 2 
sigma &amp;lt;- 2         # SD of payoff distributions
n_tr  &amp;lt;- 100       # Number of trials 
beta  &amp;lt;- 0.1       # True learning rate

# Initial expected value
ev &amp;lt;- c(0, 0) 

# Softmax choice function
logsumexp &amp;lt;- function (x) {
  y &amp;lt;- max(x)
  y + log(sum(exp(x - y)))
}
softmax &amp;lt;- function (x) {
  exp(x - logsumexp(x))
}

# Simulate data
sim_dat &amp;lt;- foreach(t=1:n_tr, .combine = &amp;quot;rbind&amp;quot;) %do% {
  # Generate choice probability with softmax
  pr &amp;lt;- softmax(ev)
  
  # Use choice probability to sample choice
  choice &amp;lt;- sample(c(1,2), size = 1, prob = pr)
  
  # Generate outcome based on choice
  outcome &amp;lt;- rnorm(1, mean = mu[choice], sd = sigma)
  
  # Delta-rule learning
  ev[choice] &amp;lt;- ev[choice] + beta * (outcome - ev[choice])
  
  # Save data
  data.frame(Trial   = rep(t, 2),
             EV      = ev,
             Pr      = pr,
             Option  = paste(1:2),
             Choice  = rep(choice, 2),
             Outcome = rep(outcome, 2))
}

# Change in expected values across tirals
ggplot(sim_dat, aes(x = Trial, y = EV, geom = &amp;quot;line&amp;quot;, color = Option)) +
  geom_line() +
  scale_color_manual(values = c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;)) +
  ylab(&amp;quot;Expected Value&amp;quot;) +
  theme_minimal(base_size = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2018-03-24-human-choice-and-reinforcement-learning-3_files/figure-html/2018-09-08_fig1-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;The above graph shows the simulated agent’s expected value (&lt;em&gt;EV&lt;/em&gt;) for options 1 and 2 across the 100 trials. We can also view the probability of selecting each option across trials:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Change in probability of selecting each option across tirals
ggplot(sim_dat, aes(x = Trial, y = Pr, geom = &amp;quot;line&amp;quot;, color = Option)) +
  geom_line() +
  scale_color_manual(values = c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;)) +
  ylab(&amp;quot;Pr(Choice)&amp;quot;) +
  theme_minimal(base_size = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2018-03-24-human-choice-and-reinforcement-learning-3_files/figure-html/2018-09-08_fig2-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;Clearly, the agent learns to prefer option 1 over option 2 across trials. Although we know the true learning rate (i.e. &lt;span class=&#34;math inline&#34;&gt;\(\beta_{true} = 0.1\)&lt;/span&gt;), we will explore the various parameter estimation techniques below to try and recover &lt;span class=&#34;math inline&#34;&gt;\(\beta_{true}\)&lt;/span&gt; from the simulated data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimation-methods&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;3. Parameter Estimation Methods&lt;/h1&gt;
&lt;div id=&#34;maximum-likelihood&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3.1 Maximum Likelihood&lt;/h2&gt;
&lt;p&gt;The goal of maximum likelihood estimation (MLE) is to identify the single, most likely parameter value(s) that could have produced the observed data. For our purposes, MLE will allow us to estimate the learning rate that maximizes the probability of observing the simulated data. We refer to his estimate as &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt; (pronounced beta-hat).&lt;/p&gt;
&lt;p&gt;Before moving on, it is worth introducing some new notation. If we refer to the observed data as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and the parameters we aim to estimate as &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, we can refer to the likelihood function as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Pr(X|\theta)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In our case, &lt;span class=&#34;math inline&#34;&gt;\(\theta = \hat{\beta}\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is the vector of simulated choices from above. So then, how do we actually compute the probability of choices &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; given learning rate &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt;? Simple! We use the model that we simulated the data from. Specifically, we:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Make a guess for &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Look into &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and find out what choice and outcome the agent made/experienced on trial &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Use our guess for &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt; to update the EV for the chosen option accoring to the model&lt;/li&gt;
&lt;li&gt;Enter the updated EVs into the softmax function to generate the probability of selecting each option for the next trial&lt;/li&gt;
&lt;li&gt;Store the model-estimated probability of selecting the choice that the agent actually made on trial &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We iterate through these steps for each trial &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; in &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, and then multiply the probabilities across all trials. In practice, we take the natural log of the probability on each trial and then sum across trials, which is equivalent to multiplying out the probabilities but is more numerically stable (computers don’t like really small numbers!). We can write out this &lt;em&gt;log-likelihood&lt;/em&gt; as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sum_{t=1}^{T}{\text{ln } Pr(Choice_{t}|\hat{\beta})}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We are not finished yet! Once we compute the above sum for a given guess for &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt;, we will run through all the steps again with a new guess for &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt;. We continue to make guesses and calculate the above sum until we find a value &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt; that gives us the maximum probability—this final value is the &lt;em&gt;maximum likelihood estimate (MLE)&lt;/em&gt;, written as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{\beta}_{MLE} = \underset{\hat{\beta}}{\text{arg max}}\sum_{t=1}^{T}{\text{ln } Pr(Choice_{t}|\hat{\beta})}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Our goal is to find the value for &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt; that maximizes the above sum. Now, we could accomplish this by sampling random learning rates between 0 and 1, computing the sum for each value, and then determining which value produces the highest log-likelihood. Alternatively, we could create a grid of values from 0 to 1 (i.e. &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta} \in \text{{0.01, 0.02, ..., 0.99}}\)&lt;/span&gt;) and select the MLE as the value with the highest log-likelihood. In the real world, however, we usually use some sort of optimization algorithm that makes our job much easier. Below, we will use the &lt;strong&gt;optim&lt;/strong&gt; function in R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Define the log-likelihood function used for MLE
mle_bandit &amp;lt;- function(X, beta, outcomes)  {
  # Initialize expected value
  ev &amp;lt;- c(0, 0)
  # loop through each trial and compute log-likelihood
  ll &amp;lt;- foreach(t=seq_along(X), .combine = &amp;quot;c&amp;quot;) %do% {
    # Generate choice probability with softmax
    pr &amp;lt;- softmax(ev)
    
    # Delta-rule learning
    ev[X[t]] &amp;lt;- ev[X[t]] + beta * (outcomes[t] - ev[X[t]])
    
    # log probability of &amp;quot;true&amp;quot; simulated choice
    log(pr[X[t]])
  }
  
  # return the summed (minus) log-likelihood, because optim minimizes by default
  sum(-1*ll)
}

# Use optim to minimize the (minus) log-likelihood function
mle_results &amp;lt;- optim(par      = 0.5,             # Initial guess for beta
                     fn       = mle_bandit,      # Function we are minimizing
                     method   = &amp;quot;L-BFGS-B&amp;quot;,      # Specific algorithm used
                     lower    = 0,               # Lower bound for beta 
                     upper    = 1,               # Upper bound for beta
                     X        = sim_dat$Choice,  # Simulated choices
                     outcomes = sim_dat$Outcome) # Simulated choice outcomes

# Print results
cat(&amp;quot;The MLE for beta is: &amp;quot; , round(mle_results$par, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The MLE for beta is:  0.079&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Not bad! &lt;strong&gt;optim&lt;/strong&gt; returns a MLE of &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta} =\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(0.079\)&lt;/span&gt;. Given that &lt;span class=&#34;math inline&#34;&gt;\(\beta_{true} = 0.1\)&lt;/span&gt; (since we determined the value for the simulations), our estimate &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt; is not that far off. One potential downside of the MLE approach we used above is that we only receive a single value for the MLE, which makes it difficult to know how certain the estimate is. For example, our simulation was for 100 trials, but surely we would be more confident in the estimate if the simulation was for 1,000’s of trials! MLE alone does not offer an explicit measure of uncertainty in the parameter estimates without additional analyses (and additional assumptions), which is one reason that Bayesian methods are easier to interpret.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;maximum-a-poseriori-map-estimation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3.2 Maximum A Poseriori (MAP) Estimation&lt;/h2&gt;
&lt;p&gt;MAP estimation is a straightforward extention of MLE, which allows us to incorporate prior information about the parameter that we are trying to estimate into the estimation procedure. In our example, we may know from prior studies that learning rates for a given task typically fall in the range of 0.05-0.4. MAP estimation allows us to formalize this prior research in a very simple way! We simply parameterize a prior distribution (&lt;span class=&#34;math inline&#34;&gt;\(Pr(\beta)\)&lt;/span&gt;) that is consistent with estimates from prior studies. For example, a normal distribution with a &lt;span class=&#34;math inline&#34;&gt;\(\mu = .2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma = 0.5\)&lt;/span&gt; captures the above range nicely but does not constrain the values too much:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- seq(0, 1, length=1000)
y &amp;lt;- dnorm(x, mean = .2, sd = .5)
qplot(x = x, y = y, geom = &amp;quot;line&amp;quot;, xlab = expression(beta[prior]), ylab = &amp;quot;Density&amp;quot;) +
  theme_minimal(base_size = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2018-03-24-human-choice-and-reinforcement-learning-3_files/figure-html/2018-09-08_fig4-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;So, how do we include this prior information? Easy! When we make a guess for &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt;, we will compute the likelihood just like we did for MLE, and we will multiple this value by the “likelihood” of the prior. Intuitively, this allows us to &lt;em&gt;weight&lt;/em&gt; the likelihood of each possible value for &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt; by the prior for that same value of &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt;. This behavior results in a sort of trade off between the likelihood and prior distribution, which ends up &lt;strong&gt;regularizing&lt;/strong&gt; our MLE estimate by pulling it toward the center mass of the prior distribution. Formally, we represent this by adding the prior distribution (bolded) to the MLE function from above:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{\beta}_{MAP} = \underset{\hat{\beta}}{\text{arg max}}\sum_{t=1}^{T}{\text{ln } Pr(Choice_{t}|\hat{\beta})\bf{Pr(\beta)}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let’s see what this looks like in R, and note how it affects estimation of &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Define the log-likelihood function used for MAP
map_bandit &amp;lt;- function(X, beta, outcomes)  {
  # Initialize expected value
  ev &amp;lt;- c(0, 0)
  # loop through each trial and compute log-likelihood
  ll &amp;lt;- foreach(t=seq_along(X), .combine = &amp;quot;c&amp;quot;) %do% {
    # Generate choice probability with softmax
    pr &amp;lt;- softmax(ev)
    
    # Delta-rule learning
    ev[X[t]] &amp;lt;- ev[X[t]] + beta * (outcomes[t] - ev[X[t]])
    
    # Probability/likelihood of &amp;quot;true&amp;quot; simulated choice
    like &amp;lt;- pr[X[t]]
    
    # Likelihood of current beta according to prior distribution
    prior &amp;lt;- dnorm(x = beta, mean = .2, sd = 0.5)
    
    # Log of like*prior
    log(like*prior)
  }
  
  # return the summed (minus) log-likelihood with prior information included
  sum(-1*ll)
}

# Use optim to minimize the (minus) log-likelihood function
map_results &amp;lt;- optim(par      = 0.5,             # Initial guess for beta
                     fn       = map_bandit,      # Function we are minimizing
                     method   = &amp;quot;L-BFGS-B&amp;quot;,      # Specific algorithm used
                     lower    = 0,               # Lower bound for beta 
                     upper    = 1,               # Upper bound for beta
                     X        = sim_dat$Choice,  # Simulated choices
                     outcomes = sim_dat$Outcome) # Simulated choice outcomes

# Print results
cat(&amp;quot;The MAP for beta is: &amp;quot; , round(map_results$par, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The MAP for beta is:  0.145&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Woah! The simple addition of prior information pushed our estimate of &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta} =\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(0.079\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta} =\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(0.145\)&lt;/span&gt;. Notice that the MAP estimator was pulled toward the mean of the prior distribution. However, is this a good thing? When is this behavior beneficial? After all, both estimates are about equidistant from &lt;span class=&#34;math inline&#34;&gt;\(\beta_{true}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;To demonstrate the benefit of prior information, let’s take the simulated data from our learner (i.e. &lt;span class=&#34;math inline&#34;&gt;\(\beta = 0.1\)&lt;/span&gt;), but only fit the model using the first 15 trials worth of data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Use MLE to fit the first 15 trials
mle_results_15tr &amp;lt;- optim(par      = 0.5,             
                          fn       = mle_bandit,      
                          method   = &amp;quot;L-BFGS-B&amp;quot;,      
                          lower    = 0,               
                          upper    = 1,               
                          X        = sim_dat$Choice[1:15],  # Only using first 15 trials
                          outcomes = sim_dat$Outcome[1:15]) 

# Use MAP to fit the first 15 trials
map_results_15tr &amp;lt;- optim(par      = 0.5,             
                          fn       = map_bandit,      
                          method   = &amp;quot;L-BFGS-B&amp;quot;,      
                          lower    = 0,               
                          upper    = 1,               
                          X        = sim_dat$Choice[1:15],  # Only using first 15 trials
                          outcomes = sim_dat$Outcome[1:15]) 

cat(&amp;quot;The MLE for beta with 15 trials is: &amp;quot; , round(mle_results_15tr$par, 3), &amp;quot;\n&amp;quot;, 
    &amp;quot;The MAP for beta with 15 trials is: &amp;quot; , round(map_results_15tr$par, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The MLE for beta with 15 trials is:  0.06 
##  The MAP for beta with 15 trials is:  0.099&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Look at that! MLE underestimates the learning rate, whereas MAP gives us a great estimate. There are two main take-aways from this toy example:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;MLE is prone to degenerate behavior in low data settings, which can push parameters to the edge of the parameter space (i.e. 0 when the range is from 0 to 1), and&lt;/li&gt;
&lt;li&gt;Introduction of our own, theory-based form of bias (i.e. regularization from the prior distribution) can help us avoid estimation problems—espectially in low data settings! (this will become clearer in future posts)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In fact, you may have realized through the above example (or math) that MLE is just a sepcial case of MAP estimation! If it is not already intuitive, think of this—what would happen to our MAP estimate if we assumed that the prior distribution was uniform (i.e. all values between 0 and 1 are equally likely for learning rate &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;)? Well, we would have to multiply &lt;span class=&#34;math inline&#34;&gt;\(Pr(Choice_{t}|\hat{\beta})\)&lt;/span&gt; by 1 for each guess of &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt;! See this yourself by observing the likelihood of different values for &lt;code&gt;x&lt;/code&gt; drawn from a uniform distribution (code: &lt;code&gt;dunif(x = .2, min = 0, max = 1)&lt;/code&gt;). Therfore, MAP is analytically equivalent to MLE when we assume a uniform prior distibution. Of course, in many settings, we know that certain paremter values are very unlikely (e.g., a learning rate of .2 is more reasonable than of .99 in most settings). It follows that assuming a uniform distribution for the prior can be quite (mis)informative!&lt;/p&gt;
&lt;p&gt;Note that MAP, like MLE, only offers a point estimate. Again, we would ideally like a proper representation of uncertainty for our estimate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;markov-chain-monte-carlo-mcmc-estimation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3.3 Markov Chain Monte Carlo (MCMC) Estimation&lt;/h2&gt;
&lt;p&gt;We have finally arrived… MCMC builds on all of the above estimation methods, resulting in a powerful estimation procedure that gives as an entire distribution—rather than just a point estimate—to represent a parameter.&lt;/p&gt;
&lt;p&gt;To begin, we will first introduce Bayes’ Theorem; you have likely seen is before:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Pr(\theta | X) = \frac{Pr(X | \theta)Pr(\theta)}{Pr(X)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In English, this translates to:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{Posterior Distribution} = \frac{\text{Likelihood} \cdot \text{Prior Distribution}}{\text{Marginal Distribution}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;You may notice that the numerator (i.e. &lt;span class=&#34;math inline&#34;&gt;\(Pr(X | \theta)Pr(\theta)\)&lt;/span&gt;) looks suspiciously like the term we were trying to maximize for MAP estimation (&lt;span class=&#34;math inline&#34;&gt;\(Pr(Choice_{t}|\hat{\beta})Pr(\beta)\)&lt;/span&gt;)…which is because MAP estimation is indeed derived from Bayes’ Theorem! In fact, the MAP estimate is the &lt;em&gt;mode of the posterior distribution&lt;/em&gt;, which explains why it is called &lt;strong&gt;maximum a posteriori&lt;/strong&gt; estimation.&lt;/p&gt;
&lt;p&gt;So then, we already know what the numerator corresponds to, but what of the denominator? Referring back to our simulation, the marginal distribution &lt;span class=&#34;math inline&#34;&gt;\(Pr(X)\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(Pr(Choices)\)&lt;/span&gt;, which is interpreted as the probability of the observed data—what exactly does this mean? Well, it turns out that for our purposes, it is not too important! &lt;span class=&#34;math inline&#34;&gt;\(Pr(Choices)\)&lt;/span&gt; is a constant term, and it does not depend on the model we are trying to estimate parameters for. Therefore, we often write:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Pr(\theta | X) \propto Pr(X | \theta)Pr(\theta)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Which translates to “&lt;em&gt;the posterior distribution is &lt;strong&gt;proportional to&lt;/strong&gt; the likelihood times the prior distribution&lt;/em&gt;”. Intuitively, this means that it is the relative differences in &lt;span class=&#34;math inline&#34;&gt;\(Pr(X | \theta)Pr(\theta)\)&lt;/span&gt; across different values of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; that give us information about the posterior distribution. Importantly, we already know how to work with this numerator term (from doing MAP estimation)! Therefore, fully Bayesian estimation using MCMC only requires a small extention. Specifically, instead of using optimization (i.e. R’s &lt;code&gt;optim&lt;/code&gt; function) to find a single value of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; that maximizes &lt;span class=&#34;math inline&#34;&gt;\(Pr(X | \theta)Pr(\theta)\)&lt;/span&gt;, we want to use a method that tells us how likely all possible values of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; are relative to each other (i.e. a distribution!). While there are many different algorithms that can be used to accomplish this, we will start with the &lt;a href=&#34;https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm&#34;&gt;Metropolis&lt;/a&gt; algorithm. Referring back to our learning data, estimating &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt; using the Metropolis algorithm proceeds with the steps outlined below.&lt;/p&gt;
&lt;p&gt;For &lt;span class=&#34;math inline&#34;&gt;\(n = 1, 2, ..., N:\)&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Propose a value &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}&amp;#39;\)&lt;/span&gt; that is near your current guess &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_{n}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Calculate the &lt;em&gt;acceptance ratio&lt;/em&gt;, defined by &lt;span class=&#34;math inline&#34;&gt;\(accept = \frac{Pr(Choices | \hat{\beta}&amp;#39;)Pr(\hat{\beta}&amp;#39;)}{Pr(Choices | \hat{\beta}_{n})Pr(\hat{\beta}_{n})}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Generate a uniform random number &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\([0,1]\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;If &lt;span class=&#34;math inline&#34;&gt;\(u \le accept\)&lt;/span&gt;, set &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_{n+1} = \hat{\beta}&amp;#39;\)&lt;/span&gt;, otherwise set &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_{n+1} = \hat{\beta}_{n}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Importantly, while iterating through all samples &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;, we store each value &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_{n}\)&lt;/span&gt;. This sequence of values &lt;em&gt;is the posterior distribution&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;\(Pr(\hat{\beta}|Choices)\)&lt;/span&gt;. The R code below shows the Metropolis algorithm in action, and the resulting histogram of posterior samples:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note that this takes a few minutes to run because it is not optimized in the least bit!&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Set number of samples N for the Metropolis algorithm
samples &amp;lt;- 5000

# Set initial guess for beta
beta_n &amp;lt;- 0.5

# Take what we did above for MAP estimation and make into a function
calc_like &amp;lt;- function(beta, X, outcomes) {
  # Initialize expected value
  ev &amp;lt;- c(0, 0)
  # loop through each trial and compute log-likelihood
  ll &amp;lt;- foreach(t=seq_along(X), .combine = &amp;quot;c&amp;quot;) %do% {
    # Generate choice probability with softmax
    pr &amp;lt;- softmax(ev)
    
    # Delta-rule learning
    ev[X[t]] &amp;lt;- ev[X[t]] + beta * (outcomes[t] - ev[X[t]])
    
    # Probability/likelihood of &amp;quot;true&amp;quot; simulated choice
    like &amp;lt;- pr[X[t]]
    
    # Likelihood of current beta according to prior distribution
    prior &amp;lt;- dnorm(x = beta, mean = .2, sd = 0.5)
    
    # log of like*prior
    log(like*prior)
  }
  
  # return the summed log-likelihood with prior information included
  sum(ll)
}

# Iterate through N samples and store each result
posterior &amp;lt;- foreach(n=1:samples, .combine = &amp;quot;c&amp;quot;) %do% {
  # Step 1: Generate random proposal value with normal distribution
  beta_proposal &amp;lt;- rnorm(1, mean = beta_n, sd = .01)
  
  # If proposal is outside of parameter bounds, keep current sample, else continue
  if (0 &amp;lt; beta_proposal &amp;amp; beta_proposal &amp;lt; 1) {
    # Step 2: Calculate acceptance ratio
    like_proposal &amp;lt;- exp(calc_like(beta_proposal, sim_dat$Choice, sim_dat$Outcome))
    like_current  &amp;lt;- exp(calc_like(beta_n, sim_dat$Choice, sim_dat$Outcome))
    accept &amp;lt;- like_proposal/like_current
    
    # Step 3: Generate uniform random number on [0,1]
    u &amp;lt;- runif(1, min = 0, max = 1)
    
    # Step 4: Accept or reject proposal
    if (u &amp;lt;= accept) {
      beta_n &amp;lt;- beta_proposal
    }
  }
  
  # Retern beta_n (either updated with proposal or remains the same)
  beta_n
}

# Plot time-series of posterior samples
qplot(x = 1:samples, y = posterior, geom = &amp;quot;line&amp;quot;) + 
  geom_hline(aes(yintercept= beta, linetype = &amp;quot;True Beta&amp;quot;), color= &amp;#39;red&amp;#39;) +
  scale_linetype_manual(name = &amp;quot;&amp;quot;, values = 2) +
  xlab(&amp;quot;Posterior Sample&amp;quot;) +
  ylab(expression(hat(beta))) +
  theme_minimal(base_size = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2018-03-24-human-choice-and-reinforcement-learning-3_files/figure-html/2018-09-08_fig7-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;This &lt;em&gt;traceplot&lt;/em&gt; shows each accepted proposal across all 5,000 samples that we drew from the posterior distribution. As you can see, the samples are all distributed around the true value once they converge to a stable estimate. The samples at the beginning (before reaching convergence) will be discarded (termed &lt;em&gt;burn-in&lt;/em&gt; samples) for further analyses because they do not represent the posterior distribution. Unlike for MLE or MAP estimation, all the posterior samples after burn-in can be used to represent the uncertainty in the learning rate parameter! We simply plot a histogram of the samples:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qplot(posterior[200:5000], geom = &amp;quot;histogram&amp;quot;) +
  geom_vline(aes(xintercept= beta, linetype = &amp;quot;True Beta&amp;quot;), color= &amp;#39;red&amp;#39;) +
  scale_linetype_manual(name = &amp;quot;&amp;quot;, values = 2) +
  xlab(expression(hat(beta))) +
  ylab(&amp;quot;Frequency&amp;quot;) +
  theme_minimal(base_size = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2018-03-24-human-choice-and-reinforcement-learning-3_files/figure-html/2018-09-08_fig8-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;wrapping-up&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;4. Wrapping up&lt;/h1&gt;
&lt;p&gt;In this post, we covered three methods of parameter estimation including: (1) maximum likelihood estimation, (2) maximum a posteriori estimation, and (3) markov chain monte carlo estimation. In the future, we will use software packages (particularly &lt;a href=&#34;https://mc-stan.org/&#34;&gt;Stan&lt;/a&gt;) to do MCMC for us, which will allow us to more rapidly estimate parameters compared to our simplistic MCMC implementation above. In the next post, we will use Stan to estimate the same learning rate from the model above. Soon after, we will work towards fitting hierarchical models!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>FEAT</title>
      <link>http://haines-lab.com/project/feat/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>http://haines-lab.com/project/feat/</guid>
      <description>&lt;p&gt;This project is currently at the beginning stages of development. Come back in a few months for an update!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Easyml: Easily Build And Evaluate Machine Learning Models</title>
      <link>http://haines-lab.com/publication/easyml/</link>
      <pubDate>Tue, 31 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>http://haines-lab.com/publication/easyml/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Indirect Effect of Emotion Regulation on Minority Stress and Problematic Substance Use in Lesbian, Gay, and Bisexual Individuals</title>
      <link>http://haines-lab.com/publication/minority_stress/</link>
      <pubDate>Wed, 25 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>http://haines-lab.com/publication/minority_stress/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Linking emotion to decision making through model-based facial expression analysis</title>
      <link>http://haines-lab.com/talk/math_psych_2017/</link>
      <pubDate>Sun, 23 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>http://haines-lab.com/talk/math_psych_2017/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Human Choice and Reinforcement Learning (2)</title>
      <link>http://haines-lab.com/post/2017-04-07-human-choice-and-reinforcement-learning-2/</link>
      <pubDate>Fri, 07 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>http://haines-lab.com/post/2017-04-07-human-choice-and-reinforcement-learning-2/</guid>
      <description>&lt;div id=&#34;answer-to-post-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;1. Answer to post 1&lt;/h1&gt;
&lt;p&gt;In the previous &lt;a href=&#34;http://haines-lab.com/2017/04/04/human-choice-and-reinforcement-learning-1/&#34;&gt;post&lt;/a&gt;, I reviewed the Rescorla-Wagner updating (Delta) rule and its contemporary instantiation. At the end, I asked the following question:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;How should you change the learning rate so that the expected win rate is always the average of all past outcomes?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We will go over the answer to this question before progressing to the use of the Delta rule in modeling human choice. To begin, refer back to the Delta rule written in the following form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Pr(win)_{t+1} = (1 - \beta) \cdot Pr(win)_{t} + \beta \cdot \lambda_{t}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here, we see that in the Delta rule the expected win probability for the next trial is equal to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average&#34;&gt;&lt;em&gt;exponentially weighted moving average&lt;/em&gt;&lt;/a&gt; of the past expectation and the current outcome. It is easy to show this through a visualization of the expectation over time. For example, imagine that we have a vector of outcomes &lt;span class=&#34;math inline&#34;&gt;\(\lambda = [1,0,0,1,1,1,0,1,1,1]\)&lt;/span&gt;, where 0 and 1 represent losing and winning slot machine rolls, respectively. Note that in this example, the placement of these outcomes within the vector &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; indicates their temporal order (i.e. &lt;span class=&#34;math inline&#34;&gt;\(\lambda_{1}=1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\lambda_{2}=0\)&lt;/span&gt;, etc.). Now, if we set an arbitrary learning rate such as &lt;span class=&#34;math inline&#34;&gt;\(\beta = 0.05\)&lt;/span&gt;, what is the expected win rate after iterating through outcomes &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;? The R code below demonstrates the use of the Delta rule and an alternative exponential weighting scheme–which takes the form of a &lt;a href=&#34;https://en.wikipedia.org/wiki/Power_series#Examples&#34;&gt;&lt;em&gt;power series&lt;/em&gt;&lt;/a&gt;–to determine the expectation on each trial:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# For pretty plots
library(ggplot2)

# Assign lambda (lambda[1] == first trial)
lambda &amp;lt;- c(1,0,0,1,1,1,0,1,1,1)

# Set learning rate
beta &amp;lt;- 0.05

### Iterative prediction error (Delta rule) approach ###

# Function that iterates the Rescorla-Wagner rule 
  # This function is slightly modified from the last post
  # to ensure that that final expectation is stored
rw_update &amp;lt;- function(lambda, beta, init) {
  # To store expected value for each trial
  Pr_win &amp;lt;- vector(length=length(lambda)+1)
  # Set initial value
  Pr_win[1] &amp;lt;- init
  for (t in 1:(length(lambda))) {
    Pr_win[t+1] &amp;lt;- Pr_win[t] + beta * (lambda[t] - Pr_win[t])
  }
  return(Pr_win)
}

# With initial expectation = 0, iterate Delta rule
delta_results &amp;lt;- rw_update(lambda = lambda, 
                           beta   = beta, 
                           init   = 0)[-1]
                          #             ^
                          # Remove initial value (0)

### Power series approach ###

# Direct exponential weighting (saving all expectations)
power_ser &amp;lt;- NULL
for (i in 1:10) {
  power_ser[i] &amp;lt;- beta * sum((1-beta)^(0:(i-1))*lambda[i:1])
}

### Comparison of both approaches ###
all(round(delta_results, 8) == round(power_ser, 8))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# data.frame for ggplot
all_data &amp;lt;- stack(data.frame(delta = delta_results,
                             pow_s = power_ser))
# Add trial 
all_data[[&amp;quot;trial&amp;quot;]] &amp;lt;- rep(1:10, 2)
names(all_data)[2] &amp;lt;- &amp;quot;Approach&amp;quot;

# Visually
p &amp;lt;- ggplot(all_data, aes(x = trial, y = values, color = Approach)) + 
  geom_line() +
  facet_grid(facets = &amp;quot;Approach ~ .&amp;quot;) + 
  ggtitle(&amp;quot;Comparison of approaches&amp;quot;) +
  xlab(&amp;quot;Trial Number&amp;quot;) +
  ylab(&amp;quot;Expected Win Probability&amp;quot;)
p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2017-04-07-human-choice-and-reinforcement-learning-2_files/figure-html/2017-04-07_fig1-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;As you can see in the plots, both the Delta rule and the power series approach yield the same exact expectations when iterated for each trial. However, the power series form requires each past observation while the Delta rule only requires the last expectation–this feature makes the Delta rule form of the equation much more plausible as a processes that people may use to estimate the value of a choice. This is because the computational cost does not increase with the number of past observations.&lt;/p&gt;
&lt;p&gt;Through this example, those familiar with &lt;a href=&#34;http://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:moving_averages&#34;&gt;economics&lt;/a&gt; or &lt;a href=&#34;https://en.wikipedia.org/wiki/Signal_processing&#34;&gt;signal processing&lt;/a&gt; may find the Delta rule familiar. Essentially, we can think of the Delta rule as a smoothing function or a &lt;a href=&#34;https://en.wikipedia.org/wiki/High-pass_filter#Algorithmic_implementation&#34;&gt;high- or low-pass filter&lt;/a&gt;–albeit in the time as opposed to frequency domain–which effectively attenuates the effect of past or current outcomes, respectively. What makes this specific form interesting is again the fact that it can be iterated (i.e. it is recursive), making it a realistic approximation to the computations performed by the brain when estimating some value.&lt;/p&gt;
&lt;p&gt;With the above intuitions in mind, we will now get back to the question. How do we change the learning rate to ensure that the current expectation is always the simple average of all past outcomes? Since the above example showed that the Delta rule is really just a moving average where past outcomes are given exponentially decreasing weights, our goal is to make all outcomes equally represented. In other words, we want to weight past and current outcomes equally–this is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Moving_average#Cumulative_moving_average&#34;&gt;&lt;em&gt;cumulative moving average&lt;/em&gt;&lt;/a&gt;. Using our slot machine example, the cumulative moving average formula (in its most common form) is written as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Pr(win)_{t+1} = \frac{\lambda_{t} + (t-1) \cdot Pr(win)_{t}}{t}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can re-write the above equation into one that is more familiar to us:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Pr(win)_{t+1} = (1-\frac{1}{t}) \cdot Pr(win)_{t} + \frac{1}{t} \cdot \lambda_{t} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In the above form, you can see that the cumulative moving average can be computed using the Delta rule by setting the learning rate to &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{t}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; is the trial number. Looking at the equation, you will notice that as &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; increases, the weight &lt;span class=&#34;math inline&#34;&gt;\((1-\frac{1}{t})\)&lt;/span&gt; placed on the past probability estimate &lt;span class=&#34;math inline&#34;&gt;\(Pr(win)_{t}\)&lt;/span&gt; becomes larger while the weight &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{t}\)&lt;/span&gt; on the current outcome &lt;span class=&#34;math inline&#34;&gt;\(\lambda_{t}\)&lt;/span&gt; shrinks. This behavior ensures that past outcomes are not discounted at a higher rate than current ones.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;choice-mechanisms&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;2. Choice mechanisms&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;http://az616578.vo.msecnd.net/files/2016/08/19/636072180885324217301014601_shoes.jpg&#34; alt=&#34;Figure 1&#34; style=&#34;height: 100%; width: 100%; object-fit: contain&#34;/&gt;&lt;/p&gt;
&lt;p&gt;With the Delta rule, we can approximate how people with a certain learning rate may update their expectations about an outcome on a trial-by-trial basis, but how does this translate to choice? In the slot machine example, we only had a single choice (i.e. pull the lever and see if you win), so this question never applied to us. &lt;strong&gt;But what if we have 2 slot machines and we want to select the one that will win most frequently?&lt;/strong&gt; In this case, we can use the Delta rule to update win probability expectations for each slot machine separately, but what do we do with these values after they are computed? Below, I will describe three different methods that can be used to translate expected values to choice.&lt;/p&gt;
&lt;div id=&#34;greedy-choice&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2.1 Greedy choice&lt;/h2&gt;
&lt;p&gt;Greedy choice is simple–choose the option with the highest expected value on each trial (i.e. pick the &lt;em&gt;greedy&lt;/em&gt; option):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[c_{t} = \underset{s \in S}{argmax}(V(s_{t}))\]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(c_{t}\)&lt;/span&gt; indicates the choice made on trial &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V(s_{t})\)&lt;/span&gt; represents the value associated with Slot machine &lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt; on trial &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;. Applying this logic to our example, this would equate to choosing the slot machine with the highest expected win probability. While this may sound like a good idea, it is important to remember that we do not know what the true win rate is for either slot machine. Instead, we estimate it after each outcome. With this in mind, a simple example (below) shows why the greedy choice method fails in practical applications.&lt;/p&gt;
&lt;p&gt;Imagine you are choosing between 2 slot machines, where machine A (&lt;span class=&#34;math inline&#34;&gt;\(Slot_{A}\)&lt;/span&gt;) has a true win rate of 0.9, and machine B (&lt;span class=&#34;math inline&#34;&gt;\(Slot_{B}\)&lt;/span&gt;) has a true win rate of 0.5. Obviously, &lt;span class=&#34;math inline&#34;&gt;\(Slot_{A}\)&lt;/span&gt; is a better option, but this is something you need to learn by making a choice and updating your expectations. Assuming that you start off thinking that each slot machine has a win rate of 0 (which is typical in human decision making models), your first choice will be a random selection between the equivalent options. In our example, imagine that you randomly choose &lt;span class=&#34;math inline&#34;&gt;\(Slot_{B}\)&lt;/span&gt;, the slot machine spins, and then you win! Great, so now (regardless of your learning rate), you will update your expectation of the win rate for &lt;span class=&#34;math inline&#34;&gt;\(Slot_{B}\)&lt;/span&gt; to a positive, non-zero value. On the next trial, you are greedy, so you again choose &lt;span class=&#34;math inline&#34;&gt;\(Slot_{B}\)&lt;/span&gt;–it has a higher expected win rate than &lt;span class=&#34;math inline&#34;&gt;\(Slot_{A}\)&lt;/span&gt;. In fact, you will continue to choose &lt;span class=&#34;math inline&#34;&gt;\(Slot_{B}\)&lt;/span&gt; on each trial without ever considering &lt;span class=&#34;math inline&#34;&gt;\(Slot_{A}\)&lt;/span&gt;! In this case, even though &lt;span class=&#34;math inline&#34;&gt;\(Slot_{A}\)&lt;/span&gt; it the optimal choice, you never allow yourself to &lt;em&gt;explore&lt;/em&gt; alternative choices. Here, we come across a classical problem in reward-learning paradigms–&lt;a href=&#34;http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0095693&#34;&gt;&lt;strong&gt;&lt;em&gt;the exploration-exploitation tradeoff&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;. The crux of this problem is this: how do you know that a “good” choice is better than other choices that you have yet to explore? Think of it like choosing a job. I chose to study psychology, and I continue to exploit this choice (i.e. I am not exploring other education). How do I know that psychology is for me, though? It is possible that I would have gained more from a computer science degree, but I did not explore that option. In the same way, this compromise exists in simple reinforcement learning paradigms such as choosing the best slot machine. Below, we will explore two methods that address the exploration-exploitation problem.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;epsilon-greedy-choice&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2.2 &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;-Greedy choice&lt;/h2&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;-greedy method is a simple extention of the greedy method above. Instead of always choosing the option with the highest expected value, we sometimes (with probability &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;) randomly choose another option:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[c_{t} = \cases{
          \underset{s \in S}{argmax}(V(s_{t}))  &amp;amp; \text{with } Pr(1 - \epsilon) \cr
          \text{random choice} &amp;amp; \text{with } Pr(\epsilon)
                }
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;By choosing a random option with &lt;span class=&#34;math inline&#34;&gt;\(Pr(\epsilon)\)&lt;/span&gt;, we can avoid getting stuck choosing the non-optimal slot machine. While this method solves our dilemma, it suffers another problem–when randomly selecting options, it gives equal probabilities to each option. Intuitively, a better method would be to choose options &lt;em&gt;probabilistically with respect to their expected values&lt;/em&gt; (i.e. give high probability to relatively good options and &lt;em&gt;vice-versa&lt;/em&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;softmax-choice&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2.3 Softmax choice&lt;/h2&gt;
&lt;p&gt;Also known as the &lt;a href=&#34;https://en.wikipedia.org/wiki/Luce%27s_choice_axiom&#34;&gt;Luce choice rule&lt;/a&gt;, the softmax allows choices to be probabilistic with weights respective to expected value:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Pr(c_{t} = s \in S) = \frac{e^{V_{s}(t)}}{\sum_{s = 1}^S e^{V_{s}(t)}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(e^{V_{s}(t)}\)&lt;/span&gt; is the exponentiated expected value of slot machine &lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt; on trial &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sum_{s = 1}^S e^{V_{s}(t)}\)&lt;/span&gt; is the summation of the exponentiated expected value of both slot machines (there are 2 in our example). When the expected values are entered, the softmax equation returns a probability of selecting each slot machine which we can then use to make an actual choice. In practice, the softmax function is used most often in decision making research–moving forward, we will use the softmax choice mechanism to model human decision making.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;implementation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;3. Implementation&lt;/h1&gt;
&lt;p&gt;We now have a full model describing each of the following steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Evaluating an outcome,&lt;/li&gt;
&lt;li&gt;Updating previous representations of choice options, and&lt;/li&gt;
&lt;li&gt;Generating a probability of selecting each choice on the next trial.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This model is simple, but it provides the basic building blocks for more complex models that are found in neuroscience, cognitive science, and decision making literature today. In the next post, we will explore various methods which can be used to estimate the &lt;em&gt;free parameters&lt;/em&gt; in the model (e.g. the learning rate) when all we have are the person’s choices.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Human Choice and Reinforcement Learning (1)</title>
      <link>http://haines-lab.com/post/2017-04-04-choice_rl_1/</link>
      <pubDate>Tue, 04 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>http://haines-lab.com/post/2017-04-04-choice_rl_1/</guid>
      <description>&lt;div id=&#34;short-history&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;1. Short history&lt;/h1&gt;
&lt;p&gt;In 1972, Robert Rescorla and Allan Wagner developed a formal theory of associative learning, the process through which multiple stimuli are associated with one-another. The most widely used example (Fig. 1) of associative learning comes straight from Psychology 101–Pavlov’s dog.&lt;/p&gt;
&lt;div id=&#34;figure-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Figure 1&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;http://www.savingstudentsmoney.org/psychimg/stangor-fig07_003.jpg&#34; alt=&#34;Figure 1&#34; style=&#34;height: 100%; width: 100%; object-fit: contain&#34;/&gt;&lt;/p&gt;
&lt;p&gt;The idea is simple, and it’s something that we experience quite often in everyday life. In the same way that Pavlov’s dog begins to drool after hearing a bell, certain cognitive and/or biological processes are triggered when we are exposed to stimuli that we have been exposed to in the past. But how can this learning process be modeled? That is to say, what sort of &lt;em&gt;equation&lt;/em&gt; can we use to describe how an agent learns to associate multiple stimuli? To answer these questions, Rescorla and Wagner developed what is now know as the Rescorla-Wagner updating rule:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\Delta V_{A} = \alpha_{A} \beta_{1} (\lambda_{1} - V_{AX})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\Delta V_{X} = \alpha_{X} \beta_{1} (\lambda_{1} - V_{AX})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;First off, note that the original Rescorla-Wagner rule was developed to explain &lt;em&gt;compound stimuli&lt;/em&gt; (e.g. presentation of a bell and light, followed by food). Here, &lt;span class=&#34;math inline&#34;&gt;\(\Delta V_{A}\)&lt;/span&gt; is the change in associative strength between stimulus &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; (e.g. the bell) and the response (e.g. food). &lt;span class=&#34;math inline&#34;&gt;\(\Delta V_{X}\)&lt;/span&gt; has the same interpretation, but refers to stimulus &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; (e.g. the light).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(0 \leq \beta_{1} \leq 1\)&lt;/span&gt; is a free parameter (i.e. we estimate it from the data) referred to as the &lt;em&gt;learning rate&lt;/em&gt;. The learning rate controls how quickly updating takes place, where values near 0 and 1 reflect sluggish and rapid learning, respectively. Above, the learning rate is shared across stimuli.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(0 \leq \alpha_{A} \leq 1\)&lt;/span&gt; is a free parameter which is determined by the salience of stimulus &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(0 \leq \alpha_{X} \leq 1\)&lt;/span&gt; for stimulus &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. Unlike the learning rate, which is shared across stimuli, the salience parameter is specific to each stimulus. Put simply, this just means that learning can occur at different rates depending on the type of stimulus (e.g. I may associate a light with food more quickly than a tone).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\lambda_{1}\)&lt;/span&gt; is described as “the asymptote of associative strength”. This is the upper-limit on how strong the association strength can be. In this way, &lt;span class=&#34;math inline&#34;&gt;\(\lambda_{1}\)&lt;/span&gt; reflects the value being updated toward by the learning rate (&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;) and stimulus salience (&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Lastly, &lt;span class=&#34;math inline&#34;&gt;\(V_{AX}\)&lt;/span&gt; is the total associative strength of the compound stimulus &lt;span class=&#34;math inline&#34;&gt;\(AX\)&lt;/span&gt;. Rescorla and Wagner assume that this is a simple sum of both stimuli strengths:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[V_{AX} = V_{A} + V_{X}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Interpretation of this model is actually quite simple–we update associative strength (&lt;span class=&#34;math inline&#34;&gt;\(V_{*}\)&lt;/span&gt;) for each stimulus by taking steps (&lt;span class=&#34;math inline&#34;&gt;\(\alpha \beta\)&lt;/span&gt;) toward the difference between the asymptote of learning (&lt;span class=&#34;math inline&#34;&gt;\(\lambda_{1}\)&lt;/span&gt;) and the current associative strength of the compund stimulus (&lt;span class=&#34;math inline&#34;&gt;\(V_{AX}\)&lt;/span&gt;). By continually exposing an agent to a tone or bell paired with a reward (or punishment), the agent learns the associative strength of the conditioned and unconditioned stimuli.&lt;/p&gt;
&lt;p&gt;While the original Rescorla-Wagner model was successful for explaining associative learning for classical conditioning paradigms, what of operant conditioning? What if we are interested in how people learn to make decisions? In most current research, we are not interested in knowing how people learn to associate lights or tones with some reward. Instead, we would like a model that can describe how people learn to select the &lt;em&gt;best choice&lt;/em&gt; among &lt;em&gt;multiple choices&lt;/em&gt;. This model would need to explain how people assign values to multiple options as well as how they decide which option to choose. In statistical terms, we want to know how people solve the &lt;a href=&#34;https://en.wikipedia.org/wiki/Multi-armed_bandit&#34;&gt;&lt;em&gt;multi-armed bandit&lt;/em&gt;&lt;/a&gt; problem. In the following section, we will begin to solve this problem.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;current-implementations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;2. Current Implementations&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;http://777click.com/assets/templates/777/img/777banner.jpg&#34; alt=&#34;Figure 2&#34; style=&#34;height: 100%; width: 100%; object-fit: contain&#34;/&gt;&lt;/p&gt;
&lt;p&gt;As a motivating example, we will explore the simple problem of learning the probability that a slot machine will payoff (i.e. that you will win any amount after pulling the lever). To do so, the above equations only need minor modifications. Additionally, we will change the terminology–instead of learning an associative strength, we will now be learning the &lt;em&gt;probability of a winning outcome&lt;/em&gt;. To start, we take the first equation above and write it for a single stimulus &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt;, but exchange &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; with the probability of observing a win:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\Delta Pr(win) = \alpha \beta (\lambda - Pr(win))\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Because &lt;span class=&#34;math inline&#34;&gt;\(\Delta Pr(win) = Pr(win)_{t+1} - Pr(win)_{t}\)&lt;/span&gt; (where &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; is the current trial), we can re-write the above equation into an iterative form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Pr(win)_{t+1} = Pr(win)_{t} + \alpha \beta (\lambda_{t} - Pr(win)_{t})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Since we are using this model to explain how people learn the probability of a binary outcome, &lt;span class=&#34;math inline&#34;&gt;\(\lambda_{t} \in [0, 1]\)&lt;/span&gt; now represents the outcome of slot machine roll on trial &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;. Now, we drop the &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; parameter to simplify the model further. Because we have a single choice option, estimating both &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; would lead to an unidentifiable model. This is because as either one increases, the other can decrease and lead to the same exact predictions. Even with multiple choice options, this problem is still apparent. In current applications of the Rescorla-Wagner rule, we do not include a “salience” parameter. Now, we have:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Pr(win)_{t+1} = Pr(win)_{t} + \beta (\lambda_{t} - Pr(win)_{t})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The model is now much easier to interpret. The term &lt;span class=&#34;math inline&#34;&gt;\((\lambda_{t} - Pr(win)_{t})\)&lt;/span&gt; can be thought of as the &lt;em&gt;prediction error&lt;/em&gt;–the difference between the actual value &lt;span class=&#34;math inline&#34;&gt;\(\lambda_{t}\)&lt;/span&gt; revealed after the choice was made and the expected value of the choice &lt;span class=&#34;math inline&#34;&gt;\(Pr(win)_{t}\)&lt;/span&gt; for that trial. &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; (the learning rate) then updates the current expectation &lt;span class=&#34;math inline&#34;&gt;\(Pr(win)_{t}\)&lt;/span&gt; in the direction of the prediction error &lt;span class=&#34;math inline&#34;&gt;\((\lambda_{t} - Pr(win)_{t})\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;3. R Example&lt;/h1&gt;
&lt;p&gt;To see the Rescorla-Wagner rule in action, let’s generate some fake data using the binomial distribution and try to estimate the rate parameter using various different values for the learning rate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# For pretty images
library(ggplot2)

# Number of &amp;#39;trials&amp;#39;
num_trials &amp;lt;- 100

# The win rate is 0.7
payoff &amp;lt;- rbinom(n = num_trials, size = 1, prob = 0.7)

# Function that iterates the Rescorla-Wagner rule 
rw_update &amp;lt;- function(lambda, beta, init) {
  # To store expected value for each trial
  Pr_win &amp;lt;- vector(length=length(lambda))
  # Set initial value
  Pr_win[1] &amp;lt;- init
  for (t in 1:(length(lambda)-1)) {
    Pr_win[t+1] &amp;lt;- Pr_win[t] + beta * (lambda[t] - Pr_win[t])
  }
  return(Pr_win)
}

# With initial expectation = 0, try different learning rates
beta_05 &amp;lt;- rw_update(lambda = payoff, beta = 0.05, init = 0)
beta_25 &amp;lt;- rw_update(lambda = payoff, beta = 0.25, init = 0)
beta_50 &amp;lt;- rw_update(lambda = payoff, beta = 0.50, init = 0)
beta_75 &amp;lt;- rw_update(lambda = payoff, beta = 0.75, init = 0)
beta_95 &amp;lt;- rw_update(lambda = payoff, beta = 0.95, init = 0)

# Store in data.frame for plotting
all_data &amp;lt;- stack(data.frame(beta_05 = beta_05,
                             beta_25 = beta_25,
                             beta_50 = beta_50,
                             beta_75 = beta_75,
                             beta_95 = beta_95))
# Add trial 
all_data[[&amp;quot;trial&amp;quot;]] &amp;lt;- rep(1:num_trials, 5)
names(all_data)[2]  &amp;lt;- &amp;quot;Beta&amp;quot;

# Plot results
p &amp;lt;- ggplot(all_data, aes(x = trial, y = values, color = Beta)) + 
  geom_line() + 
  geom_hline(yintercept = 0.7, colour=&amp;quot;black&amp;quot;, linetype = &amp;quot;longdash&amp;quot;) + 
  ggtitle(&amp;quot;Expected Probability of Winning Outcome&amp;quot;) + 
  xlab(&amp;quot;Trial Number&amp;quot;) + 
  ylab(&amp;quot;Expected Pr(win)&amp;quot;)  
p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2017-04-04-choice_RL_1_files/figure-html/2017-04-02_fig1-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;It is easy to see that the higher learning rates (i.e. &amp;gt; 0.05) are jumping around the true win rate (0.7, dashed line) quite a bit, whereas setting &lt;span class=&#34;math inline&#34;&gt;\(\beta = 0.05\)&lt;/span&gt; allows for a more stable estimate. Let’s try again with learning rates closer to 0.05.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Learning rates closer to 0.05
beta_01 &amp;lt;- rw_update(lambda = payoff, beta = 0.01, init = 0)
beta_03 &amp;lt;- rw_update(lambda = payoff, beta = 0.03, init = 0)
beta_05 &amp;lt;- rw_update(lambda = payoff, beta = 0.05, init = 0)
beta_07 &amp;lt;- rw_update(lambda = payoff, beta = 0.07, init = 0)
beta_09 &amp;lt;- rw_update(lambda = payoff, beta = 0.09, init = 0)

# Store in data.frame for plotting
all_data &amp;lt;- stack(data.frame(beta_01 = beta_01,
                             beta_03 = beta_03,
                             beta_05 = beta_05,
                             beta_07 = beta_07,
                             beta_09 = beta_09))
# Add trial 
all_data[[&amp;quot;trial&amp;quot;]] &amp;lt;- rep(1:num_trials, 5)
names(all_data)[2]  &amp;lt;- &amp;quot;Beta&amp;quot;

# Plot results
p2 &amp;lt;- ggplot(all_data, aes(x = trial, y = values, color = Beta)) +
  geom_line() + 
  geom_hline(yintercept = 0.7, colour=&amp;quot;black&amp;quot;, linetype = &amp;quot;longdash&amp;quot;) + 
  ggtitle(&amp;quot;Expected Probability of Winning Outcome&amp;quot;) + 
  xlab(&amp;quot;Trial Number&amp;quot;) + 
  ylab(&amp;quot;Expected Pr(win)&amp;quot;)
p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2017-04-04-choice_RL_1_files/figure-html/2017-04-02_fig2-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;These results look a bit better. However, it is apparent that setting &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; too low is making the updating very sluggish. If we run more trials, however, we should see the expectation converge.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Number of &amp;#39;trials&amp;#39;
num_trials &amp;lt;- 500

# The win rate is 0.7
payoff &amp;lt;- rbinom(n = num_trials, size = 1, prob = 0.7)

# Learning rates closer to 0.05
beta_01 &amp;lt;- rw_update(lambda = payoff, beta = 0.01, init = 0)
beta_03 &amp;lt;- rw_update(lambda = payoff, beta = 0.03, init = 0)
beta_05 &amp;lt;- rw_update(lambda = payoff, beta = 0.05, init = 0)
beta_07 &amp;lt;- rw_update(lambda = payoff, beta = 0.07, init = 0)
beta_09 &amp;lt;- rw_update(lambda = payoff, beta = 0.09, init = 0)

# Store in data.frame for plotting
all_data &amp;lt;- stack(data.frame(beta_01 = beta_01,
                             beta_03 = beta_03,
                             beta_05 = beta_05,
                             beta_07 = beta_07,
                             beta_09 = beta_09))
# Add trial 
all_data[[&amp;quot;trial&amp;quot;]] &amp;lt;- rep(1:num_trials, 5)
names(all_data)[2]  &amp;lt;- &amp;quot;Beta&amp;quot;

# Plot results
p2 &amp;lt;- ggplot(all_data, aes(x = trial, y = values, color = Beta)) +
  geom_line() + 
  geom_hline(yintercept = 0.7, colour=&amp;quot;black&amp;quot;, linetype = &amp;quot;longdash&amp;quot;) + 
  ggtitle(&amp;quot;Expected Probability of Winning Outcome&amp;quot;) + 
  xlab(&amp;quot;Trial Number&amp;quot;) + 
  ylab(&amp;quot;Expected Pr(win)&amp;quot;)
p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://haines-lab.com/post/2017-04-04-choice_RL_1_files/figure-html/2017-04-02_fig3-1.svg&#34; width=&#34;672&#34; style=&#39;height: 100%; width: 100%; object-fit: contain&#39; /&gt;&lt;/p&gt;
&lt;p&gt;Over 500 trials, the expected value for the win rate converges to the true win rate, 70%.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;summary&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;4. Summary&lt;/h1&gt;
&lt;p&gt;In this post, we reviewed the original Rescorla-Wagner updating rule (a.k.a. the &lt;em&gt;Delta Rule&lt;/em&gt;) and explored its contemporary instantiation. I have shown that the Delta Rule can be used to estimate the win rate of a slot machine on a trial-by-trial basis. While this example may first appear trivial (e.g. why not just take the average of all past outcomes?), we will explore more practical usages in later posts. For now, try playing with the above code yourself! If you want a slightly more challenging problem, try finding the solution to the following question:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;How should you change the learning rate so that the expected win rate is always the average of all past outcomes?&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hint –&amp;gt; With some simple algebra, the Delta Rule can be re-written as follows:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Pr(win)_{t+1} = (1 - \beta) \cdot Pr(win)_{t} + \beta \cdot \lambda_{t}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Happy solving! See the answer in the next post.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Revealing Neurocomputational Mechanisms of Reinforcement Learning and Decision-Making With the hBayesDM Package</title>
      <link>http://haines-lab.com/publication/hbayesdm/</link>
      <pubDate>Mon, 06 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>http://haines-lab.com/publication/hbayesdm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A new reinforcement learning model of the Iowa Gambling Task</title>
      <link>http://haines-lab.com/talk/cog_brown_1/</link>
      <pubDate>Wed, 30 Nov 2016 12:10:00 +0000</pubDate>
      
      <guid>http://haines-lab.com/talk/cog_brown_1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>easyml</title>
      <link>http://haines-lab.com/project/easyml/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>http://haines-lab.com/project/easyml/</guid>
      <description>&lt;p&gt;Currently under construction.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>hBayesDM</title>
      <link>http://haines-lab.com/project/hbayesdm/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>http://haines-lab.com/project/hbayesdm/</guid>
      <description>&lt;p&gt;Currently under construction.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
